{
    "version": "https://jsonfeed.org/version/1",
    "title": "Finecloud",
    "description": "",
    "home_page_url": "https://www.finecloud.ch",
    "feed_url": "https://www.finecloud.ch/feed.json",
    "user_comment": "",
    "icon": "https://www.finecloud.ch/media/website/cloud.png",
    "author": {
        "name": "Finecloud"
    },
    "items": [
        {
            "id": "https://www.finecloud.ch/tabby.html",
            "url": "https://www.finecloud.ch/tabby.html",
            "title": "Tabby Config-Sync auf Nextcloud einrichten",
            "summary": "A terminal for the modern age Tabby ist ein anpassbares, Platform-Übergreifendes Terminal App für die Arbeit mit Lokalen Shells sowie Serial, SSH und Telnet Verbindungen. Aus diesen Gründen ist Tabby viel praktischer und moderner als Putty: Link zum App: https://tabby.sh/ Link zum Projekt auf GitHub:&hellip;",
            "content_html": "<h3>A terminal for the modern age</h3>\n<p><a href=\"https://tabby.sh/\" rel=\"nofollow\">Tabby</a> ist ein anpassbares, Platform-Übergreifendes Terminal App für die Arbeit mit Lokalen Shells sowie Serial, SSH und Telnet Verbindungen.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://www.finecloud.ch/media/posts/33/readme-terminal.png\" sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/33/responsive/readme-terminal-xs.png 300w ,https://www.finecloud.ch/media/posts/33/responsive/readme-terminal-sm.png 480w ,https://www.finecloud.ch/media/posts/33/responsive/readme-terminal-md.png 768w ,https://www.finecloud.ch/media/posts/33/responsive/readme-terminal-lg.png 1024w ,https://www.finecloud.ch/media/posts/33/responsive/readme-terminal-xl.png 1360w ,https://www.finecloud.ch/media/posts/33/responsive/readme-terminal-2xl.png 1600w\"  alt=\"\" width=\"2724\" height=\"1810\"></figure>\n<p>Aus diesen Gründen ist Tabby viel praktischer und moderner als <a href=\"https://www.putty.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Putty</a>:</p>\n<ul>\n<li>Läuft auf Windows, Mac und Linux</li>\n<li>Integrierter SSH-Client mit Verbindungsmanager</li>\n<li>Integriertes serielles Terminal</li>\n<li>Unterstützung für PowerShell, PS Core, WSL, Git-Bash, Cygwin, Cmder und CMD</li>\n<li>Volle Unicode-Unterstützung, einschließlich Zeichen mit doppelter Breite</li>\n<li>Dateiübertragung von/zu SSH-Sitzungen über SFTP und Zmodem</li>\n<li>Thematisierung und Farbschemata</li>\n<li>Vollständig konfigurierbare Shortcuts und Multi-Chord-Shortcuts</li>\n<li>Erinnert sich an Ihre Registerkarten und geteilten Fenster</li>\n<li>Shell-Funktionen wie unter Windows, einschließlich Tab-Vervollständigung</li>\n<li>Integrierter verschlüsselter Container für SSH-Secrets und -Konfiguration</li>\n</ul>\n<p>Link zum App: <a href=\"https://tabby.sh/\">https://tabby.sh/</a></p>\n<p>Link zum Projekt auf GitHub: <a href=\"https://github.com/eugeny/tabby\">https://github.com/eugeny/tabby</a> </p>\n<h3>Tabby Config Sync mit Nextcloud</h3>\n<p class=\"msg msg--warning\">Achtung: So schön das alles klingt, der WebDav Sync mit Nextcloud scheint nicht zu funktionieren. Beim Anlegen der Konfigdatei via WebDav erscheint ein unspezifischer Fehler. Solange das Problem noch nicht behoben ist, muss man wohl mit alternativen auskommen wie FTPS oder manuelles kopieren der Datei auf einen Nextcloud-Share.</p>\n<p>Doch was bringt das alles ohne Config Sync zwischen deinen einzelnen Geräten, Windows, MacOS und Linux. Dafür kannst du entweder den Server von Tabby verwenden, oder andere 3rd Party Backends. Noch toller ist aber, dass du deine eigene Nextcloud mittels DAV Protokoll verwenden kannst, um die Konfiguration zwischen deinen Geräten zu synchronisieren:</p>\n<h5>Vorbereitungen auf Nextcloud</h5>\n<ol>\n<li>Aus Sicherheitsgründen empfehle ich für den ConfigSync einen separaten Benutzer Account explizit nur für diesen ConfigSync zu erstellen.</li>\n<li>Melde dich mit dem neuen Benutzer an deiner Nextcloud an und erstelle einen neuen leeren Ordner \"TabbyConfigSync\".</li>\n<li>Optional kannst du unter den Security Einstellungen des Benutzers noch ein App Passwort generieren - damit kannst du den Zugriff auf das DAV Protokoll beschränken. Mit dem App Passwort ist eine Anmeldung am Nextcloud WebInterface nicht möglich.</li>\n</ol>\n<h5>Einstellungen in der Tabby App</h5>\n<ol>\n<li>Installiere das Tabby Plugin \"cloud-settings-sync\" Quelle: <a href=\"https://tabby-cloud.tranit.co/\">https://tabby-cloud.tranit.co/</a> <br><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://www.finecloud.ch/media/posts/33/Screenshot-2022-06-14-at-22.13.16.png\" sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.13.16-xs.png 300w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.13.16-sm.png 480w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.13.16-md.png 768w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.13.16-lg.png 1024w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.13.16-xl.png 1360w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.13.16-2xl.png 1600w\"  alt=\"\" width=\"1754\" height=\"1094\"></figure></li>\n<li>Klicke auf \"Get\" um das Plugin zu installieren:<br><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://www.finecloud.ch/media/posts/33/Screenshot-2022-06-14-at-22.15.00.png\" sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.15.00-xs.png 300w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.15.00-sm.png 480w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.15.00-md.png 768w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.15.00-lg.png 1024w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.15.00-xl.png 1360w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.15.00-2xl.png 1600w\"  alt=\"\" width=\"1754\" height=\"1094\"></figure></li>\n<li>Beende die App und starte sie neu, damit das Plugin aktiv wird</li>\n<li>Nun ist ein neuer Reiter in den Einstellungen \"Settings Sync\", gib hier die folgenden Einstellungen an:\n<ul>\n<li>URL: <a href=\"https://nextcloud.domain.com\">https://nextcloud.domain.com</a></li>\n<li>User: useraccount</li>\n<li>Password: dein App-Passwort</li>\n<li>Port: 443</li>\n<li>Pfad: /remote.php/dav/files/useraccount/TabbyConfigSync<br><figure class=\"post__image post__image--wide\"><img loading=\"lazy\"  src=\"https://www.finecloud.ch/media/posts/33/Screenshot-2022-06-14-at-22.57.05.png\" sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.57.05-xs.png 300w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.57.05-sm.png 480w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.57.05-md.png 768w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.57.05-lg.png 1024w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.57.05-xl.png 1360w ,https://www.finecloud.ch/media/posts/33/responsive/Screenshot-2022-06-14-at-22.57.05-2xl.png 1600w\"  alt=\"\" width=\"1913\" height=\"693\"></figure></li>\n<li>Klicke anschliessend auf den Button \"Test Connection\"</li>\n</ul>\n</li>\n<li>Sofern deine Einstellungen korrekt sind, Klicke auf \"Save This Setting\". Nun kannst du nun auf der rechten Seite noch den Sync aktivieren.</li>\n<li>Richte diese Konfiguration auf allen deinen Geräten so ein und deine Config ist auf allen Geräten immer aktuell.</li>\n</ol>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "unix",
                   "tools",
                   "tabby",
                   "ssh",
                   "shell",
                   "nextcloud",
                   "linux",
                   "container"
            ],
            "date_published": "2022-06-17T06:44:36+02:00",
            "date_modified": "2022-06-17T06:44:36+02:00"
        },
        {
            "id": "https://www.finecloud.ch/multithreading.html",
            "url": "https://www.finecloud.ch/multithreading.html",
            "title": "Threads und Runnables",
            "summary": "In Java ist ein Thread zunächst ein Objekt wie jedes andere auch. Ein Thread kann erzeugt werden, indem man einen Konstruktoren der Klasse Thread aufruft. Diesen kann man behandeln wie jedes andere Objekt auch, ihn in einer Variabel speichern, als Parameter übergeben usw. Erst wenn&hellip;",
            "content_html": "<p>In Java ist ein Thread zunächst ein Objekt wie jedes andere auch. Ein Thread kann erzeugt werden, indem man einen Konstruktoren der Klasse Thread aufruft. Diesen kann man behandeln wie jedes andere Objekt auch, ihn in einer Variabel speichern, als Parameter übergeben usw. Erst wenn man die Methode start ruft, kehrt dieser sofort zurück und der Thread, in dem der Aufruf erfolgt, wird mit der nächsten Anweisung fortgesetzt. Gleichzeitig und unabhängig wird nun aber auch der neue Thread ausgeführt und folgt seiner eigenen Anweisungsfolge.</p>\n<p>Was ein Thead tun soll, übergibt man ihm normalerweise als Konstruktor, in Form eines Runnable-Objekts. Runnable ist ein funktionales Interface, das die Methode public void run () fordert. Man kann das Interface traditionell implementieren oder einen neuen Thea als Lambda übergeben:</p>\n<p><code>public static void main(String[] args) throws Exception {</code><br><code>    for (int i = 0; i &lt; 10; i++){</code><br><code>        Thread t = new Thread(() -&gt; </code><br><code>                IntStream.range(0, 10)</code><br><code>                .forEach(j -&gt;</code><br><code>                 System.out.println(</code><br><code>                 Thread.currentThread().getName() + \" Durchlauf \" + j)),</code><br><code>                 \"Thread \" + i);</code><br><code>        t.start();</code><br><code>    }</code><br><code>}</code></p>\n<p>Welcher Thread zuerst bis Zehn gezählt hat ist völlig willkürlich und bei der nächsten Ausführung bestimmt wieder anders. Es gibt keine Garantie welcher Thread zuerst ausgeführt wird. Man kann Einfluss darauf nehmen, wie viel Ausführungszeit einem Thread zugeteilt wird, indem man mit <em>setPriority</em> seine Priorität setzt. Ein Thread mit höherer Priorität erhält mehr Prozessorzeit als ein Thread mit niedriger Priorität. Aber auch <em>Thread.MAX_PRITORIY</em> zu setzen gibt keine Sicherheit, dass dieser Thread zuerst ausgeführt wird, es bedeutet lediglich, dass ihm insgesamt mehr Zeit zugeteilt wird. Das ist ein Problem der parallelen Programmierung: Man hat niemals die Sicherheit, dass Operationen in verschiedenen Threads in einer bestimmten Reihenfolge ausgeführt werden.</p>\n<p>Der Lebenszyklus eines Threads sieht wie folgt aus:</p>\n<ul>\n<li>Wurde das Thread-Objekt erzeugt, aber noch nicht gestartet, so existiert der Thread noch nicht. Hier ist es wichtig die Begriffe klar zu trennen: Natürlich existiert das Java-Objekt vom Typ Thread. Es gibt aber zu diesem Zeitpunkt noch keinen weiteren Ausführungsstrang.</li>\n<li>Sobald <em>start</em> gerufen wird, ist der Thread lebendig. Ein weiterer Ausführungsstrang wurde gestartet und ihm wird Rechenzeit zugeteilt. Ob ein Thread lebendig ist, können Sie mit der Methode <em>isAlive</em> prüfen.</li>\n<li>Wenn das Ende der <em>run</em>-Methode des übergebeben Runnable erreicht ist, der Thread als keinen weiteren Code mehr auszuführen hat, ist der Thread tot. Ein toter Thread bleibt auch tot, man kann ihn nicht mit <em>start</em> erneut ausführen.</li>\n</ul>\n<p><code>public static class NetzEmpfaenger implements Runnable {</code><br><code>    @Override</code><br><code>    public void run() {</code><br><code>        try (Socket verbindung = new Socket(\"…\", 23456)){</code><br><code>            InputStream in = verbindung.getInputStream();</code><br><code>            byte[] buffer = new byte[256];</code><br><code>            while (true) {</code><br><code>                int gelesen = in.read(buffer);</code><br><code>                verarbeite(buffer, gelesen);</code><br><code>            }</code><br><code>        } catch (IOException ex) {</code><br><code>            verbindungVerloren();</code><br><code>        }</code><br><code>    }</code><br><code>    protected void verarbeite(byte[] buffer, int gelesen){…}</code><br><code>    protected void verbindungVerloren(){…}</code><br><code>}</code></p>\n<p>Dieser Code liest solange Daten aus einer Netzwerkverbindung, bis die Verbindung unterbrochen wird. Währenddessen muss das Programm aber nie auf Daten aus dem Netzwerk warten, das blockierende Lesen passiert im Thread des Runnable und behindert keine anderen Threads. Solche laufende Threads haben den Nachteil das die JVM am laufen bleibt, bis alle Threads beendet wurden. Der Haupt-Thread, also der, der die main-Methode ausführt, ist in dieser Beziehung nichts besonderes. Auch wenn er beendet wurde, läuft die JVM so lange weiter, bis alle Threads tot sind. Mit solchen Threads wie dem oben gezeigten würde sie also nie beendet. Um die unsterbliche JVM zu vermeiden, könnte man entweder einen Mechanismus einbauen. um Ihre Threads zu stoppen - das ist aber umständlich -, oder man macht aus dem ausführenden Thread einen Daemon-Thread:</p>\n<p><code>Thread t = new Thread(new NetzEmpfaenger(), \"Netzwerkthread\");</code><br><code>t.setDaemon(true);</code><br><code>t.start;</code></p>\n<p>Werden in einem Programm nur noch Daemons ausgeführt, so kann die JVM beendet werden und die Daemon-Threads laufen weiter.</p>\n<h3>Geteilte Ressourcen</h3>\n<p>Herausfordernd wird es, wenn mehrere Threads auf dieselbe Ressource zugreifen möchten, zum Beispiel auf die gleiche Variable:</p>\n<p><code>public class ThreadTest {</code><br><code>    public int counter = 0;</code><br><code>    public void run() {</code><br><code>        Thread[] threads = new Thread[10];</code><br><code>        for (int i = 0; i &lt; 10; i++) {</code><br><code>            threads[i] = new Thread(() -&gt; {</code><br><code>                for (int j = 0; j &lt; 100; j++){</code><br><code>                    counter++;</code><br><code>                }</code><br><code>            }, \"Thread \" + i);</code><br><code>            threads[i].start();</code><br><code>        }</code><br><code>        for (Thread t : threads) {</code><br><code>            while (t.isAlive()) {</code><br><code>                try {</code><br><code>                    t.join();</code><br><code>                } catch (InterruptedException ex) {</code><br><code>                }</code><br><code>            }</code><br><code>        }</code><br><code>        System.out.println(counter);</code><br><code>    }</code><br><code>}</code></p>\n<p>Es werden zehr Threads gestartet. Jeder Thread führt nun eine Schleife mit 100 Durchläufen aus und addiert für jeden Durchlauf 1 zu counter, einem Feld der ThreadTest-Klasse.</p>\n<p>Jeder erzeugte Thread-Objekt wird in einem Array gespeichert, weil es noch in einer zweiten Schleife verwendet wird. Dort wird mit der Methode join darauf gewartet, dass jeder der zehn Threads auch beendeet wird. Das ganze Drumherum, die Schleife und das Try-catch-Statement sind nur deshalb nötig, weil join theoretisch beim Warten unterbrochen werden könnte und dann eine InterruptedException werfen würde. Die untere Schleife dient nur dazu, auf die zehn Threads zu warten und erst, wenn sie alle beendet sind, den finalen Wert von counter auszugeben.</p>\n<p>Das Problem in diesem Code ist, dass anstatt dem Erwarteten Resultat von 1000 teilweise das Ergebniss 850 oder andere Werte zurück kommen. Was passiert da?</p>\n<p>Die Kurzschreibweise counter++ sieht in Wirklichkeit eher so aus:</p>\n<p>int neuerWert = counter + 1;<br>counter = neuerWert;</p>\n<p>Der Wert von Counter wird ausgelesen, dann wird eins addiert und dieser neue Wert nach counter zurückgegeben. Das ist kein Problem, solange es nur einen Thread gibt. Aber mit mehreren Threads kann das passieren:</p>\n<ol>\n<li>Thread 1 lies den Wert von counter aus und erhält zum Beispiel 17.</li>\n<li>Thread 2 liest den Wert von counter aus und erhält ebenfalls 17.</li>\n<li>Thread 2 addiert 1 zu seinem gelesenen Wert und schreibt das Resultat 18 nach counter.</li>\n<li>Thread 1 addiert 1 zu seinem gelesenen Wert, erhält ebenfalls das Ergebnis 18 und schreibt dieses nach counter.</li>\n</ol>\n<p>Das Problem ist, dass der Inkrement-Operator nicht <em>atomar</em> ist. Als atomar bezeichnet werden solche Operatoren, die nicht von einem anderen Thread unterbrochen werden können.</p>\n<p>Operationen, die ihrerseits ohne weiteres zutun atomar sind, gibt es in Java nur eine: die Zuweisung. Objektvariablen und primitive Variabel mit der Ausnahme von long und double werden neue Werte von der JVM in nur einem Arbeitsschritt zugewiesen, es ist für einen anderen Thread schlicht nicht möglich, eine Zuweisung zu unterbrechen.</p>\n<p>Atomare Zuweisungen lösen das obrige Problem aber leider nicht. Um den Zähler trotz Zugriff aus mehreren Threads korrekt zu halten, müssen wir selbst dafür sorgen, dass die Variable atomar inkrementiert wird. Dazu gibt es zwei Wege: einen einfacheen mit begrenzen Möglichkeiten mit \"Atomaren Datentypen\" oder einen komplexen, aber vielseitigen mittels \"Synchronisation\".</p>\n<p> </p>\n<p> </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "writer",
                   "threads",
                   "softwareentwicklung",
                   "socket",
                   "runnable",
                   "reader",
                   "parallel",
                   "lambda",
                   "java.io",
                   "java",
                   "dev"
            ],
            "date_published": "2022-06-17T06:32:45+02:00",
            "date_modified": "2022-06-17T06:32:45+02:00"
        },
        {
            "id": "https://www.finecloud.ch/netzwerkkommunikation-mit-java.html",
            "url": "https://www.finecloud.ch/netzwerkkommunikation-mit-java.html",
            "title": "Netzwerkkommunikation mit Java",
            "summary": "In Java gibt es keinen nennenswerten Unterschied wischen I/O mit Daten und I/O mit Netzwerkverbindungen. In beiden Fällen basiert die Ein- und Ausgabe auf InputStream und OutputStream, der Unterschied liegt nur darin, wo diese Datenströme herkommen. Bei der Netzwerkkommunikation mit dem TCP-Protokoll kommen sie aus&hellip;",
            "content_html": "<p>In Java gibt es keinen nennenswerten Unterschied wischen I/O mit Daten und I/O mit Netzwerkverbindungen. In beiden Fällen basiert die Ein- und Ausgabe auf InputStream und OutputStream, der Unterschied liegt nur darin, wo diese Datenströme herkommen. Bei der Netzwerkkommunikation mit dem TCP-Protokoll kommen sie aus einem Socket. Bei UDP wird die Klasse DatagramSocket verwendet, welche nicht auf Streams basiert.</p>\n<p>Socket hat zwar eine lange Liste von Methoden, aber bei der grundlegenden Verwendung kann man die meisten davon ignorieren.</p>\n<h3>Client-Seite</h3>\n<p><code>String nachricht = in.readLine();</code><br><code>try (Socket verbindung = new Socket(\"localhost\", 23456)){</code><br><code>    BufferedReader reader = new BufferedReader(</code><br><code>     new InputStreamReader(verbindung.getInputStream())); </code><br><code>    BufferedWriter writer = new BufferedWriter(</code><br><code>     new OutputStreamWriter(verbindung.getOutputStream()));</code><br><code>    writer.write(nachricht);</code><br><code>    writer.newLine();</code><br><code>    writer.flush();</code><br><code>    String antwort = reader.readLine();</code><br><code>}</code></p>\n<p>Im Beispiel wird dem Socket im Konstruktor Adresse (IP oder Hostname) und Port des Servers angegeben, mit dem eine Verbindung hergestellt werden soll. Die Verbindung wird automatisch hergestellt und mit den Methoden getInputStream und getOutputStream kann man Daten vom Server empfangen und zum Server senden.</p>\n<p>Einen kleinen Unterschied zwischen Netzwerk I/O und Datei I/O gibt es mit der flush-Methode. Sie sorgt dafür, dass der Schreibpuffer sofort weiterverarbeitet wird, auch wenn er noch nicht voll ist. Dabei wird der Strom aber nicht sofort geschlossen, denn es sollen nicht nur Daten in eine Richtung versendet werden, es soll echte Kommunikation in beide Richtungen stattfinden. Damit der Server eine Antwort schicken kann, die dann mit readLine gelesen werden kann, muss er zunächst die Nachricht vom Client erhalten und dazu muss der Client den Puffer leeren.</p>\n<p>Ausserdem wird weder InputStream noch OutputStream geschlossen. Beide sind fest mit dem Socket verbunden, aus dem sie hergestellt wurden und wenn man einen der Ströme schliesst, wird auch der Socket geschlossen. Andersherum werden die Datenströme aber auch geschlossen, wenn man den Socket schliesst, deswegen reicht es, diesen als Ressource für den try-Block anzugeben.</p>\n<h3>Server-Seite</h3>\n<p>Ein einfaches Serverprogramm in Java zu schreiben, ist kaum anders als beim Client, nur die Herkunft des Sockets ändert sich:</p>\n<p><code>ServerSocket server = new ServerSocket(23456);</code><br><code>try (Socket verbindung = server.accept()){</code><br><code>    BufferedReader reader = new BufferedReader(</code><br><code>     new InputStreamReader(verbindung.getInputStream())); </code><br><code>    BufferedWriter writer = new BufferedWriter(</code><br><code>     new OutputStreamWriter(verbindung.getOutputStream()));</code><br><code>    String nachricht = reader.readLine();</code><br><code>    writer.write(antwort);</code><br><code>    writer.flush();</code><br><code>}</code></p>\n<p>Ein ServerSocket dient nicht direkt der Kommunikation, er wartet nur auf eingehende Verbindungen. Der Konstruktor-Parameter gibt den Port an, auf dem Verbindungen akzeptiert werden sollen; die Methode accept wartet, bis auf diesem Port eine Verbindung hergestellt wird. Und warten heisst hier wirklich warten: accept blockiert so lange, bis eine Verbindung zustande kommt. Wenn dies der Fall ist, gibt accept einen Socket zurück, mit dem man genauso verfahren kann, wie mit einem Socket auf der Client-Seite.</p>\n<p>Wie demonstriert, wird nur eine Verbindung akzeptiert und verarbeitet. Für ein Beispiel ausreichend, werden für einen echten Serverprozess dagegen üblicherweise Verbindungen in einer Schleife akzeptiert und die Verarbeiten wird in einem neuen Thread durchgeführt, so dass dieser Thread erneut mit accept auf Verbindungen warten kann.</p>\n<p>Hier ein Beispiel-Code für ServerSocket mit Threads:</p>\n<p><code>ServerSocket server = new ServerSocket(23456);</code><br><code>while(!beendet){</code><br><code>    try (Socket verbindung = server.accept()){</code><br><code>        new Thread(() -&gt; verarbeiteVerbidnung(verbindung));</code><br><code>    }</code><br><code>}</code></p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "writer",
                   "softwareentwicklung",
                   "socket",
                   "reader",
                   "network",
                   "java.io",
                   "java",
                   "dev",
                   "bufferedwriter"
            ],
            "date_published": "2022-06-10T12:53:21+02:00",
            "date_modified": "2022-06-10T14:58:43+02:00"
        },
        {
            "id": "https://www.finecloud.ch/proxmox-ve-72-installation.html",
            "url": "https://www.finecloud.ch/proxmox-ve-72-installation.html",
            "title": "Proxmox VE 7.2 Installation",
            "summary": "Systemanforderungen Proxmox gibt folgende minimale Systemanforderungen an: Für produktive Workloads sind diese Anforderungen aber nicht gedacht. Daher sind die empfohlenen Systemanforderungen wie folgt: Da ich meine Proxmox Infrastruktur zum Start nur als Standalone LAB installieren will und für mein kleines Budget maximal viel Leistung erhalten&hellip;",
            "content_html": "<h3 id=\"mcetoc_1g53sim7k6lt\"></h3>\n<div class=\"post__toc\">\n<h3>Table of Contents</h3>\n<ul>\n<li><a href=\"#mcetoc_1g53sim7k6lu\">Systemanforderungen</a></li>\n<li><a href=\"#mcetoc_1g53sim7k6lv\">Vorbereitung</a>\n<ul>\n<li><a href=\"#mcetoc_1g53sim7k6m0\">BIOS Einstellungen</a></li>\n<li><a href=\"#mcetoc_1g53sim7k6m1\">BIOS Upgrade</a></li>\n<li><a href=\"#mcetoc_1g53sim7k6m2\">Installations Medium</a></li>\n</ul>\n</li>\n<li><a href=\"#mcetoc_1g53sim7k6m3\">Installation</a></li>\n</ul>\n</div>\n<h3 id=\"mcetoc_1g53sim7k6lu\">Systemanforderungen</h3>\n<p>Proxmox gibt folgende minimale Systemanforderungen an:</p>\n<ul>\n<li>CPU: 64bit (Intel EMT64 or AMD64)</li>\n<li>Intel VT/AMD-V capable CPU/Mainboard for KVM full virtualization support</li>\n<li>RAM: 1 GB RAM, plus additional RAM needed for guests</li>\n<li>Hard drive</li>\n<li>One network card (NIC)</li>\n</ul>\n<p>Für produktive Workloads sind diese Anforderungen aber nicht gedacht. Daher sind die empfohlenen Systemanforderungen wie folgt:</p>\n<ul>\n<li>Intel EMT64 or AMD64 with Intel VT/AMD-V CPU ﬂag</li>\n<li>Memory: Minimum 2 GB for the OS and Proxmox VE services, plus designated memory for guests. For Ceph and ZFS, additional memory is required; approximately 1GB of memory for every TB of used storage</li>\n<li>Fast and redundant storage, best results are achieved with SSDs</li>\n<li>OS storage: Use a hardware RAID with battery protected write cache (“BBU”) or non-RAID with ZFS (optional SSD for ZIL)</li>\n<li>VM storage:\n<ul>\n<li>For local storage, use either a hardware RAID with battery backed write cache (BBU) or non-RAID for ZFS and Ceph. Neither ZFS nor Ceph are compatible with a hardware RAID controller</li>\n<li>Shared and distributed storage is possible</li>\n</ul>\n</li>\n<li>Redundant (Multi-)Gbit NICs, with additional NICs depending on the preferred storage technology and cluster setup.</li>\n<li>For PCI(e) passthrough the CPU needs to support the VT-d/AMD-d ﬂag.</li>\n</ul>\n<p>Da ich meine Proxmox Infrastruktur zum Start nur als Standalone LAB installieren will und für mein kleines Budget maximal viel Leistung erhalten will, geht das nur auf Kosten von Redundanz und Verfügbarkeit, deshalb habe ich mich zum Start für folgende Hardware entschieden:</p>\n<ul>\n<li>Intel NUC10i7FNHN Barebone</li>\n<li>Kingston SO-DDR4-RAM 32GB</li>\n<li>Samsung SSD 970 EVO Plus NVMe M.2 500GB</li>\n</ul>\n<h3 id=\"mcetoc_1g53sim7k6lv\">Vorbereitung</h3>\n<h4 id=\"mcetoc_1g53sim7k6m0\">BIOS Einstellungen</h4>\n<p>Bevor wir mit der Installation starten, muss im BIOS des NUC überprüft werden ob die Virtualisierungs-Unterstützung des Prozessors aktiviert ist, dazu müssen folgende Settings aktiviert sein:</p>\n<ul>\n<li>Performance &gt; Processor &gt; Hyper-Threading (enabled)</li>\n<li>Performance &gt; Processor &gt; Intel Turbo Boost Technology (checked)</li>\n</ul>\n<p>Secure Boot schalten wir aus:</p>\n<ul>\n<li>Boot &gt; Secure Boot &gt; Secure Boot &gt; Disabled</li>\n</ul>\n<p>Weiter empfiehlt es sich die Boot Reihenfolge so anzupassen das USB Geräte an erster Stelle kommen. Dazu unter:</p>\n<ul>\n<li>Boot &gt; Boot Priority &gt; Boot USB Devices Frist</li>\n</ul>\n<h4 id=\"mcetoc_1g53sim7k6m1\">BIOS Upgrade</h4>\n<p>Von einem pauschalen BIOS Upgrade habe ich abgesehen, da Intel die Frage \"Wann soll ich ein BIOS Update machen?\" wie folgt beantwortet:</p>\n<blockquote>\n<p>Update the BIOS on your computer only if the newer BIOS version can solve a specific problem. We don't recommend BIOS updates for computers that do not need it. </p>\n<p>Quelle: <a href=\"https://www.intel.com/content/www/us/en/support/articles/000006714/intel-nuc.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.intel.com/content/www/us/en/support/articles/000006714/intel-nuc.html</a></p>\n</blockquote>\n<h4 id=\"mcetoc_1g53sim7k6m2\">Installations Medium</h4>\n<p>Proxmox empfiehlt die Installation via ISO File mittels einem USB Flash Drive. Dazu muss aber das ISO File zuerst in ein Image konvertiert werden, damit wir dieses Image so auf den USB Stick schreiben können, damit wir davon booten können. Unter MacOS geht das am einfachsten so:</p>\n<ol>\n<li>Neues Terminal öffnen (suche nach Terminal in Spotlight)</li>\n<li>Konvertieren der .iso Datei nach .dmg:<br><code># hdiutil convert -format UDRW -o proxmox-ve_*.dmg proxmox-ve_*.iso</code></li>\n<li>Damit wir eine aktuelle Liste der verfügbaren Geräte erhalten:<br><code># diskutil list</code></li>\n<li>Nun stecken wir den USB Stick ein und geben den vorherigen Befehl nochmals ein, damit wir herausfinden können, welche Gerätebezeichnung vergeben wurde. (sollte etwas mit, /dev/diskX sein).<br><code># diskutil list</code><br><code># diskutil unmountDisk /dev/diskX</code></li>\n<li>Nun schreiben wir das Image auf den USB Stick. Achtung: das X muss mit der Disk Nummer des letzten Befehls ersetzt werden. (rdiskX anstelle von diskX ist Absicht, das erhöht die Schreibgeschwindikeit):<br><code># sudo dd if=proxmox-ve_*.dmg of=/dev/rdiskX bs=1m</code></li>\n</ol>\n<h3 id=\"mcetoc_1g53sim7k6m3\">Installation</h3>\n<p>Zum Start des Installations wizards erhält man folgende Optionen:</p>\n<ul>\n<li>Install Proxmox</li>\n<li>Rescue Boot</li>\n<li>Test Memory</li>\n</ul>\n<p>Mit <em>Install Proxmox</em> kann die Installation gestartet werden. Nachdem die ELUA akzeptiert wurde, müssen wir uns Entscheiden welches Filesystem wir verwenden wollen und auf welche Harddisk Proxmox installiert werden soll. <strong>Da ich nur eine NVMe SSD habe, gibt es nur diese Auswahl der Disk. Als Filesystem will ich ein ZFS ausprobieren, was eigentlich normalerweise erst bei mehreren Disks sinnvoll ist.</strong></p>\n<p><strong>Obwohl ZFS mehr Memory frisst (angeblich muss man mit mindestens Pauschal 4GB rechnen plus 1GB Memory pro TB Raw Datenspeicher) möchte ich auf die folgenden ZFS Vorteile welche in Proxmox angeblich nur mit ZFS integriert nicht verzichten:</strong></p>\n<ul>\n<li><strong>Encryption</strong></li>\n<li><strong>Snapshots/Backups</strong></li>\n<li><strong>Compression</strong></li>\n</ul>\n<p>Da ich aber nur eine Disk habe verzichte ich auf einen RAID Level, und nehme die Option: <em>zfs (RAID0)</em></p>\n<p>Als nächstes werden die <em>Location and Time Zone</em> definiert. Weiter muss ein Kennwort definiert werden für den Proxmox root Account, bevor die Netzwerk Angaben angefragt werden und schliesslich die Installation gestartet werden kann.</p>\n<p>Sobald die Installation erfolgt ist, kann das Proxmox Web-UI von einem anderen Gerät aus unter <em>https://&lt;proxmox-ip&gt;:8006/ </em>geöffnet werden.</p>\n<p> </p>\n<p> </p>\n<p> </p>\n<p> </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "virtualization",
                   "unix",
                   "proxmox",
                   "lxc",
                   "linux",
                   "kvm",
                   "hci",
                   "container"
            ],
            "date_published": "2022-06-09T09:27:28+02:00",
            "date_modified": "2022-06-09T13:16:03+02:00"
        },
        {
            "id": "https://www.finecloud.ch/proxmox-ve-intro.html",
            "url": "https://www.finecloud.ch/proxmox-ve-intro.html",
            "title": "Proxmox VE 7.2 Übersicht",
            "summary": "Die Architektur Proxmox VE ist eine Plattform zum Betrieben von virtuellen Maschinen und Container. Dabei ist die gesamte Proxmox VE Plattform open source und baisert auf Debian Linux. die VE Plattform besteht aus zwei virtualisierungs-technologien: Proxmox gibt es als single node, oder als Cluster mit&hellip;",
            "content_html": "<div class=\"post__toc\">\n<h3>Table of Contents</h3>\n<ul>\n<li><a href=\"#mcetoc_1g4tdpel45mg\">Die Architektur</a></li>\n<li><a href=\"#mcetoc_1g4tdhqsl5l5\">Zentrales Management</a></li>\n<li><a href=\"#mcetoc_1g4tdhqsl5l6\">Storage</a></li>\n<li><a href=\"#mcetoc_1g4tdhqsl5l7\">Backup und Restore</a></li>\n<li><a href=\"#mcetoc_1g4tdhqsl5l8\">High Availability Cluster</a></li>\n<li><a href=\"#mcetoc_1g4tdhqsl5l9\">Networking</a></li>\n<li><a href=\"#mcetoc_1g4tdhqsl5la\">Firewall</a></li>\n<li><a href=\"#mcetoc_1g4tdhqsl5lb\">Hyper-converged Infrastructure (HCI)</a>\n<ul>\n<li><a href=\"#mcetoc_1g4tdlsh25m7\">HCI Storage</a></li>\n</ul>\n</li>\n<li><a href=\"#mcetoc_1g4tdcg765ga\">Feature Übersicht</a></li>\n</ul>\n</div>\n<h3 id=\"mcetoc_1g4tdpel45mg\">Die Architektur</h3>\n<p><img loading=\"lazy\" src=\"https://www.finecloud.ch/media/posts/22/Screenshot-2022-06-06-at-23.00.20.png\" sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-xs.png 300w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-sm.png 480w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-md.png 768w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-lg.png 1024w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-xl.png 1360w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-2xl.png 1600w\"  alt=\"Architektur\" width=\"765\" height=\"586\"></p>\n<p>Proxmox VE ist eine Plattform zum Betrieben von virtuellen Maschinen und Container. Dabei ist die gesamte Proxmox VE Plattform open source und baisert auf Debian Linux. die VE Plattform besteht aus zwei virtualisierungs-technologien:</p>\n<ul>\n<li>Kernel-based Virtual Machine (KVM)</li>\n<li>Container-based virtualization (LXC)</li>\n</ul>\n<p>Proxmox gibt es als single node, oder als Cluster mit Anzahl n Nodes. Das gesamte Management der Plattform kann über ein Web basiertes Management Interface erfolgen.</p>\n<h3 id=\"mcetoc_1g4tdhqsl5l5\">Zentrales Management</h3>\n<p>Proxmox ermöglicht es sämtliche Management Arbeiten zentral auszuführen, egal ob es sich um einen Cluster mit n Nodes handelt, oder ob es nur ein Single Node ist.  Damit lässt sich der gesamte Cluster von jedem einzelnen Node aus verwalten. Das JavaScript basierte Web-UI erlaubt die Verwaltung von Storage, Containern sowie den KVM Guest VMs. Darüberhinaus kann über das Web-UI die History, Syslogs, Backup und Restore Jobs, live-migration oder HA Aktivitäten eingesehen werden.</p>\n<p>Was Proxmox einmalig macht ist deren Cluster File System: pmxcfs, ein Datenbank getriebener Speicher zum Speichern von Konfigurationsdateien. Mittels corosync werden diese Dateien in Echtzeit zwischen allen Nodes im Cluster repliziert. Das File System speichert alle Daten in einer persistenten Datenbank auf der Disk, unabhängig davon wird eine kopier der Datenbank im RAM, mit einer maximalen Speichergrösse von 30MB abgelegt, was für mehr als tausend VMs ausreicht.</p>\n<p>Für fortgeschrittene Anwender kann Proxmox auch via CLI, also Unix Shell oder mit Windows Powershell oder über die Rest-API verwaltet werden. Die API unterstützt JSON als primäres Datenformat.</p>\n<p>Für die Authentifizierung unterstützt Proxmox Microsoft Active Directory, LDAP, Linux PAM standard authentifizierung oder den eigenen built-in Proxmox VE auth Server.</p>\n<h3 id=\"mcetoc_1g4tdhqsl5l6\">Storage</h3>\n<p>Proxmox verfügt über ein sehr flexibles Storage Modell. VM Images können lokal auf einem oder mehreren Local Storages gespeichert werden, oder auf einem shared Storage wie NFS oder einem SAN. Es können sämtliche für Debian Linux verfügbaren Storage-Technologien verwendet werden.</p>\n<p>Für den Betrieb eines Clusters sollte man unbedingt einen Shared Storage verwenden um die VMs zu speichern, damit man auch von der live-migrate Funktion gebrauch machen kann. Diese ermöglicht es eine VM im laufenden Betrieb von einem Node auf einen anderen zu verschieben. Dabei haben sämtliche Nodes im Cluster direkten zugriff auf die VM Disk Images. Nachfolgende Liste listet die unterstützten Storage auf:</p>\n<p>Netzwerk-Storage:</p>\n<ul>\n<li>LVM Group (network backing with iSCSI targets)</li>\n<li>iSCSI target</li>\n<li>NFS Share</li>\n<li>CIFS Share</li>\n<li>Ceph Share</li>\n<li>Directly use iSCSI LUNs</li>\n<li>GlusterFS</li>\n</ul>\n<p>Lokale Storage:</p>\n<ul>\n<li>LVM Group (local backing devices like block devices, FC devices, DRBD, ect.)</li>\n<li>Directory (storage on existing filesystem)</li>\n<li>ZFS</li>\n</ul>\n<h3 id=\"mcetoc_1g4tdhqsl5l7\">Backup und Restore</h3>\n<p>Das integrierte Backup Tool names <em>vzdump </em>kreiert konsistente Snapshots von laufenden Containern und KVM Guests. Dabei wird ein Archiv der VM oder Container Daten erstellt, welches auch die Konfiguration der VM/CT beinhaltet.</p>\n<h3 id=\"mcetoc_1g4tdhqsl5l8\">High Availability Cluster</h3>\n<p>Ein multi-node Proxmox VE HA Cluster erlaubt den Betrieb von hochverfügbaren virtual servers. Der Cluster basiert auf bewährte Linux HA Technologien, welche eine stabile und zuverlässigen HA Service ermöglichen.</p>\n<h3 id=\"mcetoc_1g4tdhqsl5l9\">Networking</h3>\n<p>Proxmox erlaubt den Einsatz von VLANS (IEEE 802.1q) und Netzwerk bonding/aggregation. Damit ist es möglich auch komplexere, flexible virtuelle Netzwerke für die Proxmox VE Hosts aufzubauen und sämtliche Funktionen des Linux Netzwerk Stacks zu nutzen.</p>\n<p>Standardmässig kommt Proxmox mit einem bridge Netzwerkmodel.  Alle VMs können diese bridge verwenden, so als wären alle Guests mit virtuellen Netzwerkkabel zu einem physikalischen Netzwerk zusammengeschlossen. Jeder Netzwerkkarte kann eine TCP/IP Konfiguration zugewiesen werden.</p>\n<h3 id=\"mcetoc_1g4tdhqsl5la\">Firewall</h3>\n<p>Die integrierte Firewall ermöglicht es Netzwerk Packete von jedem VM oder Container Interface zu filtern. Firewall Rules können in <em>Security Groups</em> gruppiert werden.</p>\n<h3 id=\"mcetoc_1g4tdhqsl5lb\">Hyper-converged Infrastructure (HCI)</h3>\n<p>HCI Umgebungen sind besonders nützlich für Deployments in einer Infrastruktur mit hohen Anforderungen und tiefem administrations Budget.</p>\n<p id=\"mcetoc_1g4tdlsh25m6\">Vorteile von HCI sind:</p>\n<ul>\n<li>Skalierbarkeit: nahtlose Erweiterung von Computing, Netzwerk und Storage</li>\n<li>Tiefe Kosten: Proxmox VE ist open source und integriert alle benötigten Komponenten und kann damit eine teure Computing/Storage Infrastruktur ersetzen</li>\n<li>Daten-Schutz und Effizienz: Services wie Backup und Disaster Recovery sind direkt integriert</li>\n<li>Kein Vendor-Lock-in dank open source</li>\n</ul>\n<h4 id=\"mcetoc_1g4tdlsh25m7\">HCI Storage</h4>\n<p>Proxmox unterstützt die nahtlose Integration von HCI Storage Infrastrukturen wie ceph oder ZFS.</p>\n<ul>\n<li>ceph: bietet self-healing und self-managing shared, zuverlässig und hoch skalierbaren Storage.</li>\n<li>ZFS: kombiniert File System und Local Volume Manager mit erweitertem Schutz vor Datenkorruption, diversen RAID modi und schnellen und günstigen Snapshots. </li>\n</ul>\n<h3 id=\"mcetoc_1g4tdcg765ga\">Feature Übersicht</h3>\n<ul>\n<li>Open source software</li>\n<li>Kein Vendor lock-in</li>\n<li>Linux kernel</li>\n<li>Schnelle installation, einfach zu verwenden</li>\n<li>Web-basiertes Management Interface</li>\n<li>REST API</li>\n<li>Grosse aktive Community</li>\n<li>Tiefe Administrationskosten und einfaches deployment</li>\n</ul>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "virtualization",
                   "unix",
                   "proxmox",
                   "lxc",
                   "linux",
                   "kvm",
                   "hci",
                   "container"
            ],
            "date_published": "2022-06-08T15:44:19+02:00",
            "date_modified": "2022-06-08T15:46:47+02:00"
        },
        {
            "id": "https://www.finecloud.ch/testen-von-io-operationen.html",
            "url": "https://www.finecloud.ch/testen-von-io-operationen.html",
            "title": "Testen von I/O-Operationen",
            "summary": "Das Problem von I/O-Operationen ist, dass sie nur schlecht testbar sind. Ihre Testfälle müssen sich darauf verlasse, dass bestimmte Dateien vorhanden sind, und einen bestimmten Inhalt haben. Sie können den Testfällen zwar entsprechende Dateien beilegen, aber dann müssen Sie Dateien mit Ihren Testfällen ausliefern. Es&hellip;",
            "content_html": "<p>Das Problem von I/O-Operationen ist, dass sie nur schlecht testbar sind. Ihre Testfälle müssen sich darauf verlasse, dass bestimmte Dateien vorhanden sind, und einen bestimmten Inhalt haben. Sie können den Testfällen zwar entsprechende Dateien beilegen, aber dann müssen Sie Dateien mit Ihren Testfällen ausliefern. Es gibt Strategien das zu vermeiden.</p>\n<p>Wichtig ist, dass man für Lese- und Schreiboperationen niemals <em>File</em> als Methodenparamater deklarieren sollte, sondern immer einen <em>Reader</em> oder <em>Writer</em> (bzw. <em>InputStream</em> oder <em>OutputStream</em>). Dadurch wird der Code sofort besser testbar, denn man kann aus dem Testfall einen <em>StringReader</em> (oder <em>StringWriter</em>) übergeben. Es handelt sich dabei um einen vollwertigen <em>Reader</em> (bzw. <em>Writer</em>), der genau wie jeder andere Reader verwendet werden kann, seine Daten aber nicht aus einer Datei oder einer Netzwerkverbindung liest, sondern aus einem String, den Sie im Konstruktor übergeben. So hat der Testfall die volle Kontrolle darüber, welche Daten die zu testende Methode zu sehen bekommt:</p>\n<p><code>public static final String TESTDATEN = </code><br><code> \"2013\\t0.2\\t-0.7\\t0.1\\t8.1\\t11.8\\t15.7\\t19.5\\t17.9\\t13.3\\t10.6\\t4.6\\t3.6\\n\" +</code><br><code> \"2012\\t1.9\\t-2.5\\t6.9\\t8.1\\t14.2\\t15.5\\t17.4\\t18.4\\t13.6\\t8.7\\t5.2\\t1.5\";</code><br><br><code>@Test</code><br><code>public void testLiesTemperaturdaten() {</code><br><code>    Reader testdaten = new StringReader(TESTDATEN);</code><br><code>    Temperaturstatistik statistik = Temperaturstatistik.liesDaten(testdaten);</code><br><code>    assertNotNull(statistik.getJahr(2013);</code><br><code>    //weitere Asserts folgen</code><br><code>}</code></p>\n<p>Analog dazu funktioniert das auch beim Schreiben in einen StringWriter:</p>\n<p><code>@Test</code><br><code>public void testSchreibePlayliste() {</code><br><code>    StringWriter testWriter = new StringWriter();</code><br><code>    Playlist playlist = new Playlist();</code><br><code>    playlist.addSong(...);</code><br><code>    playlist.schreibeNach(testWriter);</code><br><code>    assertEquals(\"erwarteter Inhalt\", testWriter.toString);</code><br><code>}</code></p>\n<p>Die <em>toString</em>-Methode des <em>StringWriter</em> gibt alle Daten, die hineingeschrieben wurden, als einen String zurück. Sie können dadurch in einem Testfall ganz leicht vergleichen, ob der Inhalt dem erwarteten Inhalt entspricht. Analog dazu kann ByteArrayInputStream und ByteArrayOutputStream genutzt werden, um diese Aufgabe mit einem byte-Array für Binärdateien zu erfüllen.</p>\n<p>Schwieriger wird es, wenn der Testfall wirklich Dateien benötigt, zum Beispiel, weil die zu testende Methode Dateien in einem Verzeichnis suchen soll. Da kann man mit temporären Dateien arbeiten. Die Methode File.createTempFile erzeugt eine Datei im Verzeichnis für temporäre Dateien Ihres Betriebsystems. So kann ein Präfix übergeben werden, der klar macht, woher die Datei stammt und eine Dateiendung. Als Rückgabewert erhält man das File-Objekt der so angelegten Datei. Eine temporäre Datei wird aber nicht automatisch wieder gelöscht. Um am Ende des Tests wieder aufzuräumen, sollten Sie daher an jeder erzeugten Datei noch deleteOnExit rufen, dann stellt Java sicher, dass diese Dateien wieder entfernt werden:</p>\n<p><code>@Test</code><br><code>public void testMitDatei() throws IOException {</code><br><code>    File tempDatei = File.createTempFile(getClass().getName(), \".mp3\");</code><br><code>    tempDatei.deleteOnExit();</code><br><code>    //Test durchführen</code><br><code>}</code></p>\n<p>Als Empfehlung und gute Angewohnheit bietet es sich an, den Klassennamen als Präfix für temporäre Dateien zu verwenden. Als optionalen dritten Parameter kann createTempFile ein Verzeichnis übergeben werden, in welchem die Datei angelegt werden soll, falls man die Datei nicht im temporären Verzeichnis des Betriebssystems anlegen möchte.</p>\n<p>Wenn man ein temporäres Verzeichnis anlegen möchte, trifft man leider erneut auf den Bruch zwischen java.io und java.nio: Die Methode, die temporäre Ordner anlegt, findet man nur in der Files-Klasse, dementsprechend erhält man auch ein Path-Objekt zurück, aus dem man dann selbst wieder ein File machen muss:</p>\n<p><code>@Test</code><br><code>public void testMitVerzeichnis() throws IOException {</code><br><code>    File tempVerzeichnis = Files.createTempDirectory(\"mp3test\").toFile();</code><br><code>    tempVerzeichnis.deleteOnExit();</code><br><code>    File tempDatei = File.createTempFile(getClass().getName(), \".mp3\",</code><br><code>        tempVerzeichnis);</code><br><code>    tempDatei.deleteOnExit();</code><br><code>    //Test durchführen</code><br><code>}</code></p>\n<p> </p>\n<p> </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "writer",
                   "verzeichnisse",
                   "softwareentwicklung",
                   "reader",
                   "java.nio.files",
                   "java.io.file",
                   "java.io",
                   "java",
                   "dev",
                   "dateien"
            ],
            "date_published": "2022-06-06T22:04:20+02:00",
            "date_modified": "2022-06-06T22:45:58+02:00"
        },
        {
            "id": "https://www.finecloud.ch/java-reader-und-writer.html",
            "url": "https://www.finecloud.ch/java-reader-und-writer.html",
            "title": "Java Reader und Writer",
            "summary": "Lese und Schreiboperationen an Dateien sind in Java streambasiert. Diese Streams haben aber nichts mit der Stream-API zu tun. Streambasierte I/O bedeutet, dass nicht alle Dateien im Speicher behalten werden müssen, damit man mit ihnen Arbeiten kann. Man muss also nicht den gesamten Dateiinhalt lesen,&hellip;",
            "content_html": "<div class=\"post__toc\">\n<h3>Table of Contents</h3>\n<ul>\n<li><a href=\"#mcetoc_1g4tdq62j5mq\">Lesen und Schreiben von Textdaten</a></li>\n<li><a href=\"#mcetoc_1g4tdq62j5mr\">Puffern und zeilenweise lesen</a></li>\n<li><a href=\"#mcetoc_1g4tdq62j5ms\">Schreiben mit Writer</a></li>\n</ul>\n</div>\n<p>Lese und Schreiboperationen an Dateien sind in Java streambasiert. Diese Streams haben aber nichts mit der Stream-API zu tun. Streambasierte I/O bedeutet, dass nicht alle Dateien im Speicher behalten werden müssen, damit man mit ihnen Arbeiten kann. Man muss also nicht den gesamten Dateiinhalt lesen, bevor man ihn verarbeiten kann. Folglich muss man bei einer Netzwerkverbindung nicht darauf warte, dass alle Daten eingegangen sind, stattdessen kann man die Daten Stück für Stück aus einem <em>InputStream</em> lesen und verarbeiten. Im Idealfall kann das gerade eingelesene Datenstück bereits wieder aus dem Speicher entfernt werden, bevor das nächste Datenstück gelesen wird. Genau so können auch Datenstücke in einen OutputStream bereits geschrieben werden sobald diese zur Verfügung stehen und muss nicht zuerst gewartet werden, bis alle Daten bereit sind.</p>\n<p>Java macht einen Unterschied ob, mit Textdaten oder mit Binärdaten gearbeitet wird. Textdaten werden mit einem <em>Reader</em> gelesen und mit einem <em>Writer</em> geschrieben, für Binärdaten gibt es dafür <em>InputStream</em> und <em>OutputStream</em>.</p>\n<h3 id=\"mcetoc_1g4tdq62j5mq\">Lesen und Schreiben von Textdaten</h3>\n<p>Folgender Code liest Daten zeilenweise ein:</p>\n<p><code>try (BufferedReader reader = new BufferedReader(new FileReader(dateiname))){</code><br><code>    …</code><br><code>}</code></p>\n<p>Das ist bereits eine spezialisierte Funktion, die nur BufferedReader bietet. Andere Reader, zum Beispiel der <em>FileReader</em>, wissen nichts von Zeilen, sie arbeiten nur mit Zeichen. Dazu bietet <em>Reader</em> eine parameterlose Methode read, die genau ein Zeichen liest. Das ist zwar die für den Entwickler einfachste Variante, sie ist aber auch äusserst ineffektiv. Der komplexere, aber bessere Weg, aus einem <em>Reader</em> zu lesen, ist ein char[] als Puffer zu benutzen:</p>\n<p><code>File quelle = new File(…);</code><br><code>char[] buffer = new char[1024];</code><br><code>try (Reader reader = new FileReader(quelle)) {</code><br><code>    int gelesen;</code><br><code>    while ((gelesen = reader.read(buffer)) &gt; -1) {</code><br><code>        char[] geleseneDaten = (gelesen == buffer.length)</code><br><code>                ? buffer</code><br><code>                : Arrays.copyOf(buffer, gelesen);</code><br><code>        vearbeitePuffer(geleseneDaten);</code><br><code>    }</code><br><code>}</code></p>\n<p>Damit wird wesentlich effizienter gelesen, als Zeichen für Zeichen. Mit jedem Aufruf von read wird der Puffer gefüllt. Der Rückgabewert ist die Anzahl Zeichen, die vom Stream gelesen wurden. Meist entspricht er der Grösse des Puffers, es können aber weniger Zeichen gelesen werden, wenn das Ende der Daten erreicht ist oder gerade in diesem Moment keine Daten mehr zur Verfügung stehen. Wenn das Ende des Datenstroms erreicht ist, gibt read -1 zurück: Daten werden in einer Schleife gelesen und verarbeitet, bis dieser Punkt erreicht ist.</p>\n<p><strong>Wenn weniger Zeichen gelesen werden, als die Puffergrösse gross ist, wird der Rest des Puffers nicht verändert. Das bedeutet, dass am Ende des char-Arrays Daten aus dem Vorherigen Schleifen-Durchlauf stehen können. Deswegen werden die gelesenen Daten, falls es weniger als die Puffergrösse waren, in ein neues Array kopiert; so kann die Methode <em>verarbeitePuffer</em> immer mit einem vollständigen Array arbeiten und muss sich keine Sorgen um übrig gebliebene Daten am Ende des Arrays machen. </strong>Es ist zwar performanter, der verarbeitenden Methode das teilweise gefüllte Array und den Endindex zu übergeben, die gezeigt Variante ist aber weniger fehleranfällig, weil man in <em>verarbeitePuffer</em> nicht darauf achten muss, wann man mit lesen aufhört.</p>\n<p><strong>Es ist sehr wichtig, dass man eine Datei nach dem Zugriff darauf wieder schliesst.</strong> Im Beispiel geschieht das implizit durch das Statement try-with-resources, das an seinen Ressourcen automatisch close aufruft. Sollte man aus irgendeinem Grund dieses Statement nicht verwenden können oder wollen, dann muss man selbst sicherstellen, dass der Reader (oder Writer, InputStream, OutputStream oder jedes Objekt, das auf eine Datei zugreift) ordnungsgemäss geschlossen wird.</p>\n<p><code>public void liesAusDatei(File quelle) throws IOException{</code><br><code>    Reader reader = null;</code><br><code>    try {</code><br><code>        reader =  new BufferedReader(new FileReader(quelle));</code><br><code>        //Daten lesen und verarbeiten</code><br><code>    } finally {</code><br><code>        if (reader != null){</code><br><code>            reader.close();</code><br><code>        }</code><br><code>    }</code><br><code>}</code></p>\n<p>Dieser Code ist etwas unhandlicher und hat zwei Unschönheiten. Die Reader-Variable muss ausserhalb des try-Blocks deklariert werden, da try und Finally keinen gemeinsamen Scope haben. Ausserdem muss im finally-Block geprüft werden, ob der Reader nicht null ist. Das kann passieren, wenn schon beim Erzeugen des Readers eine Exception auftritt, weil Beispielsweise die Datei nicht existiert. In diesem Fall gibt es keinen Reader, der geschlossen werden kann, und ohne die entsprechende Prüfung käme es zu einer weiteren NullPointerException.</p>\n<p>Ein weiteres Problem ist, dass auch reader.close eine IOException werfen kann. Im Beispiel werden innerhalb der Methode liesAusDatei keine Fehler behandelt, alle Fehler werden an den Aufrufer weitergereicht. Im schlimmsten Fall kann es so passieren, dass sowohl im try- als auch im finally-Block Fehler geworfen werden. Der Aufrufer erhält dann nur die Exception aus dem finally-Block, obwohl sie wahrscheinlich nur eine Konsequenz der Exception aus dem try-Block ist. <strong>Das untere Code-Beispiel ist also länger, komplexer und fehleranfälliger. Es gibt somit keinen Grund, diese Variante zu bevorzugen, wenn die Java-Version try-with-resources unterstützt.</strong></p>\n<h3 id=\"mcetoc_1g4tdq62j5mr\">Puffern und zeilenweise lesen</h3>\n<p>Das Puffern der Daten in einem char[] kann man sich theoretisch sparen, wenn man einen BufferedReader einsetzt. Dessen Hauptaufgabe ist es, zu verhindern, dass Daten Byte für Byte von der Festplatte gelesen werden. Dazu liest er immer einen Puffer voll Daten ein, genau wie im oberen Beispiel. Nachfolgende read-Aufrufe werden dann aus dem Puffer bedient, solange dieser noch genügend Daten enthält, erst danach wird wieder auf die Festplatte zugegriffen.</p>\n<p>Als Nebeneffekt seines Puffers hat der BufferedReader aber eine weitere nützliche Fähigkeit: Er kann Textdateien zeilenweise lesen. BufferedReader bietet sowohl die Methode readLine, die die nächste Zeile der Datei liefert, als auf die Methode lines, die alle Zeilen der Datei in einem Stream liefert. Wenn der Inhalt der Datei zeilenorientiert ist, dann ist das viel praktischer, als Daten Zeichen für Zeichen oder Puffer für Puffer einzulesen und selbst nach den Umbrüchen zu suchen.</p>\n<p>Eine BufferedReader lässt sich aus jedem anderen Reader erzeugen, indem man diesen als parameter an den Konstruktor von BufferedReader übergibt:</p>\n<p><code>try (BufferedReader reader = new BufferedReader(new FileReader(quelle))) {</code><br><code>    String zeile;</code><br><code>    while ((zeile = reader.readLine()) != null){</code><br><code>        verarbeiteZeile(zeile);</code><br><code>    }</code><br><code>}</code></p>\n<p>Der zugrunde liegende FileReader wird in einem BufferReader verpackt, um die Fähigkeit zu puffern und zeilenweise zu lesen hinzuzufügen. Das ist eine Anwendung des Decorator-Entwurfsmusters, das für Ein- und Ausgabe in Java extensiv zum Einsatz kommt. Man muss in diesem Fall nur den BufferedReader schliessen, dessen close-Methode ruft automatisch die close-Methode des dekorierten Readers auf.</p>\n<h3 id=\"mcetoc_1g4tdq62j5ms\">Schreiben mit Writer</h3>\n<p>Das Schreiben in eine Date funktioniert fast genau so wie das Lesen aus einer Datei. Man erzeugt ein FileWriter-Objekt, dekoriert es noch mit einem BufferedWriter, schreibt Daten hinein und schliesst den Writer wieder:</p>\n<p><code>try (BufferedWriter writer = new BufferedWriter(new FileWriter(ziel))) {</code><br><code>    for (String zeile : zeilen){</code><br><code>        writer.write(zeile);</code><br><code>        writer.newLine();</code><br><code>    }</code><br><code>}</code></p>\n<p>So schreibt man eine Datei Zeile für Zeile. Writer sind in vielerlei Hinsicht das Spiegelbild von Readern. Sie besitzen eine Methode, die einzelne char-Werte schreibt und eine Methode, die ein ganzes char[] schreibt - man kann einen Schreibpuffer erzeugen, indem man seinen Writer mit einem BufferedWriter dekoriert und auch den Writer in diesem Fall schliesst, wenn man damit fertig ist. Writer selbst kennen das Konzept der Zeile ebenfalls nicht. Wenn man zeilenweise schreiben möchte, dann ist der beste Weg, einen BufferedWriter und seine Methode newLine zu verwenden, um an Ende jeder Zeile einen Umbruch zu erzeugen.</p>\n<p> </p>\n<p> </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "softwareentwicklung",
                   "reader",
                   "java.nio.files",
                   "java.io.file",
                   "java.io",
                   "java",
                   "dev",
                   "dateien",
                   "bufferedwriter"
            ],
            "date_published": "2022-06-06T11:40:36+02:00",
            "date_modified": "2022-06-06T23:12:59+02:00"
        },
        {
            "id": "https://www.finecloud.ch/dateien-und-verzeichnisse-unter-java.html",
            "url": "https://www.finecloud.ch/dateien-und-verzeichnisse-unter-java.html",
            "title": "Dateien und Verzeichnisse unter Java",
            "summary": "Dateioperationen mit java.io werden in Java immer, direkt oder indirekt, durch ein Objekt des Typs java.io.File abgebildet. Dabei kann File aber nicht selbst aus Dateien lesen, oder in sie schreiben, dazu benötigt man einen Reader oder Writer (für Textdateien) resp. einen InputStream oder OutputStream (für&hellip;",
            "content_html": "<div class=\"post__toc\">\n<h3>Table of Contents</h3>\n<ul>\n<li><a href=\"#mcetoc_1g4tdqg1s5n6\">Dateien und Pfade</a></li>\n<li><a href=\"#mcetoc_1g4tdqg1s5n7\">Dateioperationen aus \"Files\"</a></li>\n<li><a href=\"#mcetoc_1g4tdqg1s5n8\">Verzeichnisse</a></li>\n</ul>\n</div>\n<p>Dateioperationen mit java.io werden in Java immer, direkt oder indirekt, durch ein Objekt des Typs java.io.File abgebildet. Dabei kann File aber nicht selbst aus Dateien lesen, oder in sie schreiben, dazu benötigt man einen Reader oder Writer (für Textdateien) resp. einen InputStream oder OutputStream (für Binärdateien).</p>\n<h3 id=\"mcetoc_1g4tdqg1s5n6\">Dateien und Pfade</h3>\n<p>Ein File wird immer aus einer Pfadangabe, entweder <em>absolut</em> oder <em>relativ</em> erzeugt. Absolut geht von einem Wurzelverzeichnis aus, zum Beispiel C:\\ unter Windows, oder / unter Linux. Ein relativer Pfad bezieht sich dagegen auf das aktuelle Verzeichnis des Benutzers, normalerweise von dort aus woher das Programm aufgerufen wurde. Wenn die Datei unter dem angegebenen Pfad nicht existiert, wird auch keine entsprechende Datei unter dem definierten Pfad angelegt:</p>\n<p><code>File windowsDatei = new File(\"C:\\\\home\\\\user\\\\text.txt\");</code><br><code>File linuxDatei = new File(\"/home/user/text.txt\");</code></p>\n<p>Pfade werden also je nach OS unterschiedlich angegeben. Für Windows Pfade als Konstante sind effektiv zwei Doppel Backslashes zu verwenden! Solange die Pfadeingabe vom Benutzer selbst kommt, macht das keine Probleme. Wenn aber aus dem Programm heraus Dateipfade erzeugt werden müssen, dann müssen Sie auf diese Details acht geben. Das richtige Zeichen zum trennen von Verzeichnissen in einer Pfadangabe findet sich in der Konstanten File.separator. Damit lässt sich einen Pfad OS unabhängig erstellen: </p>\n<p><code>File datei = new File(File.separator + \"home\" </code><br><code>    + File.separator + \"user\"</code><br><code>    + File.separator + \"text.txt\");</code></p>\n<p>Unter Unix-basierten Systemen funktioniert dieser Code. Unter Windows bleibt das Problem mit dem Laufwerksbuchstaben. Dazu kann unabhängig vom OS, alle Wurzelverzeichnisse aufgelistet werden. Dazu kennt File die statische Methode listRoots. So lässt sich ein OS unabhängiger Code schreiben:</p>\n<p><code>public File waehleWurzel(){</code><br><code>    File[] wurzeln = File.listRoots();</code><br><code>    if (wurzeln.length == 1){</code><br><code>        return wurzeln[0];</code><br><code>    } else {</code><br><code>        System. out.println(\"Bitte wählen Sie eine Wurzel\");</code><br><code>        for (int i = 0; i &lt; wurzeln.length; i++){</code><br><code>            System.out.println(i + \": \" + wurzeln[i]);</code><br><code>        }</code><br><code>        int index = liesZahl();</code><br><code>        return wurzeln[index];</code><br><code>    }</code><br><code>}</code></p>\n<p>Doch das reicht immer noch nicht ganz, denn unter Windows kann es hier mehrere Einträge geben, je nachdem wieviele Laufwerke vorhanden sind (C:\\, D:\\ ...). In diesem Fall wird der Benutzer geben, ein Laufwerk auszuwählen. Anschliessend kann ein neues File-Objekt relativ zur ausgewählten Wurzel erzeugt werden, indem dies dem Konstruktor angegeben wird:</p>\n<p><code>File wurzel = waehleWurzel();</code><br><code>File datei = new File(wurzel, \"home\"</code><br><code> + File.separator + \"user\"</code><br><code> + File.separator + \"text.txt\");</code></p>\n<p>Ob eine Datei überhaupt existiert kann mit der Methode exists überprüft werden. Da ein File lediglich die objektorientierte Repräsentation eines Pfades ist, kann man Files erzeugen, ohne das diese Dateien bereits existieren. Falls keine Datei existiert kann eine neue Datei mit createNewFile oder mit mkdir ein Verzeichnis an der vom Pfad angegebenen Stelle angelegt werden. File liefert weitere Informationen über Dateien:</p>\n<table style=\"border-collapse: collapse; width: 100%; height: 525.297px;\" border=\"1\">\n<tbody>\n<tr style=\"height: 50.3594px;\">\n<td style=\"width: 49.9288%; height: 50.3594px;\"><strong>Methode</strong></td>\n<td style=\"width: 49.9288%; height: 50.3594px;\"><strong>Funktion</strong></td>\n</tr>\n<tr style=\"height: 107.953px;\">\n<td style=\"width: 49.9288%; height: 107.953px;\">isFile()</td>\n<td style=\"width: 49.9288%; height: 107.953px;\">Prüft, ob es sich bei der angegebenen File-Objekt um eine Datei handelt, (oder einen Ordner)</td>\n</tr>\n<tr style=\"height: 107.953px;\">\n<td style=\"width: 49.9288%; height: 107.953px;\">isDirectory()</td>\n<td style=\"width: 49.9288%; height: 107.953px;\">Prüft, ob es sich bei der angegebenen File-Objekt um einen Ordner handelt, (oder eine Datei)</td>\n</tr>\n<tr style=\"height: 50.3594px;\">\n<td style=\"width: 49.9288%; height: 50.3594px;\">canRead()</td>\n<td style=\"width: 49.9288%; height: 50.3594px;\">Prüft, ob der Benutzer Leserechte hat</td>\n</tr>\n<tr style=\"height: 79.1562px;\">\n<td style=\"width: 49.9288%; height: 79.1562px;\">canWrite()</td>\n<td style=\"width: 49.9288%; height: 79.1562px;\">Prüft, ob der Benutzer Schreibrechte hat</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">canExectue()</td>\n<td style=\"width: 49.9288%;\">Prüft, ob der Benutzer Ausführungsrechte hat</td>\n</tr>\n<tr style=\"height: 79.1562px;\">\n<td style=\"width: 49.9288%; height: 79.1562px;\">getName()</td>\n<td style=\"width: 49.9288%; height: 79.1562px;\">Liefert den Namen der Datei, ohne vorangehende Pfadangabe</td>\n</tr>\n<tr style=\"height: 50.3594px;\">\n<td style=\"width: 49.9288%; height: 50.3594px;\">getParent()<br>getParentFile()</td>\n<td style=\"width: 49.9288%; height: 50.3594px;\">Liefert das übergeordnete Verzeichnis, entweder als String mit getParent oder als Objekt mit getParentFile</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">lastModified()</td>\n<td style=\"width: 49.9288%;\">Liefert das letzte Änderungsdatum der Datei als long</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">length()</td>\n<td style=\"width: 49.9288%;\">Liefert die Grösse der Datei in Byte als long</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">delete</td>\n<td style=\"width: 49.9288%;\">eine Datei löschen</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">renameTo</td>\n<td style=\"width: 49.9288%;\">eine Datei umbenennen</td>\n</tr>\n</tbody>\n</table>\n<p>java.io.File stellt jedoch keine Methoden zur Verfügung für das Kopieren oder verschieben von Dateien. Dazu gibt es aber seit Java 7 eine Hilfsklasse aus Files.</p>\n<h3 id=\"mcetoc_1g4tdqg1s5n7\">Dateioperationen aus \"Files\"</h3>\n<p>Die Klasse Files ist eine Sammlung von Hilfsmethoden für alles, was mit Dateien zu tun hat. Diese Klasse ist aber nicht im java.io-Package enthalten, sondern nur im java.nio.files. Damit ist es die einzige Klasse aus der Non-Blocking-I/O-API, die man auch beim alltäglichen Umgang mit Dateien regelmässig benutzt.</p>\n<p>Da die Hilfsklasse zu der API java.nio.file.Path gehört und nicht zur java.io.File müssen bei jeder Operation die Parameter von File nach Path und die Rückgabewerte, falls Dateien zurückgegeben werden, wieder von Path nach File konvertiert werden. Dabei lassen sich nicht alle Path-Objekte nach File konvertieren, nur solche welche aus einer Operation auf einem File resultieren. Damit sind auch Kopier- und Verschiebeoperationen möglich. Die Verwendung dieser Methode macht mehr Sinn, als eine Eigenentwicklung in Java, da dies nicht nur praktischer ist, sondern auch effizienter die JDL Systemaufrufe verwenden kann.</p>\n<p><code>//File nach Path konvertieren</code><br><code>Path quellPath = quelle.toPath();</code><br><code>Path zielPath = ziel.toPath();</code><br><code>//ENTWEDER Datei kopieren</code><br><code>Path ergebnisPath = Files.copy(quellPath, zielPath);</code><br><code>//ODER Datei verschieben</code><br><code>Path ergebnisPath = Files.move(quellPath, zielPath);</code><br><code>//Ergebnis - eigentlich wieder das Ziel - nach File konvertieren</code><br><code>File ergebnis = ergebnisPath.toFile();</code></p>\n<h3 id=\"mcetoc_1g4tdqg1s5n8\">Verzeichnisse</h3>\n<p>Um den Inhalt von Verzeichnissen zu ermitteln, gibt es die überladene Methode listFiles die zur Files Klasse gehört. Ohne Parameter gibt sie alle im Verzeichnis enthaltenen Dateien zurück. Wenn man nur an bestimmten Dateien interessiert ist, dann sollte man entweder einen FileFilter oder einen FilenameFilter an listFiles übergeben. Die beiden Filterklassen unterscheiden sich nur darin, dass FileFilter das File-Objekt der gefundenen Datei zur Prüfung erhält, FilenameFilter den Dateinamen als String und das aktuelle Verzeichnis. Beide Filter sind funktionale Interfaces und können deshalb auch als Lambdas angegeben werden.</p>\n<p><code>//Alle Dateien auflisten</code><br><code>File[] alleDateien = verzeichnis.listFiles();</code><br><code>//Alle Dateien mit der Endung .txt auflisten </code><br><code>File[] textDateien = verzeichnis.listFiles((parent, name) -&gt; </code><br><code> name.endsWith(\".txt\"));</code><br><code>//Alle Unterverzeichnisse auflisten</code><br><code>File[] unterverzeichnisse = verzeichnis.listFiles(file -&gt; </code><br><code> file.isDirectory());</code></p>\n<p>Auch zum Auflisten des Verzeichnisinhalts hat die Klasse Files Hilfsmethoden. list gibt dabei den Inhalt eines Verzeichnisses als einen Stream von Path-Objekten zurück. walk, listet nicht nur den Inhalt des übergebenen Verzeichnisses auf, sondern auch aller Unterverzeichnisse, ist also rekursiv.</p>\n<p><code>Files.walk(quelle.toPath()).forEach(System.out::println);</code></p>\n<p>Optional kann die Tiefe der rekursiven Auflistung limitiert werden bis zu einer bestimmten Tiefe. walk(quelle, 1) enthält nur den Inhalt des Verzeichnisses selbst, tut also dasselbe wie list. walk(quelle, 2) enthält den Inhalt der Verzeichnisses und seiner direkten Unterverzeichnisse usw.</p>\n<p>Weiter kann mit Files.find in einem Verzeichnis und dessen Unterverzeichnisse nach Dateien gesucht werden, die bestimmten Vorgaben entsprechen. Leider ist auch hier dass java.io und java.nio nicht aus einem Guss. So muss man also die Suchkriterien nicht als FileFilter angeben, sondern als BiPredicate, das als Parameter des Path-Objekt der Datei und ein Objekt vom Typ BasicFileAttributes erhält, in dem sich Informationen wie Dateigrösse und letzte Zugriffszeit finden. Das Beispiel zeigt, wie man Dateien, die grösser als 500MB sind, auflisten kann. Der grosse Nachteil von walk und find ist, dass wenn der Zugriff auf ein Verzeichnis nicht möglich ist, brechen sie mit einer Fehlermeldung ab. Es gibt keine Funktion, diesen Methoden beizubringen, bei unlesbaren Verzeichnissen einfach den Fehler zu ignorieren und weiter zu suchen. Deswegen wird häufig dennoch auf File.listFiles zurückgegriffen.</p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "verzeichnisse",
                   "softwareentwicklung",
                   "java.nio.files",
                   "java.io.file",
                   "java.io",
                   "java",
                   "dev",
                   "dateien"
            ],
            "date_published": "2022-06-04T15:42:48+02:00",
            "date_modified": "2022-06-06T23:13:08+02:00"
        },
        {
            "id": "https://www.finecloud.ch/streamcollect-daten-aus-einem-stream-sammeln.html",
            "url": "https://www.finecloud.ch/streamcollect-daten-aus-einem-stream-sammeln.html",
            "title": "Stream.collect - Daten aus einem Stream sammeln",
            "summary": "Die mächtige collect-Methode ist mit zwei Signaturen überladen, collect(Supplier, BiConsumer, BiConsumer) und collect(Collector). Beide sind aber prinzipiell identisch; ein Collection ist lediglich ein Objekt, das die drei Funktionen zusammenfasst und wiederverwendbar macht. collect sieht etwas bedrohlich aus, weil man gleich drei Funktionen übergeben muss, die&hellip;",
            "content_html": "<p>Die mächtige collect-Methode ist mit zwei Signaturen überladen, collect(Supplier, BiConsumer, BiConsumer) und collect(Collector). Beide sind aber prinzipiell identisch; ein Collection ist lediglich ein Objekt, das die drei Funktionen zusammenfasst und wiederverwendbar macht.</p>\n<p>collect sieht etwas bedrohlich aus, weil man gleich drei Funktionen übergeben muss, die zusammen irgendwie Ihre Ausgabe erzeugen sollen. Jede Funktion hat eine klar definierte Aufgabe:</p>\n<ul>\n<li>Der <strong>Supplier</strong> erzeugt ein Objekt, in dem gesammelt werden soll. Wenn man mittels collection eine Liste aus einem Stream erzeugen will, dann muss der Supplier diese Liste erzeugen. Warum übergibt man dann nicht gleich das Objekt, in dem gesammelt werden soll? Weil der Supplier in einem parallelen Stream mehrmals gerufen wird: Es werden mehrere Listen erzeugt, die später zusammengefasst werden.</li>\n<li>Die <strong>erste BiConsumer</strong>, genannt der <em>Akkumulator</em>, kombiniert ein Element des Streams mit einem der vom Supplier erzeugten Sammelobjekte. Um beim Beispiel der Liste zu bleiben, fügt diese Funktion der Liste ein Element hinzu.</li>\n<li>Der <strong>zweite BiConsumer</strong>, der <em>Kombinator</em>, fügt zwei Sammelobjekte zu einem zusammen. Diese Funktion sorgt also dafür, dass am Ende nur eine Liste zurückgegeben wird, auch wenn mehrere vom Supplier erzeugt wurden. Damit das funktioniert, muss das Sammelobjekt eine Funktion haben, dir diesem Objekt den Inhalt eines anderen Objekts hinzufügt, wie zum Beispiel die Methode addAll an einer Liste.</li>\n</ul>\n<p>Das Beispiel zeigt, wie alle Stream-Elemente in einer Liste gesammelt werden können:</p>\n<p><code>List&lt;Person&gt; personen = personenStream.collect(</code><br><code>        ArrayList::new, </code><br><code>        ArrayList::add, </code><br><code>        ArrayList::addAll);</code></p>\n<p>collect funktioniert nicht nur mit Listen, auch wenn der Methodenname nach Collections klingt. Jedes Objekt, das geeignete Methoden bereitstellt, kann zum Sammeln verwendet werden. So sammeln Sie alle Titel aus Ihrer Musiksammlung in einem String:</p>\n<p><code>String songliste = songs.collect(StringBuilder::new, </code><br><code> (acc, el) -&gt; acc.append(el.getTitel()).append(\"\\n\"), </code><br><code> StringBuilder::append).toString();</code></p>\n<p>Die drei richtigen Funktionen für einen Collector anzugeben, kann schwierig sein. Als Hilfe können die statische Methoden der Companion-Klasse verwendet werden, die nützliche Kollektoren bereitstellt. Zum Beispiel die, welche aus einem Stream wieder eine Collection machen:</p>\n<p><code>List&lt;Song&gt; songList = songs.collect(Collectors.toList());</code><br><code>Set&lt;Song&gt; songSet = songs.collect(Collectors.toSet());</code></p>\n<p>Kollektoren können mehr als das, die nachfolgenden Möglichkeiten aus Collectors machen deutlich, wie mächtig die collect-Methode ist:</p>\n<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\">\n<tbody>\n<tr>\n<td style=\"width: 49.9288%;\"><strong>collectors-Methode</strong></td>\n<td style=\"width: 49.9288%;\"><strong>Funktion</strong></td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">mapToDouble().average()</td>\n<td style=\"width: 49.9288%;\">Durchschnitt berechnen</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">.count()</td>\n<td style=\"width: 49.9288%;\">Elemente zählen</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">.summarizingDouble</td>\n<td style=\"width: 49.9288%;\">Statistische Daten, Summe (Double)</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">.summarizingInt</td>\n<td style=\"width: 49.9288%;\">Statistische Daten, Summe (Int)</td>\n</tr>\n<tr>\n<td style=\"width: 49.9288%;\">.summarizingLong</td>\n<td style=\"width: 49.9288%;\">Statistische Daten, Summe (Long)</td>\n</tr>\n</tbody>\n</table>\n<p><code>DoubleSummaryStatistics statistik = zeilen</code><br><code>    .flatMap(line -&gt; Arrays.stream(line.split(\"\\\\s+\"))</code><br><code>        .skip(1))</code><br><code>    .collect(Collectors.summarizingDouble(Double::parseDouble));</code><br><code>    System.out.println(\"Kältester Monat: \" + statistik.getMin() + \" Grad.\");</code><br><code>    System.out.println(\"Wärmster Monat: \" + statistik.getMax() + \" Grad.\");</code><br><code>    System.out.println(\"Durchschnitt: \" + statistik.getAverage() + \" Grad.\");</code></p>\n<p>Für fortgeschrittene statistische Auswertungen reicht das zwar noch nicht, es fehlt zum Beispiel eine Varianz, aber wenn Sie diese Funktionalität benötigen, können Sie nach demselben Muster einen eigenen Kollektor schreiben.</p>\n<p>Die wohl vielseitigsten collect-Operationen, die Collectors anbietet, sind Partitionierung und Gruppierung. Beide trennen die Elemente im Stream nach einem festgelegten Kriterium in mehrere Gruppen. Der Unterschied zwischen den beiden besteht nur darin, dass <em>partitioningBy</em> Elemente nach einem Prädikat in zwei Gruppen zerlegt, die true-Gruppe und die false-Gruppe, während <em>groupingBy</em> anhand einer Funktion beliebig viele Gruppen erzeugen kann, eine für jeden Wert, den die Funktion zurückgegeben hat. Beide geben eine Map zurück, in der die Schlüssel TRUE/FALSE oder die Rückgabewerte der Funktion enthalten sind, mit den Werten dazu als jeweils eine Liste aller Objekte, die in diese Gruppe sortiert wurden. Mit diesem Beispiel können Songs nach Interpret sortiert werden:</p>\n<p><code>songs.collect(Collectors.groupingBy(Song::getInterpret));</code></p>\n<p>Dieses Beispiel gibt eine Map zurück, deren Schlüssel die Namen der Interpreten sind, die dazugehörigen Werte sind Listen aller Songs dieses Interpreten. Wenn Sie noch einen Schritt weiter gehen wollen, können Sie <em>groupingBy</em> und <em>partitioningBy</em> einen weiteren Collector übergeben, der auf die Werte jeder Gruppe angewendet wird:</p>\n<p><code>songs.collect(Collectors.groupingBy(</code><br><code> Song::getInterpret,</code><br><code> Collectors.maxBy(Comparator.comparing(Song::getSterne))));</code></p>\n<p>So einfach bekommen Sie den besten Song jedes Interpreten. Erst werden Songs nach Interpret gruppiert, in jeder Gruppe wird anschliessend der Song mit der maximalen Anzahl Sterne gefunden.</p>\n<p>Fast immer ist es egal, welche Art von Map Sie beim Gruppieren oder Partitionieren zurückbekommen, aber in seltenen Fällen möchten Sie eine bestimmte Art von Map nutzen, zum Beispiel eine SortedMap. Für diesen Fall können Sie auch noch einen Supplier übergeben, der die richtige Map-Implementierung erzeugt.</p>\n<p> </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "stream-api",
                   "softwareentwicklung",
                   "lambda",
                   "java",
                   "dev",
                   "collector",
                   "collect"
            ],
            "date_published": "2022-06-02T20:34:37+02:00",
            "date_modified": "2022-06-04T12:14:10+02:00"
        },
        {
            "id": "https://www.finecloud.ch/endlose-streams.html",
            "url": "https://www.finecloud.ch/endlose-streams.html",
            "title": "Endlose Streams",
            "summary": "Nicht jeder Stream ist endlich. Manche Streams erzeugen immer weiter Daten. Solche Streams nennt man auch Generatoren, weil sie ihre Daten selbst herstellen. Dazu gibt es in Stream und den primitiven Streams jeweils zwei statische Methoden, die einen solchen Stream erzeugen. Die generate-Methode arbeiten mit&hellip;",
            "content_html": "<p>Nicht jeder Stream ist endlich. Manche Streams erzeugen immer weiter Daten. Solche Streams nennt man auch Generatoren, weil sie ihre Daten selbst herstellen. Dazu gibt es in Stream und den primitiven Streams jeweils zwei statische Methoden, die einen solchen Stream erzeugen.</p>\n<p>Die <em>generate</em>-Methode arbeiten mit einem <em>Supplier</em>. Der so erzeugte Stream enthält nach und nach alle Werte, die dieser Supplier liefert. Ein solcher Stream ist sehr monoton, wenn der übergebene Supplier () -&gt; 1 lautet, aber er ist trotzdem endlos, denn der Supplier wird immer wieder aufgerufen. Zum Glück existieren auch interessantere Supplier.</p>\n<p>Die zweite Möglichkeit, einen endlosen Stream zu erzeugen, heisst <em>iterate</em>. Diese Methode erzeugt einen Stream, indem sie eine übergebene Funktion immer wieder auf einen Standwert anwendet. Für einen Startwert n und eine Funktion f heisst das, der erzeugt Stream enthält die Werte [n, f(n), f(f(n)), f(f(f(n))), …]</p>\n<p><code>Stream.iterate(BigInteger.ONE, i -&gt; i.multiply(two))</code><br><code>        .limit(1000)</code><br><code>        .forEach(System.out::println);</code></p>\n<p>Das Beispiel erzeugt einen Stream alle Zweierpotenzen und gibt die ersten 1000 davon aus. Es versteht sich von selbst, dass manche Operationen auf einem endlosen Stream keine gute Idee sind. Ihn zu sortieren, führt eher zu Problemen, und auch bei einer forEach ohne limit sollte man sicher sein, was man tut. Für den zweiten Fall gibt es aber durchaus Anwendungen. So könnte man in einem Thread einen endlosen Stream von Ergebnissen erzeugen und jedes gefundene Ergebnis in einem anderen Thread verarbeiten.</p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "threads",
                   "stream-api",
                   "softwareentwicklung",
                   "lambda",
                   "java",
                   "dev"
            ],
            "date_published": "2022-06-02T11:02:48+02:00",
            "date_modified": "2022-06-02T11:03:18+02:00"
        }
    ]
}
