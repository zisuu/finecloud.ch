{
    "version": "https://jsonfeed.org/version/1",
    "title": "Finecloud",
    "description": "",
    "home_page_url": "https://www.finecloud.ch",
    "feed_url": "https://www.finecloud.ch/feed.json",
    "user_comment": "",
    "author": {
        "name": "Finecloud"
    },
    "items": [
        {
            "id": "https://www.finecloud.ch/github-codespace.html",
            "url": "https://www.finecloud.ch/github-codespace.html",
            "title": "Github Codespace",
            "summary": "What is a Codespace? A codespace is a development environment that's hosted in the cloud. You can customize your project for GitHub Codespaces by committing configuration files to your repository (also known as configuration-as-code), which creates a repeatable codespace configuration for all users of your&hellip;",
            "content_html": "\n    <h2 id=\"what-is-a-codespace\">\n      What is a Codespace?\n    </h2>\n\n  <p>\n    A codespace is a development environment that's hosted in the cloud. You can customize your project for GitHub Codespaces by committing configuration files to your repository (also known as configuration-as-code), which creates a repeatable codespace configuration for all users of your project. Each codespace you create is hosted by GitHub in a Docker container that runs on a virtual machine. You can choose the type of machine you want to use depending on the resources you need.\n  </p>\n\n    <h2 id=\"how-can-i-create-a-codespace\">\n      How can I create a Codespace?\n    </h2>\n\n  <p>\n    There are four ways to create a Codespace:&nbsp;\n  </p>\n\n  <ul>\n    <li>From a GitHub template or any template repository on GitHub.com to start a new project.</li><li>    From a branch in your repository for new feature work.</li><li>    From an open pull request to explore work-in-progress.</li><li>    From a commit in a repository's history to investigate a bug at a specific point in time.</li>\n  </ul>\n\n  <p>\n    The easiest way to start a Codespace is by clicking the green Code button and then choosing open in a Codespace:\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://www.finecloud.ch/media/posts/102/SCR-20240405-stqz.png\" height=\"892\" width=\"942\" alt=\"\"  sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/102/responsive/SCR-20240405-stqz-xs.png 300w ,https://www.finecloud.ch/media/posts/102/responsive/SCR-20240405-stqz-sm.png 480w ,https://www.finecloud.ch/media/posts/102/responsive/SCR-20240405-stqz-md.png 768w ,https://www.finecloud.ch/media/posts/102/responsive/SCR-20240405-stqz-lg.png 1024w ,https://www.finecloud.ch/media/posts/102/responsive/SCR-20240405-stqz-xl.png 1360w ,https://www.finecloud.ch/media/posts/102/responsive/SCR-20240405-stqz-2xl.png 1600w\">\n      \n    </figure>\n\n    <h4 id=\"what-happens-when-i-create-a-codespace\">\n      What happens when I create a Codespace?\n    </h4>\n\n  <p>\n    When you create a GitHub Codespace, four processes occur:\n  </p>\n\n  <ol>\n    <li>VM and storage are assigned to your Codespace.</li><li>    A container is created.</li><li>    A connection to the Codespace is made.</li><li>    A post-creation setup is made.</li>\n  </ol>\n\n    <h2 id=\"what-you-can-customize\">\n      What you can customize\n    </h2>\n\n  <p>\n    There are many ways you can customize your Codespace. Let's review each one.\n  </p>\n\n  <ul>\n    <li>Settings Sync: You can synchronize your Visual Studio Code (VS Code) settings between the desktop application and the VS Code web client.</li><li>Dotfiles: You can use a dotfiles repository to specify scripts, shell preferences, and other configurations.<br></li><li>    Rename a Codespace: When you create a Codespace, it's assigned an autogenerated display name. If you have multiple Codespaces, the display name helps you to differentiate between Codespaces. You can change the display name for your Codespace.<br></li><li>    Change your shell: You can change your shell in a Codespace to keep the setup you're used to. When you're working in a Codespace, you can open a new terminal window with a shell of your choice, change your default shell for new terminal windows, or install a new shell. You can also use dotfiles to configure your shell.<br></li><li>    Change the machine type: You can change the type of machine that's running your Codespace, so that you're using resources appropriate for the work you're doing.<br></li><li>    Set the default editor: You can set your default editor for Codespaces in your personal settings page. Set your editor preference so that when you create a Codespace or open an existing Codespace, it opens to your default editor.<br>- Visual Studio Code (desktop application)<br>- Visual Studio Code (web client application)<br>- JetBrains Gateway - for opening Codespaces in a JetBrains IDE<br>- JupyterLab - the web interface for Project Jupyter<br></li><li>    Set the default region: You can set your default region in the GitHub Codespaces profile settings page to personalize where your data is held.<br></li><li>    Set the timeout: A Codespace will stop running after a period of inactivity. By default this period is 30 minutes, but you can specify a longer or shorter default timeout period in your personal settings on GitHub. The updated setting applies to any new Codespaces you create, or to existing Codespaces the next time you start them.</li><li>Configure automatic deletion: Inactive Codespaces are automatically deleted. You can choose how long your stopped Codespaces are retained, up to a maximum of 30 days.<br></li>\n  </ul>\n\n    <h2 id=\"difference-betweenandnbspcodespaces-and-githubdev-editor\">\n      Difference between&nbsp;Codespaces and GitHub.dev editor\n    </h2>\n\n    <h4 id=\"when-should-i-use-github-codespaces-and-when-should-i-use-githubdev\">\n      when should I use GitHub Codespaces and when should I use GitHub.dev?\n    </h4>\n\n  <p>\n    GitHub.dev is a good fit if you only want to navigate some files and sources code repositories from GitHub, and maybe make and commit small code changes.\n  </p>\n\n  <p>\n    On the other hand, if you want to run a bunch of tests with your code, or build a heavy application you better use GitHub Codespaces. It has compute associated with it so you can build your code, run your code, and have terminal access. GitHub.dev doesn't have compute in it. With GitHub Codespaces, you get the power of a personal Virtual Machine (VM) with terminal access, the same way you could use your local environment, just in the cloud.\n  </p>\n<div><table>\n  <tr>\n    <th></th>\n    <th>GitHub.dev</th>\n    <th>GitHub Codespaces</th>\n  </tr>\n  <tr>\n    <td>Cost</td>\n    <td>Free</td>\n    <td>Free monthly quota of usage for personal accounts</td>\n  </tr>\n  <tr>\n    <td>Availability</td>\n    <td>Available to everyone on GitHub.com</td>\n    <td>Available to everyone on GitHub.com</td>\n  </tr>\n  <tr>\n    <td>Startup</td>\n    <td>GitHub.dev opens instantly with a key-press and you can start using it right away without having to wait for configuration or installation</td>\n    <td>When you create or resume a Codespace, the Codespace is assigned a VM, and the container is configured based on the contents of a devcontainer.json file. This setup takes a few minutes to create the development environment.</td>\n  </tr>\n  <tr>\n    <td>Compute</td>\n    <td>There's no associated compute, so you can't build and run your code or use the integrated terminal.</td>\n    <td>With GitHub Codespaces, you get the power of a dedicated VM to run and debug your application.</td>\n  </tr>\n  <tr>\n    <td>Terminal access</td>\n    <td>None</td>\n    <td>GitHub Codespaces provides a common set of tools by default, meaning that you can use the Terminal exactly as you would in your local environment.</td>\n  </tr>\n  <tr>\n    <td>Extensions</td>\n    <td>Only a subset of extensions that can run on the web appear in the extensions view and can be installed</td>\n    <td>With GitHub Codespaces, you can use most extensions from the Visual Studio Code Marketplace.</td>\n  </tr>\n</table>\n</div>\n\n    <h2 id=\"using-codespace-images\">\n      Using Codespace images\n    </h2>\n\n  <p>\n    One of the biggest benefits of codespaces is that Github ships images with the most recent and common tools you need to develop. Have a look at this Repository:&nbsp;https://github.com/devcontainers/images/tree/main/src/universal&nbsp;\n  </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "software development",
                   "github",
                   "git",
                   "codespace"
            ],
            "date_published": "2024-04-05T21:02:42+02:00",
            "date_modified": "2024-04-05T21:53:57+02:00"
        },
        {
            "id": "https://www.finecloud.ch/awk-and-sed.html",
            "url": "https://www.finecloud.ch/awk-and-sed.html",
            "title": "Awk and Sed",
            "summary": "awk and sed are text manipulation programs. You can use them for example to replace strings: echo image.jpg | sed 's/\\.jpg/.png/' image.png or change order of strings: echo \"hello world\" | awk '{print $2, $1}' world hello awk and sed are harder to learn than&hellip;",
            "content_html": "\n  <p>\n    awk and sed are text manipulation programs. You can use them for example to replace strings:\n  </p>\n<pre class=\" language-bash\"><code>echo image.jpg | sed 's/\\.jpg/.png/'\nimage.png\n</code></pre>\n\n  <p>\n    or change order of strings:<br>\n  </p>\n<pre class=\" language-bash\"><code>echo \"hello world\" | awk '{print $2, $1}'\nworld hello\n</code></pre>\n\n  <p>\n    awk and sed are harder to learn than some other basic linux cli tools because they contain their own small programming language.<br>\n  </p>\n\n    <h2 id=\"awk-basics\">\n      awk basics\n    </h2>\n\n  <p>\n    awk transforms lines of text (stdin) into any other text, using a set of instructions (called the awk program):\n  </p>\n<pre class=\" language-bash\"><code>awk program input-files\n</code></pre>\n\n  <p>\n    a awk program can also contain one or more `actions`, for example calculating values or printing text. These `actions` run only when an input matches a `pattern`:<br>`pattern {action}`\n  </p>\n\n  <p>\n    typical patterns include:\n  </p>\n\n  <ul>\n    <li>`BEGIN` runs once before the awk processes any input</li><li>`END` run once after awk has processed all the input</li><li>A Regex surrounded by forward slashes, example: `/^[A-Z]/`</li><li>other awk specific expressions, example: `FNR&gt;5` tells awk to skip the first five lines of input</li>\n  </ul>\n\n  <p>\n    <br>A `pattern` with no `action` runs the default action `{print}` .<br>awk can also perform calculations such as these:\n  </p>\n<pre class=\" language-bash\"><code>seq 1 100 | awk '{s+=$1} END {print s}'\n5050</code></pre>\n\n  <p>\n    (sum numbers 1 to 100)\n  </p>\n\n    <h2 id=\"sed-basics\">\n      sed basics\n    </h2>\n\n  <p>\n    sed like awk can be used to transform text from stdin to any other text using instructions called `sed scripts`:\n  </p>\n<pre class=\" language-bash\"><code>sed script input-files</code></pre>\n\n  <p>\n    the most common use case for sed is text replacement, like in this example:<br>\n  </p>\n<pre class=\" language-bash\"><code>echo \"Windows eats Linux for breakfast\" | sed s/Windows/Linux/g | sed s/Linux/Windows/2\n</code></pre>\n\n  <p>\n    \n  </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "shell",
                   "sed",
                   "linux",
                   "bash",
                   "awk"
            ],
            "date_published": "2024-04-05T20:57:46+02:00",
            "date_modified": "2024-04-05T20:58:56+02:00"
        },
        {
            "id": "https://www.finecloud.ch/how-to-do-a-code-review.html",
            "url": "https://www.finecloud.ch/how-to-do-a-code-review.html",
            "title": "How to do a code review",
            "summary": "This Blog post is my personal summary of&nbsp;Googles code review process Make sure to review every line of code you’ve been asked to review, look at the context, make sure you’re improving code health, and compliment developers on good things that they do. Look at&hellip;",
            "content_html": "\n  <p>\n    This Blog post is my personal summary of&nbsp;<a href=\"https://google.github.io/eng-practices/review/\" target=\"_blank\" rel=\"nofollow noopener\">Googles code review process</a>\n  </p>\n\n  <p>\n    \n  </p>\n\n  <div class=\"post__toc\">\n    <h3>Table of contents</h3>\n    <ul>\n      <li><a href=\"#summary-of-what-you-should-look-at\">Summary of what you should look at</a></li><li><a href=\"#the-standard-of-code-review\">The Standard of Code Review</a></li><li><a href=\"#navigate-a-pull-request-pr-in-review\">Navigate a Pull-Request (PR) in review</a><ul><li><a href=\"#1-take-a-broad-view-of-the-change\">1. Take a broad view of the change</a></li><li><a href=\"#2-examine-the-main-parts-of-the-pr\">2. Examine the main parts of the PR</a></li><li><a href=\"#3andnbsplook-through-the-rest-of-the-pr-in-an-appropriate-sequence\">3.&nbsp;Look through the rest of the PR in an appropriate sequence</a></li></ul></li><li><a href=\"#speed-of-code-reviews\">Speed of Code Reviews</a><ul><li><a href=\"#approve-with-comments\">Approve with Comments</a></li></ul></li><li><a href=\"#how-to-write-comments\">How to write comments</a></li>\n    </ul>\n  </div>\n  \n\n    <h2 id=\"summary-of-what-you-should-look-at\">\n      Summary of what you should look at\n    </h2>\n\n  <ul>\n    <li><strong>Design</strong>: Is the code well-designed and appropriate for your system?<br></li><li>    <strong>Functionality</strong>: Does the code behave as the author likely intended? Is the way the code behaves good for its users?</li><li><strong>Complexity</strong>: Could the code be made simpler? Would another developer be able to easily understand and use this code when they come across it in the future?</li><li><strong>Tests</strong>: Does the code have correct and well-designed automated tests?<br></li><li>    <strong>Naming</strong>: Did the developer choose clear names for variables, classes, methods, etc.?</li><li><strong>Comments</strong>: Are the comments clear and useful?</li><li><strong>Style</strong>: Does the code follow our style guides?</li><li><strong>Documentation</strong>: Did the developer also update relevant documentation?<br></li>\n  </ul>\n\n  <p>\n    Make sure to review <strong>every line</strong> of code you’ve been asked to review, look at the <strong>context</strong>, make sure you’re <strong>improving code health</strong>, and compliment developers on <strong>g</strong><strong>ood things</strong> that they do.\n  </p>\n\n    <h2 id=\"the-standard-of-code-review\">\n      The Standard of Code Review\n    </h2>\n\n  <ul>\n    <li>You need to balance the tradeoff between making progress, by letting a change go into your code base and not decreasing overall code health and quality.&nbsp;</li><li><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: 1em; font-weight: var(--font-weight-normal);\">does the Pull-Request improve the maintainability, readability, and understandability?</span><br></li><li><strong>In general you should try to approve a Pull-Request (PR) once it is in a state where it definitely improves the overall code health, even if the PR isn’t perfect.</strong></li><li>Reviewers should not require the author to polish every tiny piece of a CL before granting approval. Rather, the reviewer should balance out the need to make forward progress compared to the importance of the changes they are suggesting.&nbsp;</li><li>Instead of seeking perfection, what a reviewer should seek is continuous improvement.</li><li>If you add a comment on a PR to mention something could be better, but it’s optional and not very important,&nbsp;prefix it with something like “Nit: “ to let the author know that it’s just a point of polish that they could choose to ignore.</li>\n  </ul>\n\n    <h2 id=\"navigate-a-pull-request-pr-in-review\">\n      Navigate a Pull-Request (PR) in review\n    </h2>\n\n    <h3 id=\"1-take-a-broad-view-of-the-change\">\n      1. Take a broad view of the change\n    </h3>\n\n  <p>\n    Look at the PR description and what the PR does in general. Does this change even make sense? If this change shouldn’t have happened in the first place, please respond immediately with an explanation of why the change should not be happening. When you reject a change like this, it’s also a good idea to suggest to the developer what they should have done instead.\n  </p>\n\n    <h3 id=\"2-examine-the-main-parts-of-the-pr\">\n      2. Examine the main parts of the PR\n    </h3>\n\n  <p>\n    Find the file or files that are the “main” part of this PR. Often, there is one file that has the largest number of logical changes, and it’s the major piece of the PR. Look at these major parts first. This helps give context to all of the smaller parts of the PR, and generally accelerates doing the code review.&nbsp;\n  </p>\n\n    <h3 id=\"3andnbsplook-through-the-rest-of-the-pr-in-an-appropriate-sequence\">\n      3.&nbsp;Look through the rest of the PR in an appropriate sequence\n    </h3>\n\n  <p>\n    Once you’ve confirmed there are no major design problems with the CL as a whole, try to figure out a logical sequence to look through the files while also making sure you don’t miss reviewing any file.\n  </p>\n\n    <h2 id=\"speed-of-code-reviews\">\n      Speed of Code Reviews\n    </h2>\n\n  <p>\n    Why is it so important that you send comments out immediately, especially if you see major design problems within a PR?\n  </p>\n\n  <ul>\n    <li>Developers often open a PR and then immediately start new work based on that PR (e.g. feature branch) while they wait for review. If there are major design problems in the PR you’re reviewing, they’re also going to have to re-work their later PR. You want to catch them before they’ve done too much extra work on top of the problematic design.</li><li>Major design changes take longer to do than small changes. Developers nearly all have deadlines; in order to make those deadlines and still have quality code in the codebase, the developer needs to start on any major re-work of the PR as soon as possible.<br></li>\n  </ul>\n\n  <p>\n    When code reviews are slow, several things happen:\n  </p>\n\n  <ul>\n    <li>The velocity of the team as a whole is decreased.</li><li>Developers start to protest the code review process.&nbsp;Most complaints about the code review process are actually resolved by making the process faster.</li><li>Code health can be impacted.<br></li>\n  </ul>\n\n  <p>\n    How fast should a code review be?&nbsp;\n  </p>\n\n  <ul>\n    <li>If you are not in the middle of a focused task, <strong>you should do a code review shortly after it comes in</strong>.</li><li><strong>One business day is the maximum time it should take to respond</strong> to a code review request (i.e., first thing the next morning).</li>\n  </ul>\n\n  <p>\n    <strong>If you are in the middle of a focused task, such as writing code, don’t interrupt yourself to do a code review</strong>. Research has shown that it can take a long time for a developer to get back into a smooth flow of development after being interrupted. So interrupting yourself while coding is actually more expensive to the team than making another developer wait a bit for a code review.\n  </p>\n\n    <h3 id=\"approve-with-comments\">\n      Approve with Comments\n    </h3>\n\n  <p>\n    In order to speed up code reviews, there are certain situations in which a reviewer should give the Approval even though they are also leaving unresolved comments on the PR. This is done when either:\n  </p>\n\n  <ul>\n    <li>The reviewer is confident that the developer will appropriately address all the reviewer’s remaining comments.</li><li>    The remaining changes are minor and don’t have to be done by the developer.</li>\n  </ul>\n\n    <h2 id=\"how-to-write-comments\">\n      How to write comments\n    </h2>\n\n  <ul>\n    <li>Be kind.</li><li>Explain your reasoning (why?).</li><li>Balance giving explicit directions with just pointing out problems and letting the developer decide -&gt; In general it is the developer’s responsibility to fix a PR, not the reviewer’s.</li><li>Encourage developers to simplify code or add code comments instead of just explaining the complexity to you.<br></li>\n  </ul>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "software development",
                   "devops"
            ],
            "date_published": "2024-03-18T08:44:04+01:00",
            "date_modified": "2024-03-18T17:33:39+01:00"
        },
        {
            "id": "https://www.finecloud.ch/building-a-graphql-service.html",
            "url": "https://www.finecloud.ch/building-a-graphql-service.html",
            "title": "Building a GraphQL service",
            "summary": "Let's build a GraphQL Spring Application that will accept GraphQL requests at http://localhost:8080/graphql. First let's navigate to https://start.spring.io. This service pulls in all the dependencies you need for an application and does most of the setup for you. GraphQL is a query language to retrieve&hellip;",
            "content_html": "\n  <div class=\"post__toc\">\n    <h3>Table of contents</h3>\n    <ul>\n      <li><a href=\"#preparation\">Preparation</a></li><li><a href=\"#a-very-short-introduction-to-graphql\">A very short introduction to GraphQL</a></li><li><a href=\"#our-example-api-getting-book-details\">Our example API: getting book details</a></li><li><a href=\"#schema\">Schema</a></li><li><a href=\"#source-of-the-data\">Source of the data</a></li><li><a href=\"#create-the-book-and-author-data-sources\">Create the Book and Author data sources</a></li><li><a href=\"#adding-code-to-fetch-data\">Adding code to fetch data</a></li><li><a href=\"#running-our-first-query\">Running our first query</a><ul><li><a href=\"#enable-the-graphiql-playground\">Enable the GraphiQL Playground</a></li><li><a href=\"#boot-the-application\">Boot the application</a></li><li><a href=\"#run-the-query\">Run the query</a></li></ul></li><li><a href=\"#testing\">Testing</a></li>\n    </ul>\n  </div>\n  \n\n  <p>\n    Let's build a GraphQL Spring Application that will accept GraphQL requests at http://localhost:8080/graphql.\n  </p>\n\n    <h2 id=\"preparation\">\n      Preparation\n    </h2>\n\n  <p>\n    First let's navigate to https://start.spring.io. This service pulls in all the dependencies you need for an application and does most of the setup for you.<br>\n  </p>\n\n  <ul>\n    <li>Choose Maven and chose Java.Click&nbsp;</li><li>Dependencies and select Spring for GraphQL and Spring Web.</li><li><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: 1em; font-weight: var(--font-weight-normal);\">Click Generate.</span><br></li><li><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: 1em; font-weight: var(--font-weight-normal);\">Download the resulting ZIP file, which is an archive of a GraphQL application that is configured with your choices.</span><br></li><li>Unzip and open the Folder with your favorite IDE (IntelliJ recommended)</li>\n  </ul>\n\n    <h2 id=\"a-very-short-introduction-to-graphql\">\n      A very short introduction to GraphQL\n    </h2>\n\n  <p>\n    GraphQL is a query language to retrieve data from a server. It is an alternative to REST, SOAP, or gRPC. In the next Part we will query the details for a specific book from an online store backend.<br><br>This is an example request you can send to a GraphQL server to retrieve book details:\n  </p>\n<pre class=\" language-graphql\"><code>query bookDetails {\n  bookById(id: \"book-1\") {\n    id\n    name\n    pageCount\n    author {\n      firstName\n      lastName\n    }\n  }\n}</code></pre>\n\n  <p>\n    This GraphQL request says:\n  </p>\n\n  <ul>\n    <li>perform a query for a book with id \"book-1\"</li><li><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: 1em; font-weight: var(--font-weight-normal);\">for the book, return id, name, pageCount and author</span><br></li><li><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: 1em; font-weight: var(--font-weight-normal);\">for the author, return firstName and lastName</span><br></li>\n  </ul>\n\n  <p>\n    The response is in JSON. For example:<br>\n  </p>\n<pre class=\" language-json\"><code>{\n  \"bookById\": {\n    \"id\":\"book-1\",\n    \"name\":\"Effective Java\",\n    \"pageCount\":416,\n    \"author\": {\n      \"firstName\":\"Joshua\",\n      \"lastName\":\"Bloch\"\n    }\n  }\n}</code></pre>\n\n  <p>\n    An important feature of GraphQL is that it defines a schema language, and that it is statically typed. The server knows exactly what types of objects requests can query and what fields those objects contain. Furthermore, clients can introspect the server to ask for schema details.\n  </p>\n\n  <p class=\"msg msg--info\">\n    The word schema in this Post refers to a \"GraphQL Schema\", which is not related to other schemas like \"JSON Schema\" or \"Database Schema\".\n  </p>\n\n  <p>\n    The schema for the above query is:\n  </p>\n<pre class=\" language-graphql\"><code>type Query {\n    bookById(id: ID): Book\n}\n\ntype Book {\n    id: ID\n    name: String\n    pageCount: Int\n    author: Author\n}\n\ntype Author {\n    id: ID\n    firstName: String\n    lastName: String\n}</code></pre>\n\n  <p>\n    This Post will focus on how to implement a GraphQL server with this schema in Java.<br><br>We’ve barely scratched the surface of what’s possible with GraphQL. Further information can be found on the official GraphQL page.\n  </p>\n\n    <h2 id=\"our-example-api-getting-book-details\">\n      Our example API: getting book details\n    </h2>\n\n  <p>\n    These are the main steps to create a server with Spring for GraphQL:\n  </p>\n\n  <ol>\n    <li>Define a GraphQL schema</li><li>Implement the logic to fetch the actual data for a query<br></li>\n  </ol>\n\n  <p>\n    Our example app will be a simple API to get details for a specific book. It is not intended to be a comprehensive API.\n  </p>\n\n    <h2 id=\"schema\">\n      Schema\n    </h2>\n\n  <p>\n    In your Spring for GraphQL application prepared earlier, add a new file <em>schema.graphqls</em> to the <em>src/main/resources/graphql</em> folder with the following content:\n  </p>\n<pre class=\" language-graphql\"><code>type Query {\n    bookById(id: ID): Book\n}\n\ntype Book {\n    id: ID\n    name: String\n    pageCount: Int\n    author: Author\n}\n\ntype Author {\n    id: ID\n    firstName: String\n    lastName: String\n}</code></pre>\n\n  <p>\n    Every GraphQL schema has a top-level <em>Query</em> type, and the fields under it are the query operations exposed by the application. Here the schema defines one query called <em>bookById</em> that returns the details of a specific book.<br><br>It also defines the types <em>Book</em> with fields<em> id, name, pageCount</em> and <em>author</em>, and the type <em>Author</em> with fields <em>firstName</em> and <em>lastName</em>.<br>\n  </p>\n\n  <p class=\"msg msg--info\">\n    The Domain Specific Language used above to describe a schema is called the Schema Definition Language or SDL. For more details, see the GraphQL documentation.\n  </p>\n\n    <h2 id=\"source-of-the-data\">\n      Source of the data\n    </h2>\n\n  <p>\n    A key strength of GraphQL is that data can be sourced from anywhere. Data can come from a database, an external service, or a static in-memory list.<br><br>To simplify the demo here, book and author data will come from static lists inside their respective classes.\n  </p>\n\n    <h2 id=\"create-the-book-and-author-data-sources\">\n      Create the Book and Author data sources\n    </h2>\n\n  <p>\n    Let’s now create the <em>Book</em> and <em>Author</em> classes in the main application package, right next to <em>GraphQlServerApplication</em>. Use the following as their content:\n  </p>\n<pre class=\" language-java\"><code>package com.example.graphqlserver;\n\nimport java.util.Arrays;\nimport java.util.List;\n\npublic record Book (String id, String name, int pageCount, String authorId) {\n\n    private static List&lt;Book&gt; books = Arrays.asList(\n            new Book(\"book-1\", \"Effective Java\", 416, \"author-1\"),\n            new Book(\"book-2\", \"Hitchhiker's Guide to the Galaxy\", 208, \"author-2\"),\n            new Book(\"book-3\", \"Down Under\", 436, \"author-3\")\n    );\n\n    public static Book getById(String id) {\n        return books.stream()\n\t\t\t\t.filter(book -&gt; book.id().equals(id))\n\t\t\t\t.findFirst()\n\t\t\t\t.orElse(null);\n    }\n}</code></pre>\n<pre class=\" language-java\"><code>package com.example.graphqlserver;\n\nimport java.util.Arrays;\nimport java.util.List;\n\npublic record Author (String id, String firstName, String lastName) {\n\n    private static List&lt;Author&gt; authors = Arrays.asList(\n            new Author(\"author-1\", \"Joshua\", \"Bloch\"),\n            new Author(\"author-2\", \"Douglas\", \"Adams\"),\n            new Author(\"author-3\", \"Bill\", \"Bryson\")\n    );\n\n    public static Author getById(String id) {\n        return authors.stream()\n\t\t\t\t.filter(author -&gt; author.id().equals(id))\n\t\t\t\t.findFirst()\n\t\t\t\t.orElse(null);\n    }\n}</code></pre>\n\n    <h2 id=\"adding-code-to-fetch-data\">\n      Adding code to fetch data\n    </h2>\n\n  <p>\n    Spring for GraphQL provides an annotation-based programming model. With controller annotated methods, we can declare how to fetch the data for specific GraphQL fields.<br><br>Add the following to <em>BookController.java</em> in the main application package, next to Book and Author:\n  </p>\n<pre class=\" language-java\"><code>package com.example.graphqlserver;\n\nimport org.springframework.graphql.data.method.annotation.Argument;\nimport org.springframework.graphql.data.method.annotation.QueryMapping;\nimport org.springframework.graphql.data.method.annotation.SchemaMapping;\nimport org.springframework.stereotype.Controller;\n\n@Controller\npublic class BookController {\n    @QueryMapping\n    public Book bookById(@Argument String id) {\n        return Book.getById(id);\n    }\n\n    @SchemaMapping\n    public Author author(Book book) {\n        return Author.getById(book.authorId());\n    }\n}</code></pre>\n\n  <p>\n    By defining a method named <em>bookById</em> annotated with <em>@QuerMapping</em>, this controller declares how to fetch a <em>Book</em> as defined under the Query type. The query field is determined from the method name, but can also be declared on the annotation itself.\n  </p>\n\n  <p class=\"msg msg--info\">\n    Spring for GraphQL uses RuntimeWiring.Builder that registers each such controller method as a GraphQL Java graphql.schema.DataFetcher. A DataFetcher provides the logic to fetch the data for a query or for any schema field. The Spring Boot starter for GraphQL has auto-configurations that automates this registration.\n  </p>\n\n  <p>\n    In the GraphQL Java engine, <em>DataFetchingEnvironment</em> provides access to a map of field-specific argument values. Use the <em>@Argument</em> annotation to have an argument bound to a target object and injected into the controller method. By default, the method parameter name is used to look up the argument, but can also be specified on the annotation itself.<br><br>This <em>bookById</em> method defines how to get a specific <em>Book</em>, but does not take care of fetching the related <em>Author</em>. If the request asks for the author information, GraphQL Java will need to fetch this field.<br><br>The <em>@SchemaMapping</em> annotation maps a handler method to a field in the GraphQL schema and declares it to be the <em>DataFetcher</em> for that field. The field name defaults to the method name, and the type name defaults to the simple class name of the source/parent object injected into the method. In this example, the field defaults to <em>author</em> and the type defaults to <em>Book</em>.<br><br>For more, see the <a href=\"https://docs.spring.io/spring-graphql/reference/controllers.html\" target=\"_blank\" rel=\"nofollow noopener\">documentation for the Spring for GraphQL annotated controller feature</a>.<br><br>Now let’s run our first query.\n  </p>\n\n    <h2 id=\"running-our-first-query\">\n      Running our first query\n    </h2>\n\n    <h3 id=\"enable-the-graphiql-playground\">\n      Enable the GraphiQL Playground\n    </h3>\n\n  <p>\n    GraphiQL is a useful visual interface for writing and executing queries, and much more. Enable GraphiQL by adding this config to the <em>application.properties</em> file.\n  </p>\n<pre class=\" language-java\"><code>spring.graphql.graphiql.enabled=true</code></pre>\n\n    <h3 id=\"boot-the-application\">\n      Boot the application\n    </h3>\n\n  <p>\n    Start your Spring application. Navigate to http://localhost:8080/graphiql.\n  </p>\n\n    <h3 id=\"run-the-query\">\n      Run the query\n    </h3>\n\n  <p>\n    Type in the query and click the play button at the top of the window.<br>\n  </p>\n<pre class=\" language-graphql\"><code>query bookDetails {\n  bookById(id: \"book-1\") {\n    id\n    name\n    pageCount\n    author {\n      id\n      firstName\n      lastName\n    }\n  }\n}</code></pre>\n\n  <p>\n    You should see a response like this:\n  </p>\n<pre class=\" language-json\"><code>{\n  \"data\": {\n    \"bookById\": {\n      \"id\": \"book-1\",\n      \"name\": \"Effective Java\",\n      \"pageCount\": 416,\n      \"author\": {\n        \"id\": \"author-1\",\n        \"firstName\": \"Joshua\",\n        \"lastName\": \"Bloch\"\n      }\n    }\n  }\n}</code></pre>\n\n  <p>\n    Congratulations, you have built a GraphQL service and executed your first query! With the help of Spring for GraphQL, you were able to achieve this with only a few lines of code.\n  </p>\n\n    <h2 id=\"testing\">\n      Testing\n    </h2>\n\n  <p>\n    Spring for GraphQL provides helpers for GraphQL testing in the <em>spring-graphql-test</em> artifact. We have already included this artifact as part of the project generated by Spring Initializr.<br><br>Thoroughly testing a GraphQL service requires tests with different scopes. In this tutorial, we will write a <em>@GraphQlTest</em> slice test, which focuses on a single controller. There are other helpers to assist with full end-to-end integration tests and focused server side tests. For the full details, see the Spring for GraphQL Testing documentation and Auto-configured Spring for GraphQL tests in the Spring Boot documentation.<br><br>Let’s write a controller slice test that verifies the same <em>bookDetails</em> query requested in the GraphiQL playground a few moments ago.<br><br>Add the following to a test file <em>BookControllerTests.java</em>. Save this file in a location within the <em>src/test/java/com/example/graphqlserver/</em> folder.\n  </p>\n<pre class=\" language-java\"><code>package com.example.graphqlserver;\n\nimport org.junit.jupiter.api.Test;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.autoconfigure.graphql.GraphQlTest;\nimport org.springframework.graphql.test.tester.GraphQlTester;\n\n@GraphQlTest(BookController.class)\npublic class BookControllerTests {\n\n    @Autowired\n    private GraphQlTester graphQlTester;\n\n    @Test\n    void shouldGetFirstBook() {\n        this.graphQlTester\n\t\t\t\t.documentName(\"bookDetails\")\n\t\t\t\t.variable(\"id\", \"book-1\")\n                .execute()\n                .path(\"bookById\")\n                .matchesJson(\"\"\"\n                    {\n                        \"id\": \"book-1\",\n                        \"name\": \"Effective Java\",\n                        \"pageCount\": 416,\n                        \"author\": {\n                          \"firstName\": \"Joshua\",\n                          \"lastName\": \"Bloch\"\n                        }\n                    }\n                \"\"\");\n    }\n}\n</code></pre>\n\n  <p>\n    This test refers to a GraphQL query similar to what we used in the GraphiQL Playground. It’s parameterized with an <em>$id</em> to make it reusable. Add this query in a <em>bookDetails</em>.<em>graphql</em> file located in <em>src/test/resources/graphql-test.</em>\n  </p>\n<pre class=\" language-graphql\"><code>query bookDetails($id: ID) {\n    bookById(id: $id) {\n        id\n        name\n        pageCount\n        author {\n            id\n            firstName\n            lastName\n        }\n    }\n}</code></pre>\n\n  <p>\n    Run the test and verify that the result is identical to the GraphQL query manually requested in the GraphiQL Playground.<br><br>The <em>@GraphQlTest</em> annotation is useful for writing controller slice tests, which are focused on a single controller. <em>@GraphQlTest </em>auto-configures the Spring for GraphQL infrastructure, without any transport nor server being involved. Automatic configuration enables us to write tests faster by skipping boilerplate code. As this is a focused slice test, only a limited number of beans are scanned including <em>@Controller</em> and <em>RuntimeWiringConfigurer.</em><br><br><em>GraphQlTester</em> is a contract that declares a common workflow for testing GraphQL requests, independent of transport. In our test, we provide a document with <em>documentName</em> with the required variables, then <em>execute</em> the request. We then select a part of the response with its JSON path and assert that the JSON at this location matches the expected result.<br><br>Congratulations! In this tutorial you built a GraphQL service, ran your first query, and wrote your first GraphQL test!<br>\n  </p>\n\n  <p>\n    \n  </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "spring-framework",
                   "spring",
                   "software development",
                   "java",
                   "graphql",
                   "api"
            ],
            "date_published": "2024-01-22T21:19:17+01:00",
            "date_modified": "2024-01-24T20:15:11+01:00"
        },
        {
            "id": "https://www.finecloud.ch/working-efficient-within-different-directories-in-a-linux-shell.html",
            "url": "https://www.finecloud.ch/working-efficient-within-different-directories-in-a-linux-shell.html",
            "title": "Working efficient within different directories in a Linux Shell",
            "summary": "Lets Suppose you need to perform a certain kind of work in all of these directories:&nbsp; You might know about the \"cd\" command. But isn't it annoying if you need to use and retype a lot of Commands, like for example: $ cd ~/Work/Projects/Web/src $&hellip;",
            "content_html": "\n  <p>\n    \n  </p>\n\n  <div class=\"post__toc\">\n    <h3>TOC</h3>\n    <ul>\n      <ul><li><a href=\"#directory-stack\">Directory stack</a></li><li><a href=\"#push-a-directory-onto-the-stack\">Push a directory onto the stack</a></li><li><a href=\"#view-a-directory-stack\">View a directory stack</a></li><li><a href=\"#pop-a-directory-from-the-stack\">Pop a directory from the stack</a></li><li><a href=\"#swap-directories-on-the-stack\">Swap directories on the stack</a></li><li><a href=\"#turn-a-mistaken-cd-into-a-pushd\">Turn a mistaken cd into a pushd</a></li><li><a href=\"#go-deeper-into-the-stack\">Go deeper into the stack</a></li></ul>\n    </ul>\n  </div>\n  \n\n  <p>\n    Lets Suppose you need to perform a certain kind of work in all of these directories:&nbsp;\n  </p>\n\n  <ul>\n    <li>/var/www/html</li><li>/etc/apache2</li><li>/etc/ssl/certs</li><li>~/Work/Projects/Web/src</li>\n  </ul>\n\n  <p>\n    You might know about the \"cd\" command. But isn't it annoying if you need to use and retype a lot of Commands, like for example:\n  </p>\n<pre class=\" language-bash\"><code>$ cd ~/Work/Projects/Web/src\n$ cd /var/www/html\n$ cd /etc/apache2\n$ cd ~/Work/Projects/Web/src\n$ cd /etc/ssl/certs</code></pre>\n\n  <p>\n    But there is a much better and more efficient way. Take&nbsp;advantage of a shell feature called a directory stack.\n  </p>\n\n    <h3 id=\"directory-stack\">\n      Directory stack\n    </h3>\n\n  <p>\n    You can manipulate the stack by performing two operations called <em>pushing</em> and <em>popping</em>.\n  </p>\n\n  <ul>\n    <li>Pushing a&nbsp; directory adds it to the beginning of the list, which is traditionally called the top of the stack.</li><li>Popping removes the topmost directory from the stack.</li><li>Initially, the stack contains only your current directory, but you can add (push) and remove (pop) directories and rapidly cd among them.</li>\n  </ul>\n\n    <h3 id=\"push-a-directory-onto-the-stack\">\n      Push a directory onto the stack\n    </h3>\n\n  <p>\n    The command pushd (short for “push directory”) does all of the following:\n  </p>\n\n  <ol>\n    <li>Adds a given directory to the top of the stack</li><li>Performs a cd to that directory</li><li>Prints the stack from top to bottom for your reference</li>\n  </ol>\n\n  <p>\n    Let's build a directory stack of four directories, pushing them onto the stack one at a time:\n  </p>\n<pre class=\" language-bash\"><code>$ pwd\n/home/john/Work/Projects/Web/src\n$ pushd /var/www/html\n/var/www/html ~/Work/Projects/Web/src\n$ pushd /etc/apache2\n/etc/apache2 /var/www/html ~/Work/Projects/Web/src\n$ pushd /etc/ssl/certs\n/etc/ssl/certs /etc/apache2 /var/www/html\n~/Work/Projects/Web/src\n$ pwd\n/etc/ssl/certs</code></pre>\n\n  <p>\n    The shell prints the stack after each pushd operation. The current directory is the leftmost (top) directory.\n  </p>\n\n    <h3 id=\"view-a-directory-stack\">\n      View a directory stack\n    </h3>\n\n  <p>\n    Print a shell’s directory stack with the dirs command. It does not modify the stack:\n  </p>\n<pre class=\" language-bash\"><code>$ dirs -p\n/etc/ssl/certs\n/etc/apache2\n/var/www/html\n~/Work/Projects/Web/src</code></pre>\n\n  <p>\n    you can leave out the -p if you don't want to have each of them at it's own line. Or you can pass a -v to see them numbered:\n  </p>\n<pre class=\" language-bash\"><code>$ dirs -v\n0 /etc/ssl/certs\n1 /etc/apache2\n2 /var/www/html\n3 ~/Work/Projects/Web/src\n</code></pre>\n\n    <h3 id=\"pop-a-directory-from-the-stack\">\n      Pop a directory from the stack\n    </h3>\n\n  <p>\n    The popd command (“pop directory”) is the reverse of pushd. It does all of the following:\n  </p>\n\n  <ol>\n    <li>Removes one directory from the top of the stack</li><li>Performs a cd to the new top directory</li><li>Prints the stack from top to bottom for your reference<br></li>\n  </ol>\n\n  <p>\n    For example, if your stack has four directories:\n  </p>\n<pre class=\" language-bash\"><code>$ dirs\n/etc/ssl/certs /etc/apache2 /var/www/html\n~/Work/Projects/Web/src\n</code></pre>\n\n  <p>\n    then repeatedly running popd will traverse these directories from top to bottom:\n  </p>\n<pre class=\" language-bash\"><code>$ popd\n/etc/apache2 /var/www/html ~/Work/Projects/Web/src\n$ popd\n/var/www/html ~/Work/Projects/Web/src\n$ popd\n~/Work/Projects/Web/src\n$ popd\nbash: popd: directory stack empty\n$ pwd\n~/Work/Projects/Web/src</code></pre>\n\n    <h3 id=\"swap-directories-on-the-stack\">\n      Swap directories on the stack\n    </h3>\n\n  <p>\n    Now that you can build and empty the directory stack, let’s focus on practical use cases. <em>pushd</em> with no arguments swaps the top two directories in the stack and navigates to the new top directory. Let’s jump between /etc/apache2 and your work directory several times by simply running <em>pushd</em>. See how the third directory /var/www/html remains in the stack as the first two directories swap positions:\n  </p>\n<pre class=\" language-bash\"><code>$ dirs\n/etc/apache2 ~/Work/Projects/Web/src /var/www/html\n$ pushd\n~/Work/Projects/Web/src /etc/apache2 /var/www/html\n$ pushd\n/etc/apache2 ~/Work/Projects/Web/src /var/www/html\n$ pushd\n~/Work/Projects/Web/src /etc/apache2 /var/www/html</code></pre>\n\n  <p>\n    <em>pushd</em> behaves similarly to the <em>cd -</em> command, toggling between two directories, but it does not have the limitation of remembering just one directory.\n  </p>\n\n    <h3 id=\"turn-a-mistaken-cd-into-a-pushd\">\n      Turn a mistaken cd into a pushd\n    </h3>\n\n  <p>\n    Suppose you are jumping among several directories with pushd and you accidentally run cd instead and lose a directory:\n  </p>\n<pre class=\" language-bash\"><code>$ dirs\n~/Work/Projects/Web/src /var/www/html /etc/apache2\n$ cd /etc/ssl/certs\n$ dirs\n/etc/ssl/certs /var/www/html /etc/apache2</code></pre>\n\n  <p>\n    Oops, the accidental cd command replaced ~/Work/Projects/Web/src in the stack with /etc/ssl/certs. But don’t worry. You can add the missing directory back to the stack without typing its long path. Just run <em>pushd</em> twice, once with a dash argument and once without:\n  </p>\n<pre class=\" language-bash\"><code>$ pushd -\n~/Work/Projects/Web/src /etc/ssl/certs /var/www/html\n/etc/apache2\n$ pushd\n/etc/ssl/certs ~/Work/Projects/Web/src /var/www/html\n/etc/apache2</code></pre>\n\n  <p>\n    Why this works:\n  </p>\n\n  <ul>\n    <li>The first pushd returns to your shell’s previous directory, ~/Work/Projects/Web/src, and pushes it onto the stack. pushd, like cd, accepts a dash as an argument to mean “go back to my previous directory.”</li><li>The second pushd command swaps the top two directories, bringing you back to /etc/ssl/certs. The end result is that you’ve restored ~/Work/Projects/Web/src to the second position in the stack, exactly where it would have been if you hadn’t made your mistake.</li>\n  </ul>\n\n    <h3 id=\"go-deeper-into-the-stack\">\n      Go deeper into the stack\n    </h3>\n\n  <p>\n    What if you want to cd between directories in the stack other than the top two? <em>pushd</em> and <em>popd</em> accept a positive or negative integer argument to operate further into the stack. The command:\n  </p>\n<pre class=\" language-bash\"><code>$ pushd +N</code></pre>\n\n  <p>\n    shifts N directories from the top of the stack to the bottom and then&nbsp;performs a cd to the new top directory. A negative argument (-N) shifts directories in the opposite direction, from the bottom to the top, before performing the cd.\n  </p>\n<pre class=\" language-bash\"><code>$ dirs\n/etc/ssl/certs ~/Work/Projects/Web/src /var/www/html\n/etc/apache2\n$ pushd +1\n~/Work/Projects/Web/src /var/www/html /etc/apache2\n/etc/ssl/certs\n$ pushd +2\n/etc/apache2 /etc/ssl/certs ~/Work/Projects/Web/src\n/var/www/html</code></pre>\n\n  <p>\n    In this manner, you can jump to any other directory in the stack with a simple command. If your stack is long, however, it may be difficult to judge a directory’s numeric position by eye. So, print the numeric position of each directory with dirs -v, as you did in “View a<br>directory stack”:\n  </p>\n<pre class=\" language-bash\"><code>$ dirs -v\n0 /etc/apache2\n1 /etc/ssl/certs\n2 ~/Work/Projects/Web/src\n3 /var/www/html</code></pre>\n\n  <p>\n    To shift /var/www/html to the top of the stack (and make it your current directory), run pushd +3. To jump to the directory at the bottom of the stack, run pushd -0&nbsp;(dash zero):\n  </p>\n<pre class=\" language-bash\"><code>$ dirs\n/etc/apache2 /etc/ssl/certs ~/Work/Projects/Web/src\n/var/www/html\n$ pushd -0\n/var/www/html /etc/apache2 /etc/ssl/certs\n~/Work/Projects/Web/src</code></pre>\n\n  <p>\n    You also can remove directories from the stack beyond the top directory, using popd with a numeric argument. The command:\n  </p>\n<pre class=\" language-bash\"><code>$ popd +N</code></pre>\n\n  <p>\n    removes the directory in position N from the stack, counting down from the top. A negative argument (-N) counts up from the bottom of the stack instead. Counting begins at zero, so popd +1 removes the second directory from the top:\n  </p>\n<pre class=\" language-bash\"><code>$ dirs\n/var/www/html /etc/apache2 /etc/ssl/certs\n~/Work/Projects/Web/src\n$ popd +1\n/var/www/html /etc/ssl/certs ~/Work/Projects/Web/src\n$ popd +2\n/var/www/html /etc/ssl/certs</code></pre>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "shell",
                   "linux",
                   "bash"
            ],
            "date_published": "2023-12-10T13:52:14+01:00",
            "date_modified": "2023-12-11T07:36:08+01:00"
        },
        {
            "id": "https://www.finecloud.ch/microservices.html",
            "url": "https://www.finecloud.ch/microservices.html",
            "title": "Microservices",
            "summary": "This Post is a summary of the famous Article about Microservices: https://martinfowler.com/articles/microservices.html The text discusses the concept of \"Microservice Architecture,\" which is an approach to designing software applications as a suite of independently deployable services. It highlights that there is no precise definition but outlines&hellip;",
            "content_html": "\n  <p>\n    This Post is a summary of the famous Article about Microservices: https://martinfowler.com/articles/microservices.html<br>\n  </p>\n\n    <h2 id=\"a-definition-of-this-new-architectural-termlessbrgreater\">\n      a definition of this new architectural term<br>\n    </h2>\n\n  <p>\n    The text discusses the concept of \"Microservice Architecture,\" which is an approach to designing software applications as a suite of independently deployable services. It highlights that there is no precise definition but outlines common characteristics such as organization around business capabilities, automated deployment, decentralized control of languages and data, and the use of lightweight communication mechanisms like HTTP. Microservices are contrasted with monolithic architecture, where applications are built as a single unit. The text emphasizes that microservices provide advantages like independent deployment, scalability, and modular structure, making it increasingly appealing for building enterprise applications. The microservice style is not claimed to be innovative but is considered beneficial for software development.<br>\n  </p>\n\n    <h2 id=\"componentization-via-services\">\n      Componentization via Services\n    </h2>\n\n  <p>\n    The text discusses the evolution of component-based software development in the software industry. It highlights the distinction between libraries and services as components, with a focus on microservice architectures. The main point is that components, in this context, are units of software that are independently replaceable and upgradeable. The text also explains that services, as out-of-process components, offer advantages in terms of independent deployability and explicit component interfaces. However, it acknowledges that using services can have downsides, such as increased overhead for remote calls and challenges in changing the allocation of responsibilities between components. The text concludes by noting that services can consist of multiple processes that are developed and deployed together.\n  </p>\n\n    <h2 id=\"organized-around-business-capabilities\">\n      Organized around Business Capabilities\n    </h2>\n\n  <p>\n    The text mentions how companies like comparethemarket.com organize themselves using cross-functional teams responsible for building and operating individual services. The text also touches upon Conway's Law, emphasizing that an organization's system design mirrors its communication structure.\n  </p>\n\n  <p>\n    The key point is the contrast between the traditional approach of splitting teams based on technology layers (UI, server-side, database) and the microservices approach, which focuses on dividing services around business capabilities. Microservices encourage cross-functional teams with expertise in user experience, database, and project management. The text suggests that large monolithic applications can also benefit from modularization based on business capabilities but cautions against excessive complexity and recommends maintaining clear team boundaries, which is facilitated by the more explicit separation in service components.\n  </p>\n\n    <h2 id=\"products-not-projects\">\n      Products not Projects\n    </h2>\n\n  <p>\n    The text discusses the difference in development approaches between traditional project-based models and the microservices approach. In the traditional model, software development is seen as a project with a defined end, after which it's handed over to a maintenance organization. Microservice proponents advocate for teams to own a product throughout its entire lifecycle, emphasizing the \"you build, you run it\" philosophy popularized by Amazon.<br><br>This approach encourages developers to be responsible for their software in production, fostering closer interaction with how it behaves and its users. The text highlights that this product-oriented mentality aligns with the focus on business capabilities, emphasizing an ongoing relationship where software continuously enhances business capabilities.<br><br>It also notes that while this approach can be applied to monolithic applications, the smaller granularity of services in microservices makes it easier to establish personal relationships between service developers and their users.\n  </p>\n\n    <h2 id=\"smart-endpoints-and-dumb-pipes\">\n      Smart endpoints and dumb pipes\n    </h2>\n\n  <p>\n    The text starts by mentioning the traditional approach, exemplified by Enterprise Service Bus (ESB), where significant intelligence is embedded in the communication mechanism itself, allowing for sophisticated message routing, choreography, and transformation.<br><br>In contrast, the microservices community prefers a different approach: \"smart endpoints and dumb pipes.\" Microservices are designed to be highly decoupled and cohesive, with each service owning its domain logic. These services act as filters, receiving requests, applying logic, and producing responses. They utilize simple RESTish protocols and emphasize two common protocols: HTTP request-response with resource APIs and lightweight messaging. The principles of the World Wide Web and Unix underlie these protocols.<br><br>The text also highlights that, in microservices, the infrastructure used for messaging is typically simple and serves as a message router only, with the intelligence residing in the end points. The key challenge in transitioning from a monolithic architecture to microservices is changing the communication pattern. The text advises against a naive conversion to remote procedure calls (RPC) as it can lead to inefficient and \"chatty\" communications, advocating for a coarser-grained approach instead.\n  </p>\n\n    <h2 id=\"decentralized-governance\">\n      Decentralized Governance\n    </h2>\n\n  <p>\n    The text highlights the limitations of centralized governance, such as the tendency to standardize on single technology platforms. In contrast, microservices allow for a more flexible approach, enabling teams to choose the right tools and technologies for specific components.<br><br>Microservice teams focus on producing practical tools and sharing them with other developers, often following open-source practices. This approach encourages flexibility in solving similar problems while still valuing service contracts. The text mentions patterns like Tolerant Reader and Consumer-Driven Contracts that help service contracts evolve independently, with tools enabling automated contract verification during the build process.<br><br>Furthermore, the text discusses the \"build it / run it\" ethos popularized by Amazon, where development teams are responsible for operating the software they build, emphasizing the decentralization of responsibility. This approach, exemplified by companies like Netflix, fosters a focus on code quality and contrasts sharply with traditional centralized governance models.\n  </p>\n\n    <h2 id=\"decentralized-data-management\">\n      Decentralized Data Management\n    </h2>\n\n  <p>\n    The text points out that decentralized data management leads to differences in the conceptual models of systems, particularly when integrating across a large enterprise. This divergence in views can even occur within applications, especially when they are divided into separate components, which can be understood using the concept of Bounded Context from Domain-Driven Design.\n  </p>\n\n  <p>\n    Microservices further decentralize data storage decisions by allowing each service to manage its own database, known as Polyglot Persistence. This contrasts with the monolithic approach of a single logical database for persistent data.<br><br>In terms of data updates, traditional monolithic applications often use transactions to guarantee consistency when updating multiple resources. However, microservices prioritize transactionless coordination between services due to the challenges of implementing distributed transactions. This approach acknowledges that consistency may be eventual and addresses problems with compensating operations.<br><br>The text also highlights that managing inconsistencies aligns with business practices where businesses often tolerate a degree of inconsistency to respond quickly to demand, with the ability to reverse processes to address mistakes. This trade-off is considered worthwhile as long as the cost of fixing errors is lower than the cost of lost business under greater consistency.\n  </p>\n\n    <h2 id=\"infrastructure-automation\">\n      Infrastructure Automation\n    </h2>\n\n  <p>\n    The text points out that teams building microservices often have experience with Continuous Delivery and Continuous Integration, both of which heavily rely on infrastructure automation.<br><br>The text highlights that infrastructure automation plays a crucial role in building confidence in software by running automated tests and automating deployment to different environments. It mentions that once the path to production for a monolithic application is automated, deploying more applications becomes less daunting. The goal of Continuous Delivery is to make deployment a routine and uneventful process.\n  </p>\n\n  <p>\n    The text also acknowledges that while the deployment process may not differ significantly between monolithic applications and microservices, the operational landscape for each can be notably distinct, suggesting that infrastructure automation is key to managing microservices effectively in production.\n  </p>\n\n    <h2 id=\"design-for-failure\">\n      Design for failure\n    </h2>\n\n  <p>\n    The text points out that using services as components means applications need to be resilient and capable of handling service failures. Unlike monolithic designs, microservices introduce complexity in managing failures gracefully. To address this, microservice teams place a strong emphasis on monitoring and detecting failures in real-time.<br><br>The text mentions Netflix's \"Simian Army,\" which intentionally induces service and datacenter failures during the working day to test the application's resilience and monitoring capabilities. While monolithic architectures can also have sophisticated monitoring, it's less common.<br><br>Microservices require the ability to quickly detect and, if possible, automatically restore service. They rely on real-time monitoring, checking both architectural and business-relevant metrics. Semantic monitoring helps spot issues, especially in a microservices architecture where choreography and event collaboration can lead to emergent behavior, which may not always be desirable.<br><br>The text concludes that microservice teams expect to have sophisticated monitoring and logging setups for each individual service, including dashboards for status, operational and business metrics, and details on circuit breaker status, throughput, and latency. Transparency and quick detection of failures are critical in a microservices environment.\n  </p>\n\n    <h2 id=\"evolutionary-design\">\n      Evolutionary Design\n    </h2>\n\n  <p>\n    Microservice practitioners often come from an evolutionary design background and view service decomposition as a tool to enable application developers to control changes without slowing down the development process.<br><br>The key principle behind microservices is the notion of independent replacement and upgradeability. This means looking for points in the application where components can be rewritten without affecting their collaborators. Some microservice groups take this a step further by expecting that many services will be replaced rather than evolved in the long term.<br><br>The text provides examples of applications that started as monoliths but evolved in a microservice direction. These microservices are particularly useful for adding temporary features or services that are discarded after a short period, such as specialized pages for sporting events.<br><br>It emphasizes the importance of modular design based on the pattern of change, where components that change together should be in the same module. Microservices allow for more granular release planning, as changes only require redeploying the specific service(s) that were modified. However, this introduces the challenge of ensuring that changes to one service do not break its consumers, and the text suggests that versioning should be a last resort, with services designed to be tolerant of changes in their suppliers.\n  </p>\n\n    <h2 id=\"are-microservices-the-future\">\n      Are Microservices the Future?\n    </h2>\n\n  <p>\n    The concept of microservices is a promising architectural style for enterprise applications but the text emphasizes that it's still too early to make definitive judgments about its long-term impact. Several well-known companies, including Amazon, Netflix, The Guardian, and others, have adopted microservices. However, the text acknowledges that the full consequences of architectural decisions may take several years to become evident.<br><br>It highlights some challenges and potential concerns associated with microservices, such as the difficulty of defining service boundaries, the increased complexity in coordinating interface changes, and the risk of moving complexity from within a component to the connections between components. Additionally, the success of microservices can be influenced by team skill, and it remains to be seen how less skillful teams would fare with this approach.<br><br>The text suggests a reasonable argument of starting with a monolith and splitting it into microservices when necessary, while maintaining modularity from the beginning. It concludes with cautious optimism, acknowledging that the microservices style holds promise, but the ultimate outcomes will depend on how well it addresses these challenges in practice.\n  </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "software development",
                   "microservices"
            ],
            "date_published": "2023-10-28T14:08:02+02:00",
            "date_modified": "2023-10-28T14:08:12+02:00"
        },
        {
            "id": "https://www.finecloud.ch/the-concept-of-api-contracts.html",
            "url": "https://www.finecloud.ch/the-concept-of-api-contracts.html",
            "title": "The Concept of API Contracts",
            "summary": "What is it about? We define an API contract as a formal agreement between a software provider and a consumer that abstractly communicates how to interact with each other. This contract defines how API providers and consumers interact, what data exchanges looks like, and how&hellip;",
            "content_html": "\n    <h2 id=\"what-is-it-about\">\n      What is it about?\n    </h2>\n\n  <p>\n    We define an API contract as a formal agreement between a software provider and a consumer that abstractly communicates how to interact with each other. This contract defines how API providers and consumers interact, what data exchanges looks like, and how to communicate success and failure cases.<br><br>The provider and consumers do not have to share the same programming language, only the same API contracts. Lets imagine that we need to design a API for a Family Cash Card Web Application. Let’s assume that currently there's one contract between the Cash Card service and all services using it. Below is an example of that first API contract.\n  </p>\n<pre class=\" language-json\"><code>Request\n  URI: /cashcards/{id}\n  HTTP Verb: GET\n  Body: None\n\nResponse:\n  HTTP Status:\n    200 OK if the user is authorized and the Cash Card was successfully retrieved\n    403 UNAUTHORIZED if the user is unauthenticated or unauthorized\n    404 NOT FOUND if the user is authenticated and authorized but the Cash Card cannot be found\n  Response Body Type: JSON\n  Example Response Body:\n    {\n      \"id\": 99,\n      \"amount\": 123.45\n    }</code></pre>\n\n    <h2 id=\"why-are-api-contracts-important\">\n      Why Are API Contracts Important?\n    </h2>\n\n  <p>\n    API contracts are important because they communicate the behavior of a REST API. They provide specific details about the data being serialized (or deserialized) for each command and parameter being exchanged. The API contracts are written in such a way that can be easily translated into API provider and consumer functionality, and corresponding automated tests.\n  </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "software development",
                   "api"
            ],
            "date_published": "2023-09-23T13:52:33+02:00",
            "date_modified": "2023-09-23T13:54:08+02:00"
        },
        {
            "id": "https://www.finecloud.ch/terraform-tips-and-tricks-2.html",
            "url": "https://www.finecloud.ch/terraform-tips-and-tricks-2.html",
            "title": "Terraform Tips and Tricks",
            "summary": "module \"zland\" { source = \"git::ssh//git@gitlab.com/zland/module.git\" version = \"1.0.5\" servers = 3 } Module Output Values resource \"aws_instance\" \"appserver\" { #... instance = module.servers.instance_ids } Since the resources defined in a module are encapsulated, a calling module cannot access their attributes directly. Instead, the child&hellip;",
            "content_html": "\n  <p>\n    <br>\n  </p>\n\n  <div class=\"post__toc\">\n    <h3>Table of contents</h3>\n    <ul>\n      <li><a href=\"#facts-about-remote-state\">Facts about Remote State</a></li><li><a href=\"#remote-state-storage-support\">Remote State Storage support</a></li><li><a href=\"#separate-environments\">Separate Environments</a></li><li><a href=\"#use-modules\">Use Modules</a></li><li><a href=\"#arguments-to-use-with-modules\">Arguments to use with Modules</a></li><li><a href=\"#module-output-valueslessbrgreater\">Module Output Values<br></a><ul><li><a href=\"#create-a-custom-module-example\">Create a custom Module (Example)</a></li></ul></li><li><a href=\"#dont-repeat-yourself\">Don’t Repeat Yourself</a></li><li><a href=\"#3-things-to-use-to-keep-it-dry\">3 Things to Use to Keep It DRY</a><ul><li><a href=\"#conditional-example\">Conditional Example</a><ul><li><a href=\"#the-create_bucketfalse-conditional\">The create_bucket=false Conditional</a></li><li><a href=\"#the-create_buckettrue-conditional\">The create_bucket=true Conditional</a></li></ul></li></ul></li><li><a href=\"#use-null_resource\">Use null_resource</a><ul><li><a href=\"#example-null_resource\">Example null_resource</a></li></ul></li><li><a href=\"#use-functions\">Use Functions</a><ul><li><a href=\"#the-format-function\">The format Function</a></li><li><a href=\"#the-matchkeys-function\">The matchkeys Function</a></li><li><a href=\"#the-element-function\">The element Function</a></li></ul></li><li><a href=\"#test-your-code\">Test Your Code</a><ul><li><a href=\"#other-testing-tools\">Other Testing Tools</a></li></ul></li>\n    </ul>\n  </div>\n  \n\n    <h2 id=\"facts-about-remote-state\">\n      Facts about Remote State\n    </h2>\n\n  <ul>\n    <li>Remote state is not the default; you must specify which backend to use and configure it to be used.</li><li>Remote state can be used by multiple team members. Terraform will write state data to a remote data store that users with access can use so there aren’t multiple state files.</li><li>Remote state uses a backend, which is configured in your configuration’s root module.</li><li>Remote state allows you to share output values with other configurations. Those configurations can then consume the exposed outputs in additional configurations.</li>\n  </ul>\n\n    <h2 id=\"remote-state-storage-support\">\n      Remote State Storage support\n    </h2>\n\n  <ul>\n    <li>Terraform Cloud</li><li>HashiCorp Consul</li><li>Amazon S3</li><li>Azure Blob Storage</li><li>Google Cloud Storage</li><li>Alibaba Cloud OSS</li><li>...and more</li>\n  </ul>\n\n    <h2 id=\"separate-environments\">\n      Separate Environments\n    </h2>\n\n  <ol>\n    <li>It is good practice to separate your Terraform configurations per environment.</li><li>Separate environments help with code organization, as well as allowing for better and easier CI and automation integration.</li><li>Implementing a one-folder-per-environment pattern lets you copy and paste Terraform code from one folder to another. This, used with variables, allows you to quickly change only what is needed per environment.</li>\n  </ol>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://www.finecloud.ch/media/posts/92/Screenshot-2023-09-15-at-21.25.59.png\" height=\"620\" width=\"1432\" alt=\"\"  sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-15-at-21.25.59-xs.png 300w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-15-at-21.25.59-sm.png 480w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-15-at-21.25.59-md.png 768w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-15-at-21.25.59-lg.png 1024w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-15-at-21.25.59-xl.png 1360w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-15-at-21.25.59-2xl.png 1600w\">\n      \n    </figure>\n\n    <h2 id=\"use-modules\">\n      Use Modules\n    </h2>\n\n  <ol>\n    <li>Modules are containers for multiple resources that are used together.</li><li>Every Terraform configuration contains at least one module.</li><li>Modules can call other modules. This lets you include a module’s resources in a configuration in a concise way.</li><li>Modules can be called multiple times, either in the same Terraform configuration or in separate ones. This allows for resource configurations to be packaged and reused.</li>\n  </ol>\n\n    <h2 id=\"arguments-to-use-with-modules\">\n      Arguments to use with Modules\n    </h2>\n\n  <ul>\n    <li>source: This argument is mandatory for all modules.</li><li>version: This argument is recommended for modules from a registry.</li><li>meta-arguments: Arguments like for_each and count.</li><li>input variables: Most other arguments correspond to input variables.</li>\n  </ul>\n<pre class=\" language-go\"><code>module \"zland\" {\n  source = \"git::ssh//git@gitlab.com/zland/module.git\"\n  version = \"1.0.5\"\n  servers = 3\n}</code></pre>\n\n    <h2 id=\"module-output-valueslessbrgreater\">\n      Module Output Values<br>\n    </h2>\n<pre class=\" language-go\"><code>resource \"aws_instance\" \"appserver\" {\n    #...\n    instance = module.servers.instance_ids\n}</code></pre>\n\n  <p>\n    Since the resources defined in a module are encapsulated, a calling module cannot access their attributes directly. Instead, the child module can declare output values.\n  </p>\n\n    <h3 id=\"create-a-custom-module-example\">\n      Create a custom Module (Example)\n    </h3>\n\n  <p>\n    Create those files in the folder modules/ec2:<br><br>main.tf\n  </p>\n<pre class=\" language-go\"><code>resource \"aws_instance\" \"app_server\" {\n  ami           = \"DUMMY_VALUE_AMI\"\n  instance_type = \"t3.micro\"\n  subnet_id     = \"DUMMY_VALUE_SUBNET_ID\"\n  tags = {\n    Name = \"WayneCorp\"\n  }\n}\n</code></pre>\n\n  <p>\n    outputs.tf\n  </p>\n<pre class=\" language-go\"><code>output \"instance_id\" {\n  description = \"ID of the EC2 instance\"\n  value       = aws_instance.app_server.id\n}\n\noutput \"instance_public_ip\" {\n  description = \"Public IP address of the EC2 instance\"\n  value       = aws_instance.app_server.public_ip\n}</code></pre>\n\n  <p>\n    to use your module, add this snippet at the end of you existing ec2.tf file:<br><br>existing ec2.tf:\n  </p>\n<pre class=\" language-go\"><code>terraform {\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~&gt; 3.27\"\n    }\n  }\n  required_version = \"&gt;= 0.14.9\"\n}\nprovider \"aws\" {\n  profile = \"default\"\n  region  = \"us-east-1\"\n}</code></pre>\n\n  <p>\n    new content to add:\n  </p>\n<pre class=\" language-go\"><code>module \"ec2-module\" {\n  source = \"./modules/ec2/\"\n}\n</code></pre>\n\n  <p>\n    now you can run a <code>terraform fmt </code>to format your code.<br><br>Now run a <code>terraform init</code>&nbsp;to initialize your terraform backend<br><br>run a <code>terraform validate</code>&nbsp;to make sure syntax is correct<br><br>finally run a <code>terraform plan</code>&nbsp;and if your happy with the output a terraform apply<br><br>To check your state you can now run <code>terraform show</code>&nbsp;or <code>aws ec2 describe-instances</code>\n  </p>\n\n    <h2 id=\"dont-repeat-yourself\">\n      Don’t Repeat Yourself\n    </h2>\n\n  <ul>\n    <li>DRY is a principle that promotes modularization, abstraction, and code reuse and discourages repetition.</li><li>    This principle states that “every piece of knowledge must have a single, unambiguous, authoritative representation within a system”.</li><li>    This principle can be applied to not only programming, but to database schemas, test plans, the build system, and even documentation.</li><li>    If applied successfully, a modification of a single piece of the system will not require a change in other logic or unrelated elements of the system.</li>\n  </ul>\n\n  <p>\n    Not Keeping It DRY looks like this:\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://www.finecloud.ch/media/posts/92/Screenshot-2023-09-18-at-13.40.41.png\" height=\"482\" width=\"1958\" alt=\"\"  sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.40.41-xs.png 300w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.40.41-sm.png 480w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.40.41-md.png 768w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.40.41-lg.png 1024w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.40.41-xl.png 1360w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.40.41-2xl.png 1600w\">\n      \n    </figure>\n\n  <p>\n    Keeping it DRY on the oder hand look like this:\n  </p>\n\n    <figure class=\"post__image post__image--center\">\n      <img loading=\"lazy\" src=\"https://www.finecloud.ch/media/posts/92/Screenshot-2023-09-18-at-13.43.16.png\" height=\"590\" width=\"2216\" alt=\"\"  sizes=\"100vw\" srcset=\"https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.43.16-xs.png 300w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.43.16-sm.png 480w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.43.16-md.png 768w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.43.16-lg.png 1024w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.43.16-xl.png 1360w ,https://www.finecloud.ch/media/posts/92/responsive/Screenshot-2023-09-18-at-13.43.16-2xl.png 1600w\">\n      \n    </figure>\n\n  <p>\n    the configurations are symlinked here, this allows us to share the same configurations between those environments\n  </p>\n\n    <h2 id=\"3-things-to-use-to-keep-it-dry\">\n      3 Things to Use to Keep It DRY\n    </h2>\n\n  <ul>\n    <li>Terraform supports conditionals through the syntax of a ternary operator.</li><li>    The most common use case for conditionals is to create a conditional resource based on an input variable and the meta-parameter count.</li>\n  </ul>\n\n    <h3 id=\"conditional-example\">\n      Conditional Example\n    </h3>\n<pre class=\" language-go\"><code>locals {\n  make_bucket = \"${var.create_bucket == \"true\" ? True : false}\"\n}\nresource \"google_storage_bucket” “twinkiebucket\" {\n  count = \"${local.make_bucket ? 1 : 0}\"\n  name = \"${var.bucket_name}\"\n  project = \"${var.project_name}\"\n}</code></pre>\n\n    <h4 id=\"the-create_bucketfalse-conditional\">\n      The create_bucket=false Conditional\n    </h4>\n\n  <p>\n    output:\n  </p>\n\n  <p>\n    —&gt; test-bucket terraform plan -var=‘create_bucket=false’<br>Refreshing Terraform state in-memory prior to plan...<br>The refreshed state will be used to calculate this plan, but will not be Persisted to local or remote state storage.\n  </p>\n\n  <p>\n    No changes. Infrastructure is up-to-date.<br><br>This means that Terraform did not detect any differences between your configuration and real physical resources that exist. As a result, no actions need to be performed.\n  </p>\n\n    <h4 id=\"the-create_buckettrue-conditional\">\n      The create_bucket=true Conditional\n    </h4>\n\n  <p>\n    output:\n  </p>\n\n  <p>\n    —&gt; test-bucket terraform plan -var=‘create_bucket=true’<br>Refreshing Terraform state in-memory prior to plan...<br>The refreshed state will be used to calculate this plan, but will not be Persisted to local or remote state storage.<br><br>An execution plan has been generated and is shown below. Resource actions are indicated with the following symbols:<br><br>+ create<br>Terraform will perform the following actions:<br><br>+ google_storage_bucket.twinkiebucket ...\n  </p>\n\n    <h2 id=\"use-null_resource\">\n      Use null_resource\n    </h2>\n\n  <ul>\n    <li>The null_resource is useful when you need to do something that is not directly associated with the lifecycle of an actual resource.</li><li>    Within a null_resource, you can configure provisioners to run scripts to do pretty much whatever you want.</li><li>    Just like with provisioners, it is a good idea to use null_resource sparingly since it adds to the complexity of your Terraform usage.</li><li>    Make sure, when you do use it, that you vet the scripts being called thoroughly.</li>\n  </ul>\n\n    <h3 id=\"example-null_resource\">\n      Example null_resource\n    </h3>\n<pre class=\" language-go\"><code>resource \"aws_instance\" \"prod_cluster\" {\n    count = 4\n    #...\n}\nresource \"null_resource\" \"prod_cluster\" {\n    triggers = {\n        cluster_instance_ids = join(\",\" aws_instance.prod_cluster.*.id)\n    }\n    connection {\n        host = element(aws_instance.prod_cluster.*.public_ip, 0)\n    }\n    provisioner \"remote-exec\" {\n        inline = [\n            \"prod_cluster.sh ${join(\" \", aws_instance.prod_cluster.*.private_ip)}\",\n        ]\n    }\n}\n</code></pre>\n\n  <p class=\"msg msg--highlight\">\n    Actions that are done inside a null_resource are not managed by Terraform. If you decide to call a command to create resources in your null_resource, Terraform will not know about the resource creation, and therefore can’t manage its lifecycle and state.\n  </p>\n\n  <p>\n    you could for example add those lines to your main.tf:\n  </p>\n<pre class=\" language-go\"><code>resource \"null_resource\" \"ec2_status\" {\n  provisioner \"local-exec\" {\n    command = \"./scripts/health.sh\"\n  }\n}\n</code></pre>\n\n  <p>\n    and add the health.sh script to your repository:\n  </p>\n<pre class=\" language-bash\"><code>#!/bin/bash\necho \"   -------------------------------- \"\necho \"  --&gt; Fetching Instance status.\"\nsleep 25\ninstance_id=$(aws ec2 describe-instances --filters \"Name=tag:Name,Values=TheFastestManAlive\" \"Name=instance-state-name,Values=running\" --query 'Reservations[*].Instances[*].InstanceId' --output text)\nsize=${#instance_id}\necho \"  --&gt; Instance ID: $instance_id\"\nsleep 2\ninstance_state=$(aws ec2 describe-instance-status --instance-ids $instance_id --query 'InstanceStatuses[*].InstanceState.Name' --output text)\nsize=${#instance_state}\necho \"  --&gt; Instance Status: $instance_state\"\nsleep 2\ninstance_zone=$(aws ec2 describe-instance-status --instance-ids $instance_id --query 'InstanceStatuses[*].AvailabilityZone' --output text)\nsize=${#instance_zone}\necho \"  --&gt; Availability Zone: $instance_zone\"\nsleep 2\nfetch_instance_health=$(aws ec2 describe-instance-status --instance-ids $instance_id --query 'InstanceStatuses[*].InstanceStatus.Status' --output text)\necho \"  --&gt; Instance health check : $fetch_instance_health\"\necho \"  -------------------------------------------\"</code></pre>\n\n  <p>\n    do run some trivial heal check after the deployment of our EC2 instance.\n  </p>\n\n    <h2 id=\"use-functions\">\n      Use Functions\n    </h2>\n\n  <ul>\n    <li>Terraform has built-in interpolation functions that allow you to use interpolation syntax embedded within strings to interpolate other values.</li><li>Interpolationfunctionsarecalledwiththesyntax${name(arg, arg2, ...)}.</li><li>The interpolation syntax allows you to call a large list of built-in functions.</li>\n  </ul>\n\n    <h3 id=\"the-format-function\">\n      The format Function\n    </h3>\n<pre class=\" language-bash\"><code>#format.tf\nlocals {\nhostname = \"${format(\"%s-%s-%s-%s-%04d-%s\", var.region, var.env, var.app,\nvar.type, var.cluster_id, var.id)}\" }</code></pre>\n\n  <p>\n    this Terraform code defines a local variable named <em>hostname</em>&nbsp;using the locals block. This variable is computed using the `format` function and a string template. Let's break down the components of this function:<br><br>1. `${format(...)}:` This part of the code is using Terraform's interpolation syntax `${...}` to execute the `format` function. The `format` function is used to create formatted strings by substituting values into placeholders within a template string.<br><br>2. `\"${format(\"%s-%s-%s-%s-%04d-%s\", var.region, var.env, var.app, var.type, var.cluster_id, var.id)}\"`: This is the template string used in the `format` function. It consists of several placeholders, each represented by `%s` or `%04d`, which are replaced by the values provided after the template string.\n  </p>\n\n  <ul>\n    <li>`%s`: This is a placeholder for a string value.</li><li>`%04d`: This is a placeholder for a decimal integer value, formatted with leading zeros to ensure a total width of 4 characters.</li>\n  </ul>\n\n  <p>\n    The values to be substituted into these placeholders come from various Terraform variables:\n  </p>\n\n  <ul>\n    <li>`var.region`: This variable is expected to contain a string representing a region.</li><li>`var.env`: This variable is expected to contain a string representing an environment.</li><li>`var.app`: This variable is expected to contain a string representing an application name.</li><li>`var.type`: This variable is expected to contain a string representing a type.</li><li>`var.cluster_id`: This variable is expected to contain a numeric cluster identifier.</li><li>`var.id`: This variable is expected to contain a string or value that is used in the formatted hostname.</li>\n  </ul>\n\n  <p>\n    The `format` function combines these values using the specified template to generate a formatted hostname. The resulting hostname will be a string that includes the region, environment, application, type, cluster identifier (with leading zeros if necessary), and the additional identifier provided by `var.id`.<br><br>For example, if you have the following values for your variables:\n  </p>\n\n  <ul>\n    <li>`var.region` = \"us-west\"</li><li>`var.env` = \"prod\"</li><li>`var.app` = \"web\"</li><li>`var.type` = \"frontend\"</li><li>`var.cluster_id` = 42</li><li>`var.id` = \"abc123\"</li>\n  </ul>\n\n  <p>\n    The `hostname` variable will be computed as follows:<br>\n  </p>\n<pre class=\" language-bash\"><code>us-west-prod-web-frontend-0042-abc123</code></pre>\n\n  <p>\n    This computed hostname can then be used in your Terraform configuration as needed, such as for provisioning cloud resources with this specific hostname format.\n  </p>\n\n    <h3 id=\"the-matchkeys-function\">\n      The matchkeys Function\n    </h3>\n\n  <p>\n    matchkeys constructs a new list by taking a subset of elements from one list whose indexes match the corresponding indexes of values in another list.<br><br>matchkeys identifies the indexes in keyslist that are equal to elements of searchset, and then constructs a new list by taking those same indexes from valueslist. Both valueslist and keyslist must be the same length.<br><br>The ordering of the values in valueslist is preserved in the result.\n  </p>\n<pre class=\" language-bash\"><code>#matchkeys.tf\ninstances = [ \"${matchkeys(\n  google_compute_instance.compute_instance.*.self_link,\n  google_compute_instance.compute_instance.*.zone,\n  data.google_compute_zones.available.names[0])\n}\" ]</code></pre>\n\n    <h3 id=\"the-element-function\">\n      The element Function\n    </h3>\n\n  <p>\n    The `element` function in Terraform is primarily used for accessing elements within a list or an array. It's a versatile function that can be used for various purposes, including:\n  </p>\n\n  <ol>\n    <li>Retrieving Values: You can use `element` to retrieve specific values from a list or array. For example, you might use it to access the nth element of a list.</li><li><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: 1em; font-weight: var(--font-weight-normal);\">Looping and Iteration: When combined with other Terraform constructs like `count` or `for_each`, `element` can be used to iterate over a list or array, applying the same resource configuration or operation to each element.</span></li><li>Dynamic Resource Creation: In Terraform, you can use `element` to dynamically create multiple instances of a resource by specifying different configurations for each instance based on the elements of a list or array.</li><li><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: 1em; font-weight: var(--font-weight-normal);\">Conditional Behavior: It can be used to conditionally set values or attributes in resources or variables based on the index of an element in a list.</span></li>\n  </ol>\n\n  <p>\n    Here's an example of how you might use the `element` function in a Terraform configuration:\n  </p>\n<pre class=\" language-bash\"><code>variable \"server_names\" {\n  type    = list(string)\n  default = [\"web-server-1\", \"web-server-2\", \"web-server-3\"]\n}\n\nresource \"aws_instance\" \"example\" {\n  count = length(var.server_names)\n  ami   = \"ami-12345678\"\n  instance_type = \"t2.micro\"\n  tags = {\n    Name = element(var.server_names, count.index)\n  }\n}\n</code></pre>\n\n  <p>\n    In this example, the `element` function is used to assign a unique name tag to each AWS EC2 instance being created based on the elements of the \"server_names\" list. It demonstrates how `element` can be used for dynamic resource creation and conditional behavior.<br><br>Overall, the `element` function is a fundamental tool in Terraform for working with lists and arrays, enabling you to make your configurations more dynamic and flexible.\n  </p>\n\n    <h2 id=\"test-your-code\">\n      Test Your Code\n    </h2>\n\n  <ul>\n    <li>Testing code leads to greater confidence that the code will perform as expected.</li><li>Terraform has built-in tools to help test your code before deployment.</li><li>Due to Terraform’s usefulness and popularity, there are many tools which expand upon the built-in tools.</li>\n  </ul>\n\n  <p>\n    there are a few built-in commands to test your TF code:\n  </p>\n\n  <ol>\n    <li>terraform fmt</li><li>terraform init</li><li>terraform validate</li><li>terraform plan</li>\n  </ol>\n\n    <h3 id=\"other-testing-tools\">\n      Other Testing Tools\n    </h3>\n\n  <ul>\n    <li>Terratest:&nbsp;A great, comprehensive tool by Gruntwork. This tool does not do unit testing.</li><li>Kitchen-Terraform:&nbsp;Spins up, tests, and spins down various Terraform resources.</li><li>Terraform-compliance:&nbsp;A simple tool for testing and enforcing Terraform compliance rules.</li>\n  </ul>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "terraform",
                   "iac",
                   "devops"
            ],
            "date_published": "2023-09-17T14:14:00+02:00",
            "date_modified": "2023-09-18T17:11:41+02:00"
        },
        {
            "id": "https://www.finecloud.ch/spring-boot-on-kubernetes.html",
            "url": "https://www.finecloud.ch/spring-boot-on-kubernetes.html",
            "title": "Spring Boot on Kubernetes",
            "summary": "Enable Kubernetes in Docker Desktop We will use Docker Desktop to provide us a Test Kubernetes Environment. Open Docker Desktop Settings, go to Tab \"Kubernetes\". Select \"Enable Kubernetes\", then \"Apply &amp; Restart\". Now you should be able to see docker-desktop listed, if you run kubectl&hellip;",
            "content_html": "<div class=\"post__toc\">\n<h3>Table of Contents</h3>\n<ul>\n<li><a href=\"#mcetoc_1gvimt7cd1et\">Enable Kubernetes in Docker Desktop</a></li>\n<li><a href=\"#mcetoc_1gvimt7cd1eu\">Create Deployment</a></li>\n<li><a href=\"#mcetoc_1gvimt7cd1ev\">Create Service</a></li>\n<li><a href=\"#mcetoc_1gvimt7cd1f0\">Port Forwarding</a></li>\n</ul>\n</div>\n<h2 id=\"mcetoc_1gvimt7cd1et\">Enable Kubernetes in Docker Desktop</h2>\n<p>We will use Docker Desktop to provide us a Test Kubernetes Environment.</p>\n<p>Open Docker Desktop Settings, go to Tab \"Kubernetes\". Select \"Enable Kubernetes\", then \"Apply &amp; Restart\".</p>\n<p>Now you should be able to see docker-desktop listed, if you run <code>kubectl get nodes</code></p>\n<h2 id=\"mcetoc_1gvimt7cd1eu\">Create Deployment</h2>\n<p>We will use the Docker Image we created in the last Post. Instead of directly deploying the Application we want to create a deployment.yml file:</p>\n<p><code>kubectl create deployment myapp --image name/myapp --dry-run=client -o=yaml &gt; deployment.yml</code></p>\n<p>the content looks like this:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-attr\">apiVersion:</span> apps/v1\n<span class=\"hljs-attr\">kind:</span> Deployment\n<span class=\"hljs-attr\">metadata:</span>\n<span class=\"hljs-attr\">  creationTimestamp:</span> <span class=\"hljs-literal\" style=\"color: #6897bb;\">null</span>\n<span class=\"hljs-attr\">  labels:</span>\n<span class=\"hljs-attr\">    app:</span> myapp\n<span class=\"hljs-attr\">  name:</span> myapp\n<span class=\"hljs-attr\">spec:</span>\n<span class=\"hljs-attr\">  replicas:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">1</span>\n<span class=\"hljs-attr\">  selector:</span>\n<span class=\"hljs-attr\">    matchLabels:</span>\n<span class=\"hljs-attr\">      app:</span> myapp\n<span class=\"hljs-attr\">  strategy:</span> {}\n<span class=\"hljs-attr\">  template:</span>\n<span class=\"hljs-attr\">    metadata:</span>\n<span class=\"hljs-attr\">      creationTimestamp:</span> <span class=\"hljs-literal\" style=\"color: #6897bb;\">null</span>\n<span class=\"hljs-attr\">      labels:</span>\n<span class=\"hljs-attr\">        app:</span> myapp\n<span class=\"hljs-attr\">    spec:</span>\n<span class=\"hljs-attr\">      containers:</span>\n<span class=\"hljs-attr\">      - image:</span> name/myapp\n<span class=\"hljs-attr\">        name:</span> myapp\n<span class=\"hljs-attr\">        resources:</span> {}\n<span class=\"hljs-attr\">status:</span> {}</pre>\n<p>now we can apply this deployment with: <code>kubectl apply -f deployment.yml</code></p>\n<h2 id=\"mcetoc_1gvimt7cd1ev\">Create Service</h2>\n<p>With the command </p>\n<p><code>kubectl create service clusterip myapp --tcp=8080:8080 --dry-run=client -o=yaml &gt; service.yml</code></p>\n<p>we can create the service definition file. And then apply it with: </p>\n<p><code>kubectl apply -f service.yml</code></p>\n<p>the content of the file:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-attr\">apiVersion:</span> v1\n<span class=\"hljs-attr\">kind:</span> Service\n<span class=\"hljs-attr\">metadata:</span>\n<span class=\"hljs-attr\">  creationTimestamp:</span> <span class=\"hljs-literal\" style=\"color: #6897bb;\">null</span>\n<span class=\"hljs-attr\">  labels:</span>\n<span class=\"hljs-attr\">    app:</span> myapp\n<span class=\"hljs-attr\">  name:</span> myapp\n<span class=\"hljs-attr\">spec:</span>\n<span class=\"hljs-attr\">  ports:</span>\n<span class=\"hljs-attr\">  - name:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">8080</span><span class=\"hljs-bullet\" style=\"color: #6897bb;\">-8080</span>\n<span class=\"hljs-attr\">    port:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">8080</span>\n<span class=\"hljs-attr\">    protocol:</span> TCP\n<span class=\"hljs-attr\">    targetPort:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">8080</span>\n<span class=\"hljs-attr\">  selector:</span>\n<span class=\"hljs-attr\">    app:</span> myapp\n<span class=\"hljs-attr\">  type:</span> ClusterIP\n<span class=\"hljs-attr\">status:</span>\n<span class=\"hljs-attr\">  loadBalancer:</span> {}</pre>\n<p>with <code>kubectl get all</code> we can now see that the service has been created.</p>\n<h2 id=\"mcetoc_1gvimt7cd1f0\">Port Forwarding</h2>\n<p>To be able to access the App, we need to create a Port Forwarding like so:</p>\n<ol>\n<li>get your local ip address, e.g.: <code>ipconfig getifaddr en0</code></li>\n<li>configure port forwarding with: <code>kubectl port-forward service/myapp 8080:8080</code></li>\n<li>Check if it works with: <code>curl localhost:8080/actuator/health</code></li>\n<li>this should return: <code>{\"status\":\"UP\",\"groups\":[\"liveness\",\"readiness\"]}</code></li>\n</ol>\n<h2>Terminate Service and Deployment</h2>\n<p>If you want to stop a Service or a Deployment you can use these cmds:</p>\n<p><code>kubectl delete service myapp</code></p>\n<p><code>kubectl delete deployment myapp</code></p>\n<h2>Exposing Services</h2>\n<p>If you want to expose a Service permanent and not only with Port Forwarding you can go with this: </p>\n<ol>\n<li>Replace <em><span class=\"hljs-attr\">type:</span> ClusterIP </em>in the service.yml file with <em><span class=\"hljs-attr\">type:</span> NodePort</em></li>\n<li>Reapply the deployment and service</li>\n<li>Check what dynamic Port the service has been exposed on: <code>kubectl get all</code></li>\n<li>Check access with curl: <code>curl localhost:31610/actuator/health</code></li>\n</ol>\n<h2>Accessing Logs</h2>\n<p>One option is to check the logs on the docker containers directly with:</p>\n<ol>\n<li>docker ps -a</li>\n<li>docker logs -f &lt;containername&gt;</li>\n</ol>\n<p>but in a Kubernetes context you probably cant access the docker logs directly, or docker is not used at all, thats why you need to go with this:</p>\n<ol>\n<li>kubectl get all</li>\n<li>kubectl logs -f &lt;podname&gt;</li>\n</ol>\n<h2>Setting Environment Variables</h2>\n<p>Example use case: overwrite log levels.</p>\n<ol>\n<li>Change your deployment.yml and add the env part to it:</li>\n<li>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-attr\">apiVersion:</span> apps/v1\n<span class=\"hljs-attr\">kind:</span> Deployment\n<span class=\"hljs-attr\">metadata:</span>\n<span class=\"hljs-attr\">  creationTimestamp:</span> <span class=\"hljs-literal\" style=\"color: #6897bb;\">null</span>\n<span class=\"hljs-attr\">  labels:</span>\n<span class=\"hljs-attr\">    app:</span> myapp\n<span class=\"hljs-attr\">  name:</span> myapp\n<span class=\"hljs-attr\">spec:</span>\n<span class=\"hljs-attr\">  replicas:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">1</span>\n<span class=\"hljs-attr\">  selector:</span>\n<span class=\"hljs-attr\">    matchLabels:</span>\n<span class=\"hljs-attr\">      app:</span> myapp\n<span class=\"hljs-attr\">  strategy:</span> {}\n<span class=\"hljs-attr\">  template:</span>\n<span class=\"hljs-attr\">    metadata:</span>\n<span class=\"hljs-attr\">      creationTimestamp:</span> <span class=\"hljs-literal\" style=\"color: #6897bb;\">null</span>\n<span class=\"hljs-attr\">      labels:</span>\n<span class=\"hljs-attr\">        app:</span> myapp\n<span class=\"hljs-attr\">    spec:</span>\n<span class=\"hljs-attr\">      containers:</span>\n<span class=\"hljs-attr\">      - image:</span> jhyyhpp/kbe-rest-brewery\n<span class=\"hljs-attr\">        name:</span> kbe-rest-brewery\n<span class=\"hljs-attr\">        resources:</span> {}\n<span class=\"hljs-attr\">        env:</span>\n<span class=\"hljs-attr\">        - name:</span> LOGGING_LEVEL_MYAPP\n<span class=\"hljs-attr\">          value:</span> INFO\n<span class=\"hljs-attr\">status:</span> {}\n</pre>\n</li>\n<li>kubectl apply -f deployment.yml</li>\n<li>kubectl get all</li>\n<li>kubectl logs -f &lt;podname&gt;</li>\n</ol>\n<h2>Readiness Probe</h2>\n<div class=\"flex flex-grow flex-col gap-3\">\n<div class=\"min-h-[20px] flex flex-col items-start gap-4 whitespace-pre-wrap break-words\">\n<div class=\"markdown prose w-full break-words dark:prose-invert light\">\n<p>A readiness probe is an essential feature in Kubernetes that ensures the proper functioning of a deployed application. Here are some reasons why you should use a readiness probe:</p>\n<ol>\n<li>\n<p>Prevents traffic to unhealthy pods: Kubernetes uses readiness probes to determine if a pod is ready to receive traffic or not. If a pod is not ready, Kubernetes will not route traffic to that pod. This ensures that traffic is only sent to healthy pods, preventing downtime and improving the overall availability of the application.</p>\n</li>\n<li>\n<p>Allows for graceful scaling: When new pods are added to a deployment or replica set, Kubernetes uses readiness probes to determine when the new pods are ready to receive traffic. This allows for a more graceful scaling experience, as traffic is only routed to new pods once they are ready to handle it.</p>\n</li>\n<li>\n<p>Helps with rolling updates: Kubernetes uses readiness probes to determine when a new version of an application is ready to receive traffic. This allows for rolling updates to be performed without causing downtime or disruption to users.</p>\n</li>\n<li>\n<p>Provides insight into application health: Readiness probes can be used to provide insight into the health of an application. By monitoring the results of readiness probes, you can determine if your application is healthy and identify any issues that need to be addressed.</p>\n</li>\n</ol>\n<p>Overall, readiness probes are a crucial feature in Kubernetes that help ensure the proper functioning of your application and improve its availability.</p>\n</div>\n</div>\n</div>\n<h2>Liveness Probe</h2>\n<div class=\"flex flex-grow flex-col gap-3\">\n<div class=\"min-h-[20px] flex flex-col items-start gap-4 whitespace-pre-wrap break-words\">\n<div class=\"markdown prose w-full break-words dark:prose-invert light\">\n<p>A liveness probe is another important feature in Kubernetes that ensures the health of a deployed application. Here are some reasons why you should use a liveness probe:</p>\n<ol>\n<li>\n<p>Restarts unhealthy pods: Kubernetes uses liveness probes to determine if a pod is healthy or not. If a pod fails the liveness probe, Kubernetes will automatically restart the pod, ensuring that the application remains available.</p>\n</li>\n<li>\n<p>Prevents failed requests: Liveness probes help prevent failed requests by ensuring that only healthy pods are serving traffic. If a pod is not healthy, Kubernetes will not route traffic to that pod, preventing failed requests and improving the overall availability of the application.</p>\n</li>\n<li>\n<p>Identifies application failures: Liveness probes can be used to identify application failures and help diagnose issues. By monitoring the results of liveness probes, you can determine if your application is healthy and identify any issues that need to be addressed.</p>\n</li>\n<li>\n<p>Supports self-healing: By automatically restarting unhealthy pods, liveness probes support self-healing in Kubernetes. This ensures that your application remains available even in the face of failures.</p>\n</li>\n</ol>\n<p>Overall, liveness probes are a crucial feature in Kubernetes that help ensure the health of your application and improve its availability. By using liveness probes, you can ensure that your application remains available, even in the face of failures, and identify and address any issues that may arise.</p>\n<p>To add the readiness and liveness probles we need to add the following content to our deployment.yml file:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-attr\">apiVersion:</span> apps/v1\n<span class=\"hljs-attr\">kind:</span> Deployment\n<span class=\"hljs-attr\">metadata:</span>\n<span class=\"hljs-attr\">  creationTimestamp:</span> <span class=\"hljs-literal\" style=\"color: #6897bb;\">null</span>\n<span class=\"hljs-attr\">  labels:</span>\n<span class=\"hljs-attr\">    app:</span> myapp\n<span class=\"hljs-attr\">  name:</span> myapp\n<span class=\"hljs-attr\">spec:</span>\n<span class=\"hljs-attr\">  replicas:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">1</span>\n<span class=\"hljs-attr\">  selector:</span>\n<span class=\"hljs-attr\">    matchLabels:</span>\n<span class=\"hljs-attr\">      app:</span> myapp\n<span class=\"hljs-attr\">  strategy:</span> {}\n<span class=\"hljs-attr\">  template:</span>\n<span class=\"hljs-attr\">    metadata:</span>\n<span class=\"hljs-attr\">      creationTimestamp:</span> <span class=\"hljs-literal\" style=\"color: #6897bb;\">null</span>\n<span class=\"hljs-attr\">      labels:</span>\n<span class=\"hljs-attr\">        app:</span> myapp\n<span class=\"hljs-attr\">    spec:</span>\n<span class=\"hljs-attr\">      containers:</span>\n<span class=\"hljs-attr\">      - image:</span> jhyyhpp/kbe-rest-brewery\n<span class=\"hljs-attr\">        name:</span> kbe-rest-brewery\n<span class=\"hljs-attr\">        resources:</span> {}\n<span class=\"hljs-attr\">        env:</span>\n<span class=\"hljs-attr\">        - name:</span> LOGGING_LEVEL_CH_FINECLOUD_SFGRESTBREWERY\n<span class=\"hljs-attr\">          value:</span> INFO\n<span class=\"hljs-attr\">        - name:</span> MANAGEMENT_ENDPOINTS_HEALTH_PROBES_ENABLED\n<span class=\"hljs-attr\">          value:</span> <span class=\"hljs-string\" style=\"color: #6a8759;\">\"true\"</span>\n<span class=\"hljs-attr\">        - name:</span> MANAGEMENT_HEALTH_READINESSSTATE_ENABLED\n<span class=\"hljs-attr\">          value:</span> <span class=\"hljs-string\" style=\"color: #6a8759;\">\"true\"</span>\n<span class=\"hljs-attr\">        - name:</span> MANAGEMENT_HEALTH_LIVENESSSTATE_ENABLED\n<span class=\"hljs-attr\">          value:</span> <span class=\"hljs-string\" style=\"color: #6a8759;\">\"true\"</span>\n<span class=\"hljs-attr\">        livenessProbe:</span>\n<span class=\"hljs-attr\">            httpGet:</span>\n<span class=\"hljs-attr\">                path:</span> /actuator/health/liveness\n<span class=\"hljs-attr\">                port:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">8080</span>\n<span class=\"hljs-attr\">        readinessProbe:</span>\n<span class=\"hljs-attr\">          httpGet:</span>\n<span class=\"hljs-attr\">            path:</span> /actuator/health/readiness\n<span class=\"hljs-attr\">            port:</span> <span class=\"hljs-number\" style=\"color: #6897bb;\">8080</span>\n<span class=\"hljs-attr\">status:</span> {}\n</pre>\n</div>\n</div>\n</div>\n<h2>Graceful Shutdown</h2>\n<div class=\"flex flex-grow flex-col gap-3\">\n<div class=\"min-h-[20px] flex flex-col items-start gap-4 whitespace-pre-wrap break-words\">\n<div class=\"markdown prose w-full break-words dark:prose-invert light\">\n<p>Graceful shutdown is an important feature to consider when deploying an application on Kubernetes. Here are some reasons why you should use a graceful shutdown:</p>\n<ol>\n<li>\n<p>Minimizes downtime: Graceful shutdown allows your application to shut down in a controlled manner, ensuring that any in-flight requests are completed before the application is terminated. This helps to minimize downtime and improve the overall availability of the application.</p>\n</li>\n<li>\n<p>Avoids data loss: During a graceful shutdown, your application has the opportunity to save any data that needs to be persisted before shutting down. This helps to avoid data loss and ensures that your application can be restarted without losing any important data.</p>\n</li>\n<li>\n<p>Prevents disruption to users: A graceful shutdown ensures that your application is shut down in a way that is transparent to users. By completing any in-flight requests and avoiding abrupt terminations, you can prevent disruption to users and provide a better user experience.</p>\n</li>\n<li>\n<p>Supports scaling: When scaling down your application, a graceful shutdown ensures that any remaining requests are completed before the pod is terminated. This allows for more efficient scaling and helps to prevent any lost or interrupted requests.</p>\n</li>\n</ol>\n<p>Overall, a graceful shutdown is an important feature to consider when deploying an application on Kubernetes. It helps to minimize downtime, avoid data loss, prevent disruption to users, and support efficient scaling. By using a graceful shutdown, you can ensure that your application is shut down in a way that is safe, controlled, and reliable.</p>\n</div>\n</div>\n</div>\n<p>To configure graceful shutdown we need to add the following content to our deployment.yml file:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-attr\">        - name:</span> SERVER_SHUTDOWN\n<span class=\"hljs-attr\">          value:</span> <span class=\"hljs-string\" style=\"color: #6a8759;\">\"graceful\"</span>\n<span class=\"hljs-attr\">        lifecycle:</span>\n<span class=\"hljs-attr\">          preStop:</span>\n<span class=\"hljs-attr\">            exec:</span>\n<span class=\"hljs-attr\">              command:</span> [<span class=\"hljs-string\" style=\"color: #6a8759;\">\"/bin/sh\"</span>, <span class=\"hljs-string\" style=\"color: #6a8759;\">\"-c\"</span>, <span class=\"hljs-string\" style=\"color: #6a8759;\">\"sleep 10\"</span>]</pre>\n<p> </p>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "spring-framework",
                   "spring",
                   "software development",
                   "kubernetes",
                   "java",
                   "docker",
                   "container"
            ],
            "date_published": "2023-05-03T20:46:16+02:00",
            "date_modified": "2023-05-05T19:16:26+02:00"
        },
        {
            "id": "https://www.finecloud.ch/building-spring-boot-docker-images.html",
            "url": "https://www.finecloud.ch/building-spring-boot-docker-images.html",
            "title": "Building Spring Boot Docker Images",
            "summary": "Pre-Requirements Developer Environment ready with Docker, JDK, IDE A Java Spring Boot Project with a h2 in-memory DB Docker Hub account Create Docker File Create a Dockerfile with the following content: FROM openjdk:11-jre-slim ENV JAVA_OPTS \" -Xms512m -Xmx512m -Djava.security.egd=file:///dev/./urandom\" WORKDIR application COPY target/myapp-0.0.1-SNAPSHOT.jar ./ ENTRYPOINT&hellip;",
            "content_html": "<div class=\"post__toc\">\n<h3>Table of Contents</h3>\n<ul>\n<li><a href=\"#mcetoc_1gvhe7lit17h\">Pre-Requirements</a></li>\n<li><a href=\"#mcetoc_1gvhe7lit17i\">Create Docker File</a></li>\n<li><a href=\"#mcetoc_1gvhe7lit17j\">Build and Run the Docker Image</a></li>\n<li><a href=\"#mcetoc_1gvhe7lit17k\">Add Layer Tool in Maven</a></li>\n<li><a href=\"#mcetoc_1gvhe7lit17l\">Enable Multi-Stage Dockerfile</a></li>\n<li><a href=\"#mcetoc_1gvhe7lit17m\">Build the Docker Image with Maven</a></li>\n<li><a href=\"#mcetoc_1gvhe7lit17n\">Push your Docker Image to Docker Hub</a></li>\n</ul>\n</div>\n<h2 id=\"mcetoc_1gvhe7lit17h\">Pre-Requirements</h2>\n<ul>\n<li>Developer Environment ready with Docker, JDK, IDE</li>\n<li>A Java Spring Boot Project with a h2 in-memory DB</li>\n<li>Docker Hub account</li>\n</ul>\n<h2 id=\"mcetoc_1gvhe7lit17i\">Create Docker File</h2>\n<p>Create a Dockerfile with the following content:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-keyword\" style=\"color: #cc7832;\">FROM</span> openjdk:<span class=\"hljs-number\" style=\"color: #6897bb;\">11</span>-jre-slim\n<span class=\"hljs-keyword\" style=\"color: #cc7832;\">ENV</span> JAVA_OPTS <span class=\"hljs-string\" style=\"color: #6a8759;\">\" -Xms512m -Xmx512m -Djava.security.egd=file:///dev/./urandom\"</span>\nWORKDIR application\n<span class=\"hljs-keyword\" style=\"color: #cc7832;\">COPY</span> <span class=\"bash\">target/myapp-0.0.1-SNAPSHOT.jar ./\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">ENTRYPOINT</span> <span class=\"bash\">[<span class=\"hljs-string\" style=\"color: #6a8759;\">\"java\"</span>, <span class=\"hljs-string\" style=\"color: #6a8759;\">\"-jar\"</span>, <span class=\"hljs-string\" style=\"color: #6a8759;\">\"myapp-0.0.1-SNAPSHOT.jar\"</span>]</span></pre>\n<div>make sure the Paths where the .jar files are stored matches with your environment.</div>\n<h2 id=\"mcetoc_1gvhe7lit17j\">Build and Run the Docker Image</h2>\n<p>Build the image with this command:</p>\n<p><code><span class=\"blob-code-inner blob-code-marker js-code-nav-pass \" data-code-marker=\"+\"><span class=\"pl-c1\">docker build -f ./src/main/Dockerfile -t myapp .</span></span></code></p>\n<p>Run the image with this command:</p>\n<p><code><span class=\"blob-code-inner blob-code-marker js-code-nav-pass \" data-code-marker=\"+\"><span class=\"pl-c1\">docker run -p 8080:8080 -d myapp</span></span></code></p>\n<p>The Spring Application-Context should now be loaded and started inside the Container. You can verify this with the <code>docker ps -a</code> and <code>docker logs -f &lt;containername&gt;</code> commands.</p>\n<h2 id=\"mcetoc_1gvhe7lit17k\">Add Layer Tool in Maven</h2>\n<p>Make sure that you have enabled the Layer Tool with having this content in the pom.xml file:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\">            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">plugin</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">groupId</span>&gt;</span>org.springframework.boot<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">groupId</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">artifactId</span>&gt;</span>spring-boot-maven-plugin<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">artifactId</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">configuration</span>&gt;</span>\n                    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">layers</span>&gt;</span>\n                        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">enabled</span>&gt;</span>true<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">enabled</span>&gt;</span>\n                        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">includeLayerTools</span>&gt;</span>true<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">includeLayerTools</span>&gt;</span>\n                    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">layers</span>&gt;</span>\n                    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">excludes</span>&gt;</span>\n                        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">exclude</span>&gt;</span>\n                            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">groupId</span>&gt;</span>org.projectlombok<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">groupId</span>&gt;</span>\n                            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">artifactId</span>&gt;</span>lombok<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">artifactId</span>&gt;</span>\n                        <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">exclude</span>&gt;</span>\n                    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">excludes</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">configuration</span>&gt;</span>\n            <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">plugin</span>&gt;</span></pre>\n<div class=\"flex flex-grow flex-col gap-3\">\n<div class=\"min-h-[20px] flex flex-col items-start gap-4 whitespace-pre-wrap break-words\">\n<div class=\"markdown prose w-full break-words dark:prose-invert light\">\n<p>Enabling the layer tool in a Java Spring project that runs in a Docker container can help reduce the size of the Docker image, which can be especially important in a production environment. The layer tool feature allows the Spring Boot application to be broken down into layers, where each layer contains a subset of the application's dependencies and resources. This makes it possible to separate the application's core functionality from its dependencies, such as external libraries and resources.</p>\n<p>By separating the application's dependencies into separate layers, Docker can cache each layer independently, making it easier to reuse existing layers when building new Docker images. This can significantly reduce the amount of time it takes to build and deploy new versions of the application.</p>\n<p>Enabling the layer tool also allows you to take advantage of other features, such as layer analysis, which can help you optimize your Docker image even further by identifying potential areas for improvement.</p>\n<p>In summary, enabling the layer tool in a Java Spring project that runs in a Docker container can help reduce the size of the Docker image, improve the speed of deployment, and optimize resource usage.</p>\n<h2 id=\"mcetoc_1gvhe7lit17l\">Enable Multi-Stage Dockerfile</h2>\n<p>Now we want to create a example of a Multi-Stage Dockerfile, like so:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-keyword\" style=\"color: #cc7832;\">FROM</span> openjdk:<span class=\"hljs-number\" style=\"color: #6897bb;\">11</span>-jre-slim as builder\n<span class=\"hljs-keyword\" style=\"color: #cc7832;\">WORKDIR</span> <span class=\"bash\">application\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">ADD</span> <span class=\"bash\">target/myapp-0.0.1-SNAPSHOT.jar ./\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">RUN</span> <span class=\"bash\">java -Djarmode=layertools -jar myapp-0.0.1-SNAPSHOT.jar extract\n</span>\n<span class=\"hljs-keyword\" style=\"color: #cc7832;\">FROM</span> openjdk:<span class=\"hljs-number\" style=\"color: #6897bb;\">11</span>-jre-slim\n\n<span class=\"hljs-keyword\" style=\"color: #cc7832;\">WORKDIR</span> <span class=\"bash\">application\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">COPY</span> <span class=\"bash\">--from=builder application/dependencies/ ./\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">COPY</span> <span class=\"bash\">--from=builder application/spring-boot-loader/ ./\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">COPY</span> <span class=\"bash\">--from=builder application/snapshot-dependencies/ ./\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">COPY</span> <span class=\"bash\">--from=builder application/application/ ./\n</span><span class=\"hljs-keyword\" style=\"color: #cc7832;\">ENTRYPOINT</span> <span class=\"bash\">[<span class=\"hljs-string\" style=\"color: #6a8759;\">\"java\"</span>, <span class=\"hljs-string\" style=\"color: #6a8759;\">\"-Djava.security.egd=file:///dev/./urandom\"</span>, <span class=\"hljs-string\" style=\"color: #6a8759;\">\"org.springframework.boot.loader.JarLauncher\"</span>]</span></pre>\n<p>now we can recreate the image like so: <code><span class=\"blob-code-inner blob-code-marker js-code-nav-pass \" data-code-marker=\"+\"><span class=\"pl-c1\">docker build -f ./src/main/docker/Dockerfile -t myapp .</span></span></code></p>\n<h2 id=\"mcetoc_1gvhe7lit17m\">Build the Docker Image with Maven</h2>\n<p>So far it's very uncomfortable to have the Version of the .jar Artifact in the Dockerfile. This way we would need to change this after every new release. There is a better way: we can use the Docker Maven plugin. Add this dependency to your pom.xml:</p>\n<pre class=\"hljs\" style=\"color: #a9b7c6; background: #282b2e; display: block; overflow-x: auto; padding: 0.5em;\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">plugin</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">groupId</span>&gt;</span>io.fabric8<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">groupId</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">artifactId</span>&gt;</span>docker-maven-plugin<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">artifactId</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">version</span>&gt;0.42.1</span><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">version</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">configuration</span>&gt;</span>\n                    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">verbose</span>&gt;</span>true<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">verbose</span>&gt;</span>\n                    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">images</span>&gt;</span>\n                        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">image</span>&gt;</span>\n                            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">name</span>&gt;</span>yourdockeraccount/myapp<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">name</span>&gt;</span>\n                            <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">build</span>&gt;</span>\n                                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">assembly</span>&gt;</span>\n                                    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">descriptorRef</span>&gt;</span>artifact<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">descriptorRef</span>&gt;</span>\n                                <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">assembly</span>&gt;</span>\n                                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">dockerFile</span>&gt;</span>Dockerfile<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">dockerFile</span>&gt;</span>\n                                <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">tags</span>&gt;</span>\n                                    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">tag</span>&gt;</span>latest<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">tag</span>&gt;</span>\n                                    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\" style=\"color: #e8bf6a;\">tag</span>&gt;</span>${project.version}<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">tag</span>&gt;</span>\n                                <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">tags</span>&gt;</span>\n                            <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">build</span>&gt;</span>\n                        <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">image</span>&gt;</span>\n                    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">images</span>&gt;</span>\n                <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">configuration</span>&gt;</span>\n            <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\" style=\"color: #e8bf6a;\">plugin</span>&gt;</span></pre>\n<p>make sure you add your image name!</p>\n<p>Also you need to replace the Artifact Name of \"<span class=\"bash\">myapp-0.0.1-SNAPSHOT.jar</span>\" with </p>\n<div>\"${project.build.finalName}.jar\" in the Dockerfile.</div>\n<div> </div>\n<div>Now you can build the docker image with the maven plugin using a dynamic version.</div>\n<h2 id=\"mcetoc_1gvhe7lit17n\">Push your Docker Image to Docker Hub</h2>\n<p>Last step is to push your Application to the docker hub. But first lets build the image with:</p>\n<p><code>mvn clean package docker:build docker:push</code></p>\n<p> </p>\n</div>\n</div>\n</div>",
            "author": {
                "name": "Finecloud"
            },
            "tags": [
                   "spring-framework",
                   "spring",
                   "software development",
                   "java",
                   "docker",
                   "container"
            ],
            "date_published": "2023-05-02T21:45:09+02:00",
            "date_modified": "2023-05-03T20:34:47+02:00"
        }
    ]
}
