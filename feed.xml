<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Finecloud</title>
    <link href="https://www.finecloud.ch/feed.xml" rel="self" />
    <link href="https://www.finecloud.ch" />
    <updated>2022-06-10T14:58:43+02:00</updated>
    <author>
        <name>Finecloud</name>
    </author>
    <id>https://www.finecloud.ch</id>

    <entry>
        <title>Netzwerkkommunikation mit Java</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/netzwerkkommunikation-mit-java.html"/>
        <id>https://www.finecloud.ch/netzwerkkommunikation-mit-java.html</id>
            <category term="writer"/>
            <category term="softwareentwicklung"/>
            <category term="socket"/>
            <category term="reader"/>
            <category term="network"/>
            <category term="java.io"/>
            <category term="java"/>
            <category term="dev"/>
            <category term="bufferedwriter"/>

        <updated>2022-06-10T14:58:43+02:00</updated>
            <summary>
                <![CDATA[
                    In Java gibt es keinen nennenswerten Unterschied wischen I/O mit Daten und I/O mit Netzwerkverbindungen. In beiden Fällen basiert die Ein- und Ausgabe auf InputStream und OutputStream, der Unterschied liegt nur darin, wo diese Datenströme herkommen. Bei der Netzwerkkommunikation mit dem TCP-Protokoll kommen sie aus&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>In Java gibt es keinen nennenswerten Unterschied wischen I/O mit Daten und I/O mit Netzwerkverbindungen. In beiden Fällen basiert die Ein- und Ausgabe auf InputStream und OutputStream, der Unterschied liegt nur darin, wo diese Datenströme herkommen. Bei der Netzwerkkommunikation mit dem TCP-Protokoll kommen sie aus einem Socket. Bei UDP wird die Klasse DatagramSocket verwendet, welche nicht auf Streams basiert.</p>
<p>Socket hat zwar eine lange Liste von Methoden, aber bei der grundlegenden Verwendung kann man die meisten davon ignorieren.</p>
<h3>Client-Seite</h3>
<p><code>String nachricht = in.readLine();</code><br><code>try (Socket verbindung = new Socket("localhost", 23456)){</code><br><code>    BufferedReader reader = new BufferedReader(</code><br><code>     new InputStreamReader(verbindung.getInputStream())); </code><br><code>    BufferedWriter writer = new BufferedWriter(</code><br><code>     new OutputStreamWriter(verbindung.getOutputStream()));</code><br><code>    writer.write(nachricht);</code><br><code>    writer.newLine();</code><br><code>    writer.flush();</code><br><code>    String antwort = reader.readLine();</code><br><code>}</code></p>
<p>Im Beispiel wird dem Socket im Konstruktor Adresse (IP oder Hostname) und Port des Servers angegeben, mit dem eine Verbindung hergestellt werden soll. Die Verbindung wird automatisch hergestellt und mit den Methoden getInputStream und getOutputStream kann man Daten vom Server empfangen und zum Server senden.</p>
<p>Einen kleinen Unterschied zwischen Netzwerk I/O und Datei I/O gibt es mit der flush-Methode. Sie sorgt dafür, dass der Schreibpuffer sofort weiterverarbeitet wird, auch wenn er noch nicht voll ist. Dabei wird der Strom aber nicht sofort geschlossen, denn es sollen nicht nur Daten in eine Richtung versendet werden, es soll echte Kommunikation in beide Richtungen stattfinden. Damit der Server eine Antwort schicken kann, die dann mit readLine gelesen werden kann, muss er zunächst die Nachricht vom Client erhalten und dazu muss der Client den Puffer leeren.</p>
<p>Ausserdem wird weder InputStream noch OutputStream geschlossen. Beide sind fest mit dem Socket verbunden, aus dem sie hergestellt wurden und wenn man einen der Ströme schliesst, wird auch der Socket geschlossen. Andersherum werden die Datenströme aber auch geschlossen, wenn man den Socket schliesst, deswegen reicht es, diesen als Ressource für den try-Block anzugeben.</p>
<h3>Server-Seite</h3>
<p>Ein einfaches Serverprogramm in Java zu schreiben, ist kaum anders als beim Client, nur die Herkunft des Sockets ändert sich:</p>
<p><code>ServerSocket server = new ServerSocket(23456);</code><br><code>try (Socket verbindung = server.accept()){</code><br><code>    BufferedReader reader = new BufferedReader(</code><br><code>     new InputStreamReader(verbindung.getInputStream())); </code><br><code>    BufferedWriter writer = new BufferedWriter(</code><br><code>     new OutputStreamWriter(verbindung.getOutputStream()));</code><br><code>    String nachricht = reader.readLine();</code><br><code>    writer.write(antwort);</code><br><code>    writer.flush();</code><br><code>}</code></p>
<p>Ein ServerSocket dient nicht direkt der Kommunikation, er wartet nur auf eingehende Verbindungen. Der Konstruktor-Parameter gibt den Port an, auf dem Verbindungen akzeptiert werden sollen; die Methode accept wartet, bis auf diesem Port eine Verbindung hergestellt wird. Und warten heisst hier wirklich warten: accept blockiert so lange, bis eine Verbindung zustande kommt. Wenn dies der Fall ist, gibt accept einen Socket zurück, mit dem man genauso verfahren kann, wie mit einem Socket auf der Client-Seite.</p>
<p>Wie demonstriert, wird nur eine Verbindung akzeptiert und verarbeitet. Für ein Beispiel ausreichend, werden für einen echten Serverprozess dagegen üblicherweise Verbindungen in einer Schleife akzeptiert und die Verarbeiten wird in einem neuen Thread durchgeführt, so dass dieser Thread erneut mit accept auf Verbindungen warten kann.</p>
<p>Hier ein Beispiel-Code für ServerSocket mit Threads:</p>
<p><code>ServerSocket server = new ServerSocket(23456);</code><br><code>while(!beendet){</code><br><code>    try (Socket verbindung = server.accept()){</code><br><code>        new Thread(() -&gt; verarbeiteVerbidnung(verbindung));</code><br><code>    }</code><br><code>}</code></p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Proxmox VE 7.2 Installation</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/proxmox-ve-72-installation.html"/>
        <id>https://www.finecloud.ch/proxmox-ve-72-installation.html</id>
            <category term="virtualization"/>
            <category term="unix"/>
            <category term="proxmox"/>
            <category term="lxc"/>
            <category term="linux"/>
            <category term="kvm"/>
            <category term="hci"/>
            <category term="container"/>

        <updated>2022-06-09T13:16:03+02:00</updated>
            <summary>
                <![CDATA[
                    Systemanforderungen Proxmox gibt folgende minimale Systemanforderungen an: Für produktive Workloads sind diese Anforderungen aber nicht gedacht. Daher sind die empfohlenen Systemanforderungen wie folgt: Da ich meine Proxmox Infrastruktur zum Start nur als Standalone LAB installieren will und für mein kleines Budget maximal viel Leistung erhalten&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <h3 id="mcetoc_1g53sim7k6lt"></h3>
<div class="post__toc">
<h3>Table of Contents</h3>
<ul>
<li><a href="#mcetoc_1g53sim7k6lu">Systemanforderungen</a></li>
<li><a href="#mcetoc_1g53sim7k6lv">Vorbereitung</a>
<ul>
<li><a href="#mcetoc_1g53sim7k6m0">BIOS Einstellungen</a></li>
<li><a href="#mcetoc_1g53sim7k6m1">BIOS Upgrade</a></li>
<li><a href="#mcetoc_1g53sim7k6m2">Installations Medium</a></li>
</ul>
</li>
<li><a href="#mcetoc_1g53sim7k6m3">Installation</a></li>
</ul>
</div>
<h3 id="mcetoc_1g53sim7k6lu">Systemanforderungen</h3>
<p>Proxmox gibt folgende minimale Systemanforderungen an:</p>
<ul>
<li>CPU: 64bit (Intel EMT64 or AMD64)</li>
<li>Intel VT/AMD-V capable CPU/Mainboard for KVM full virtualization support</li>
<li>RAM: 1 GB RAM, plus additional RAM needed for guests</li>
<li>Hard drive</li>
<li>One network card (NIC)</li>
</ul>
<p>Für produktive Workloads sind diese Anforderungen aber nicht gedacht. Daher sind die empfohlenen Systemanforderungen wie folgt:</p>
<ul>
<li>Intel EMT64 or AMD64 with Intel VT/AMD-V CPU ﬂag</li>
<li>Memory: Minimum 2 GB for the OS and Proxmox VE services, plus designated memory for guests. For Ceph and ZFS, additional memory is required; approximately 1GB of memory for every TB of used storage</li>
<li>Fast and redundant storage, best results are achieved with SSDs</li>
<li>OS storage: Use a hardware RAID with battery protected write cache (“BBU”) or non-RAID with ZFS (optional SSD for ZIL)</li>
<li>VM storage:
<ul>
<li>For local storage, use either a hardware RAID with battery backed write cache (BBU) or non-RAID for ZFS and Ceph. Neither ZFS nor Ceph are compatible with a hardware RAID controller</li>
<li>Shared and distributed storage is possible</li>
</ul>
</li>
<li>Redundant (Multi-)Gbit NICs, with additional NICs depending on the preferred storage technology and cluster setup.</li>
<li>For PCI(e) passthrough the CPU needs to support the VT-d/AMD-d ﬂag.</li>
</ul>
<p>Da ich meine Proxmox Infrastruktur zum Start nur als Standalone LAB installieren will und für mein kleines Budget maximal viel Leistung erhalten will, geht das nur auf Kosten von Redundanz und Verfügbarkeit, deshalb habe ich mich zum Start für folgende Hardware entschieden:</p>
<ul>
<li>Intel NUC10i7FNHN Barebone</li>
<li>Kingston SO-DDR4-RAM 32GB</li>
<li>Samsung SSD 970 EVO Plus NVMe M.2 500GB</li>
</ul>
<h3 id="mcetoc_1g53sim7k6lv">Vorbereitung</h3>
<h4 id="mcetoc_1g53sim7k6m0">BIOS Einstellungen</h4>
<p>Bevor wir mit der Installation starten, muss im BIOS des NUC überprüft werden ob die Virtualisierungs-Unterstützung des Prozessors aktiviert ist, dazu müssen folgende Settings aktiviert sein:</p>
<ul>
<li>Performance &gt; Processor &gt; Hyper-Threading (enabled)</li>
<li>Performance &gt; Processor &gt; Intel Turbo Boost Technology (checked)</li>
</ul>
<p>Secure Boot schalten wir aus:</p>
<ul>
<li>Boot &gt; Secure Boot &gt; Secure Boot &gt; Disabled</li>
</ul>
<p>Weiter empfiehlt es sich die Boot Reihenfolge so anzupassen das USB Geräte an erster Stelle kommen. Dazu unter:</p>
<ul>
<li>Boot &gt; Boot Priority &gt; Boot USB Devices Frist</li>
</ul>
<h4 id="mcetoc_1g53sim7k6m1">BIOS Upgrade</h4>
<p>Von einem pauschalen BIOS Upgrade habe ich abgesehen, da Intel die Frage "Wann soll ich ein BIOS Update machen?" wie folgt beantwortet:</p>
<blockquote>
<p>Update the BIOS on your computer only if the newer BIOS version can solve a specific problem. We don't recommend BIOS updates for computers that do not need it. </p>
<p>Quelle: <a href="https://www.intel.com/content/www/us/en/support/articles/000006714/intel-nuc.html" target="_blank" rel="nofollow noopener noreferrer">https://www.intel.com/content/www/us/en/support/articles/000006714/intel-nuc.html</a></p>
</blockquote>
<h4 id="mcetoc_1g53sim7k6m2">Installations Medium</h4>
<p>Proxmox empfiehlt die Installation via ISO File mittels einem USB Flash Drive. Dazu muss aber das ISO File zuerst in ein Image konvertiert werden, damit wir dieses Image so auf den USB Stick schreiben können, damit wir davon booten können. Unter MacOS geht das am einfachsten so:</p>
<ol>
<li>Neues Terminal öffnen (suche nach Terminal in Spotlight)</li>
<li>Konvertieren der .iso Datei nach .dmg:<br><code># hdiutil convert -format UDRW -o proxmox-ve_*.dmg proxmox-ve_*.iso</code></li>
<li>Damit wir eine aktuelle Liste der verfügbaren Geräte erhalten:<br><code># diskutil list</code></li>
<li>Nun stecken wir den USB Stick ein und geben den vorherigen Befehl nochmals ein, damit wir herausfinden können, welche Gerätebezeichnung vergeben wurde. (sollte etwas mit, /dev/diskX sein).<br><code># diskutil list</code><br><code># diskutil unmountDisk /dev/diskX</code></li>
<li>Nun schreiben wir das Image auf den USB Stick. Achtung: das X muss mit der Disk Nummer des letzten Befehls ersetzt werden. (rdiskX anstelle von diskX ist Absicht, das erhöht die Schreibgeschwindikeit):<br><code># sudo dd if=proxmox-ve_*.dmg of=/dev/rdiskX bs=1m</code></li>
</ol>
<h3 id="mcetoc_1g53sim7k6m3">Installation</h3>
<p>Zum Start des Installations wizards erhält man folgende Optionen:</p>
<ul>
<li>Install Proxmox</li>
<li>Rescue Boot</li>
<li>Test Memory</li>
</ul>
<p>Mit <em>Install Proxmox</em> kann die Installation gestartet werden. Nachdem die ELUA akzeptiert wurde, müssen wir uns Entscheiden welches Filesystem wir verwenden wollen und auf welche Harddisk Proxmox installiert werden soll. <strong>Da ich nur eine NVMe SSD habe, gibt es nur diese Auswahl der Disk. Als Filesystem will ich ein ZFS ausprobieren, was eigentlich normalerweise erst bei mehreren Disks sinnvoll ist.</strong></p>
<p><strong>Obwohl ZFS mehr Memory frisst (angeblich muss man mit mindestens Pauschal 4GB rechnen plus 1GB Memory pro TB Raw Datenspeicher) möchte ich auf die folgenden ZFS Vorteile welche in Proxmox angeblich nur mit ZFS integriert nicht verzichten:</strong></p>
<ul>
<li><strong>Encryption</strong></li>
<li><strong>Snapshots/Backups</strong></li>
<li><strong>Compression</strong></li>
</ul>
<p>Da ich aber nur eine Disk habe verzichte ich auf einen RAID Level, und nehme die Option: <em>zfs (RAID0)</em></p>
<p>Als nächstes werden die <em>Location and Time Zone</em> definiert. Weiter muss ein Kennwort definiert werden für den Proxmox root Account, bevor die Netzwerk Angaben angefragt werden und schliesslich die Installation gestartet werden kann.</p>
<p>Sobald die Installation erfolgt ist, kann das Proxmox Web-UI von einem anderen Gerät aus unter <em>https://&lt;proxmox-ip&gt;:8006/ </em>geöffnet werden.</p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Proxmox VE 7.2 Übersicht</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/proxmox-ve-intro.html"/>
        <id>https://www.finecloud.ch/proxmox-ve-intro.html</id>
            <category term="virtualization"/>
            <category term="unix"/>
            <category term="proxmox"/>
            <category term="lxc"/>
            <category term="linux"/>
            <category term="kvm"/>
            <category term="hci"/>
            <category term="container"/>

        <updated>2022-06-08T15:46:47+02:00</updated>
            <summary>
                <![CDATA[
                    Die Architektur Proxmox VE ist eine Plattform zum Betrieben von virtuellen Maschinen und Container. Dabei ist die gesamte Proxmox VE Plattform open source und baisert auf Debian Linux. die VE Plattform besteht aus zwei virtualisierungs-technologien: Proxmox gibt es als single node, oder als Cluster mit&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="post__toc">
<h3>Table of Contents</h3>
<ul>
<li><a href="#mcetoc_1g4tdpel45mg">Die Architektur</a></li>
<li><a href="#mcetoc_1g4tdhqsl5l5">Zentrales Management</a></li>
<li><a href="#mcetoc_1g4tdhqsl5l6">Storage</a></li>
<li><a href="#mcetoc_1g4tdhqsl5l7">Backup und Restore</a></li>
<li><a href="#mcetoc_1g4tdhqsl5l8">High Availability Cluster</a></li>
<li><a href="#mcetoc_1g4tdhqsl5l9">Networking</a></li>
<li><a href="#mcetoc_1g4tdhqsl5la">Firewall</a></li>
<li><a href="#mcetoc_1g4tdhqsl5lb">Hyper-converged Infrastructure (HCI)</a>
<ul>
<li><a href="#mcetoc_1g4tdlsh25m7">HCI Storage</a></li>
</ul>
</li>
<li><a href="#mcetoc_1g4tdcg765ga">Feature Übersicht</a></li>
</ul>
</div>
<h3 id="mcetoc_1g4tdpel45mg">Die Architektur</h3>
<p><img loading="lazy" src="https://www.finecloud.ch/media/posts/22/Screenshot-2022-06-06-at-23.00.20.png" sizes="100vw" srcset="https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-xs.png 300w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-sm.png 480w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-md.png 768w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-lg.png 1024w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-xl.png 1360w ,https://www.finecloud.ch/media/posts/22/responsive/Screenshot-2022-06-06-at-23.00.20-2xl.png 1600w"  alt="Architektur" width="765" height="586"></p>
<p>Proxmox VE ist eine Plattform zum Betrieben von virtuellen Maschinen und Container. Dabei ist die gesamte Proxmox VE Plattform open source und baisert auf Debian Linux. die VE Plattform besteht aus zwei virtualisierungs-technologien:</p>
<ul>
<li>Kernel-based Virtual Machine (KVM)</li>
<li>Container-based virtualization (LXC)</li>
</ul>
<p>Proxmox gibt es als single node, oder als Cluster mit Anzahl n Nodes. Das gesamte Management der Plattform kann über ein Web basiertes Management Interface erfolgen.</p>
<h3 id="mcetoc_1g4tdhqsl5l5">Zentrales Management</h3>
<p>Proxmox ermöglicht es sämtliche Management Arbeiten zentral auszuführen, egal ob es sich um einen Cluster mit n Nodes handelt, oder ob es nur ein Single Node ist.  Damit lässt sich der gesamte Cluster von jedem einzelnen Node aus verwalten. Das JavaScript basierte Web-UI erlaubt die Verwaltung von Storage, Containern sowie den KVM Guest VMs. Darüberhinaus kann über das Web-UI die History, Syslogs, Backup und Restore Jobs, live-migration oder HA Aktivitäten eingesehen werden.</p>
<p>Was Proxmox einmalig macht ist deren Cluster File System: pmxcfs, ein Datenbank getriebener Speicher zum Speichern von Konfigurationsdateien. Mittels corosync werden diese Dateien in Echtzeit zwischen allen Nodes im Cluster repliziert. Das File System speichert alle Daten in einer persistenten Datenbank auf der Disk, unabhängig davon wird eine kopier der Datenbank im RAM, mit einer maximalen Speichergrösse von 30MB abgelegt, was für mehr als tausend VMs ausreicht.</p>
<p>Für fortgeschrittene Anwender kann Proxmox auch via CLI, also Unix Shell oder mit Windows Powershell oder über die Rest-API verwaltet werden. Die API unterstützt JSON als primäres Datenformat.</p>
<p>Für die Authentifizierung unterstützt Proxmox Microsoft Active Directory, LDAP, Linux PAM standard authentifizierung oder den eigenen built-in Proxmox VE auth Server.</p>
<h3 id="mcetoc_1g4tdhqsl5l6">Storage</h3>
<p>Proxmox verfügt über ein sehr flexibles Storage Modell. VM Images können lokal auf einem oder mehreren Local Storages gespeichert werden, oder auf einem shared Storage wie NFS oder einem SAN. Es können sämtliche für Debian Linux verfügbaren Storage-Technologien verwendet werden.</p>
<p>Für den Betrieb eines Clusters sollte man unbedingt einen Shared Storage verwenden um die VMs zu speichern, damit man auch von der live-migrate Funktion gebrauch machen kann. Diese ermöglicht es eine VM im laufenden Betrieb von einem Node auf einen anderen zu verschieben. Dabei haben sämtliche Nodes im Cluster direkten zugriff auf die VM Disk Images. Nachfolgende Liste listet die unterstützten Storage auf:</p>
<p>Netzwerk-Storage:</p>
<ul>
<li>LVM Group (network backing with iSCSI targets)</li>
<li>iSCSI target</li>
<li>NFS Share</li>
<li>CIFS Share</li>
<li>Ceph Share</li>
<li>Directly use iSCSI LUNs</li>
<li>GlusterFS</li>
</ul>
<p>Lokale Storage:</p>
<ul>
<li>LVM Group (local backing devices like block devices, FC devices, DRBD, ect.)</li>
<li>Directory (storage on existing filesystem)</li>
<li>ZFS</li>
</ul>
<h3 id="mcetoc_1g4tdhqsl5l7">Backup und Restore</h3>
<p>Das integrierte Backup Tool names <em>vzdump </em>kreiert konsistente Snapshots von laufenden Containern und KVM Guests. Dabei wird ein Archiv der VM oder Container Daten erstellt, welches auch die Konfiguration der VM/CT beinhaltet.</p>
<h3 id="mcetoc_1g4tdhqsl5l8">High Availability Cluster</h3>
<p>Ein multi-node Proxmox VE HA Cluster erlaubt den Betrieb von hochverfügbaren virtual servers. Der Cluster basiert auf bewährte Linux HA Technologien, welche eine stabile und zuverlässigen HA Service ermöglichen.</p>
<h3 id="mcetoc_1g4tdhqsl5l9">Networking</h3>
<p>Proxmox erlaubt den Einsatz von VLANS (IEEE 802.1q) und Netzwerk bonding/aggregation. Damit ist es möglich auch komplexere, flexible virtuelle Netzwerke für die Proxmox VE Hosts aufzubauen und sämtliche Funktionen des Linux Netzwerk Stacks zu nutzen.</p>
<p>Standardmässig kommt Proxmox mit einem bridge Netzwerkmodel.  Alle VMs können diese bridge verwenden, so als wären alle Guests mit virtuellen Netzwerkkabel zu einem physikalischen Netzwerk zusammengeschlossen. Jeder Netzwerkkarte kann eine TCP/IP Konfiguration zugewiesen werden.</p>
<h3 id="mcetoc_1g4tdhqsl5la">Firewall</h3>
<p>Die integrierte Firewall ermöglicht es Netzwerk Packete von jedem VM oder Container Interface zu filtern. Firewall Rules können in <em>Security Groups</em> gruppiert werden.</p>
<h3 id="mcetoc_1g4tdhqsl5lb">Hyper-converged Infrastructure (HCI)</h3>
<p>HCI Umgebungen sind besonders nützlich für Deployments in einer Infrastruktur mit hohen Anforderungen und tiefem administrations Budget.</p>
<p id="mcetoc_1g4tdlsh25m6">Vorteile von HCI sind:</p>
<ul>
<li>Skalierbarkeit: nahtlose Erweiterung von Computing, Netzwerk und Storage</li>
<li>Tiefe Kosten: Proxmox VE ist open source und integriert alle benötigten Komponenten und kann damit eine teure Computing/Storage Infrastruktur ersetzen</li>
<li>Daten-Schutz und Effizienz: Services wie Backup und Disaster Recovery sind direkt integriert</li>
<li>Kein Vendor-Lock-in dank open source</li>
</ul>
<h4 id="mcetoc_1g4tdlsh25m7">HCI Storage</h4>
<p>Proxmox unterstützt die nahtlose Integration von HCI Storage Infrastrukturen wie ceph oder ZFS.</p>
<ul>
<li>ceph: bietet self-healing und self-managing shared, zuverlässig und hoch skalierbaren Storage.</li>
<li>ZFS: kombiniert File System und Local Volume Manager mit erweitertem Schutz vor Datenkorruption, diversen RAID modi und schnellen und günstigen Snapshots. </li>
</ul>
<h3 id="mcetoc_1g4tdcg765ga">Feature Übersicht</h3>
<ul>
<li>Open source software</li>
<li>Kein Vendor lock-in</li>
<li>Linux kernel</li>
<li>Schnelle installation, einfach zu verwenden</li>
<li>Web-basiertes Management Interface</li>
<li>REST API</li>
<li>Grosse aktive Community</li>
<li>Tiefe Administrationskosten und einfaches deployment</li>
</ul>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Testen von I/O-Operationen</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/testen-von-io-operationen.html"/>
        <id>https://www.finecloud.ch/testen-von-io-operationen.html</id>
            <category term="writer"/>
            <category term="verzeichnisse"/>
            <category term="softwareentwicklung"/>
            <category term="reader"/>
            <category term="java.nio.files"/>
            <category term="java.io.file"/>
            <category term="java.io"/>
            <category term="java"/>
            <category term="dev"/>
            <category term="dateien"/>

        <updated>2022-06-06T22:45:58+02:00</updated>
            <summary>
                <![CDATA[
                    Das Problem von I/O-Operationen ist, dass sie nur schlecht testbar sind. Ihre Testfälle müssen sich darauf verlasse, dass bestimmte Dateien vorhanden sind, und einen bestimmten Inhalt haben. Sie können den Testfällen zwar entsprechende Dateien beilegen, aber dann müssen Sie Dateien mit Ihren Testfällen ausliefern. Es&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Das Problem von I/O-Operationen ist, dass sie nur schlecht testbar sind. Ihre Testfälle müssen sich darauf verlasse, dass bestimmte Dateien vorhanden sind, und einen bestimmten Inhalt haben. Sie können den Testfällen zwar entsprechende Dateien beilegen, aber dann müssen Sie Dateien mit Ihren Testfällen ausliefern. Es gibt Strategien das zu vermeiden.</p>
<p>Wichtig ist, dass man für Lese- und Schreiboperationen niemals <em>File</em> als Methodenparamater deklarieren sollte, sondern immer einen <em>Reader</em> oder <em>Writer</em> (bzw. <em>InputStream</em> oder <em>OutputStream</em>). Dadurch wird der Code sofort besser testbar, denn man kann aus dem Testfall einen <em>StringReader</em> (oder <em>StringWriter</em>) übergeben. Es handelt sich dabei um einen vollwertigen <em>Reader</em> (bzw. <em>Writer</em>), der genau wie jeder andere Reader verwendet werden kann, seine Daten aber nicht aus einer Datei oder einer Netzwerkverbindung liest, sondern aus einem String, den Sie im Konstruktor übergeben. So hat der Testfall die volle Kontrolle darüber, welche Daten die zu testende Methode zu sehen bekommt:</p>
<p><code>public static final String TESTDATEN = </code><br><code> "2013\t0.2\t-0.7\t0.1\t8.1\t11.8\t15.7\t19.5\t17.9\t13.3\t10.6\t4.6\t3.6\n" +</code><br><code> "2012\t1.9\t-2.5\t6.9\t8.1\t14.2\t15.5\t17.4\t18.4\t13.6\t8.7\t5.2\t1.5";</code><br><br><code>@Test</code><br><code>public void testLiesTemperaturdaten() {</code><br><code>    Reader testdaten = new StringReader(TESTDATEN);</code><br><code>    Temperaturstatistik statistik = Temperaturstatistik.liesDaten(testdaten);</code><br><code>    assertNotNull(statistik.getJahr(2013);</code><br><code>    //weitere Asserts folgen</code><br><code>}</code></p>
<p>Analog dazu funktioniert das auch beim Schreiben in einen StringWriter:</p>
<p><code>@Test</code><br><code>public void testSchreibePlayliste() {</code><br><code>    StringWriter testWriter = new StringWriter();</code><br><code>    Playlist playlist = new Playlist();</code><br><code>    playlist.addSong(...);</code><br><code>    playlist.schreibeNach(testWriter);</code><br><code>    assertEquals("erwarteter Inhalt", testWriter.toString);</code><br><code>}</code></p>
<p>Die <em>toString</em>-Methode des <em>StringWriter</em> gibt alle Daten, die hineingeschrieben wurden, als einen String zurück. Sie können dadurch in einem Testfall ganz leicht vergleichen, ob der Inhalt dem erwarteten Inhalt entspricht. Analog dazu kann ByteArrayInputStream und ByteArrayOutputStream genutzt werden, um diese Aufgabe mit einem byte-Array für Binärdateien zu erfüllen.</p>
<p>Schwieriger wird es, wenn der Testfall wirklich Dateien benötigt, zum Beispiel, weil die zu testende Methode Dateien in einem Verzeichnis suchen soll. Da kann man mit temporären Dateien arbeiten. Die Methode File.createTempFile erzeugt eine Datei im Verzeichnis für temporäre Dateien Ihres Betriebsystems. So kann ein Präfix übergeben werden, der klar macht, woher die Datei stammt und eine Dateiendung. Als Rückgabewert erhält man das File-Objekt der so angelegten Datei. Eine temporäre Datei wird aber nicht automatisch wieder gelöscht. Um am Ende des Tests wieder aufzuräumen, sollten Sie daher an jeder erzeugten Datei noch deleteOnExit rufen, dann stellt Java sicher, dass diese Dateien wieder entfernt werden:</p>
<p><code>@Test</code><br><code>public void testMitDatei() throws IOException {</code><br><code>    File tempDatei = File.createTempFile(getClass().getName(), ".mp3");</code><br><code>    tempDatei.deleteOnExit();</code><br><code>    //Test durchführen</code><br><code>}</code></p>
<p>Als Empfehlung und gute Angewohnheit bietet es sich an, den Klassennamen als Präfix für temporäre Dateien zu verwenden. Als optionalen dritten Parameter kann createTempFile ein Verzeichnis übergeben werden, in welchem die Datei angelegt werden soll, falls man die Datei nicht im temporären Verzeichnis des Betriebssystems anlegen möchte.</p>
<p>Wenn man ein temporäres Verzeichnis anlegen möchte, trifft man leider erneut auf den Bruch zwischen java.io und java.nio: Die Methode, die temporäre Ordner anlegt, findet man nur in der Files-Klasse, dementsprechend erhält man auch ein Path-Objekt zurück, aus dem man dann selbst wieder ein File machen muss:</p>
<p><code>@Test</code><br><code>public void testMitVerzeichnis() throws IOException {</code><br><code>    File tempVerzeichnis = Files.createTempDirectory("mp3test").toFile();</code><br><code>    tempVerzeichnis.deleteOnExit();</code><br><code>    File tempDatei = File.createTempFile(getClass().getName(), ".mp3",</code><br><code>        tempVerzeichnis);</code><br><code>    tempDatei.deleteOnExit();</code><br><code>    //Test durchführen</code><br><code>}</code></p>
<p> </p>
<p> </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Java Reader und Writer</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/java-reader-und-writer.html"/>
        <id>https://www.finecloud.ch/java-reader-und-writer.html</id>
            <category term="softwareentwicklung"/>
            <category term="reader"/>
            <category term="java.nio.files"/>
            <category term="java.io.file"/>
            <category term="java.io"/>
            <category term="java"/>
            <category term="dev"/>
            <category term="dateien"/>
            <category term="bufferedwriter"/>

        <updated>2022-06-06T23:12:59+02:00</updated>
            <summary>
                <![CDATA[
                    Lese und Schreiboperationen an Dateien sind in Java streambasiert. Diese Streams haben aber nichts mit der Stream-API zu tun. Streambasierte I/O bedeutet, dass nicht alle Dateien im Speicher behalten werden müssen, damit man mit ihnen Arbeiten kann. Man muss also nicht den gesamten Dateiinhalt lesen,&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="post__toc">
<h3>Table of Contents</h3>
<ul>
<li><a href="#mcetoc_1g4tdq62j5mq">Lesen und Schreiben von Textdaten</a></li>
<li><a href="#mcetoc_1g4tdq62j5mr">Puffern und zeilenweise lesen</a></li>
<li><a href="#mcetoc_1g4tdq62j5ms">Schreiben mit Writer</a></li>
</ul>
</div>
<p>Lese und Schreiboperationen an Dateien sind in Java streambasiert. Diese Streams haben aber nichts mit der Stream-API zu tun. Streambasierte I/O bedeutet, dass nicht alle Dateien im Speicher behalten werden müssen, damit man mit ihnen Arbeiten kann. Man muss also nicht den gesamten Dateiinhalt lesen, bevor man ihn verarbeiten kann. Folglich muss man bei einer Netzwerkverbindung nicht darauf warte, dass alle Daten eingegangen sind, stattdessen kann man die Daten Stück für Stück aus einem <em>InputStream</em> lesen und verarbeiten. Im Idealfall kann das gerade eingelesene Datenstück bereits wieder aus dem Speicher entfernt werden, bevor das nächste Datenstück gelesen wird. Genau so können auch Datenstücke in einen OutputStream bereits geschrieben werden sobald diese zur Verfügung stehen und muss nicht zuerst gewartet werden, bis alle Daten bereit sind.</p>
<p>Java macht einen Unterschied ob, mit Textdaten oder mit Binärdaten gearbeitet wird. Textdaten werden mit einem <em>Reader</em> gelesen und mit einem <em>Writer</em> geschrieben, für Binärdaten gibt es dafür <em>InputStream</em> und <em>OutputStream</em>.</p>
<h3 id="mcetoc_1g4tdq62j5mq">Lesen und Schreiben von Textdaten</h3>
<p>Folgender Code liest Daten zeilenweise ein:</p>
<p><code>try (BufferedReader reader = new BufferedReader(new FileReader(dateiname))){</code><br><code>    …</code><br><code>}</code></p>
<p>Das ist bereits eine spezialisierte Funktion, die nur BufferedReader bietet. Andere Reader, zum Beispiel der <em>FileReader</em>, wissen nichts von Zeilen, sie arbeiten nur mit Zeichen. Dazu bietet <em>Reader</em> eine parameterlose Methode read, die genau ein Zeichen liest. Das ist zwar die für den Entwickler einfachste Variante, sie ist aber auch äusserst ineffektiv. Der komplexere, aber bessere Weg, aus einem <em>Reader</em> zu lesen, ist ein char[] als Puffer zu benutzen:</p>
<p><code>File quelle = new File(…);</code><br><code>char[] buffer = new char[1024];</code><br><code>try (Reader reader = new FileReader(quelle)) {</code><br><code>    int gelesen;</code><br><code>    while ((gelesen = reader.read(buffer)) &gt; -1) {</code><br><code>        char[] geleseneDaten = (gelesen == buffer.length)</code><br><code>                ? buffer</code><br><code>                : Arrays.copyOf(buffer, gelesen);</code><br><code>        vearbeitePuffer(geleseneDaten);</code><br><code>    }</code><br><code>}</code></p>
<p>Damit wird wesentlich effizienter gelesen, als Zeichen für Zeichen. Mit jedem Aufruf von read wird der Puffer gefüllt. Der Rückgabewert ist die Anzahl Zeichen, die vom Stream gelesen wurden. Meist entspricht er der Grösse des Puffers, es können aber weniger Zeichen gelesen werden, wenn das Ende der Daten erreicht ist oder gerade in diesem Moment keine Daten mehr zur Verfügung stehen. Wenn das Ende des Datenstroms erreicht ist, gibt read -1 zurück: Daten werden in einer Schleife gelesen und verarbeitet, bis dieser Punkt erreicht ist.</p>
<p><strong>Wenn weniger Zeichen gelesen werden, als die Puffergrösse gross ist, wird der Rest des Puffers nicht verändert. Das bedeutet, dass am Ende des char-Arrays Daten aus dem Vorherigen Schleifen-Durchlauf stehen können. Deswegen werden die gelesenen Daten, falls es weniger als die Puffergrösse waren, in ein neues Array kopiert; so kann die Methode <em>verarbeitePuffer</em> immer mit einem vollständigen Array arbeiten und muss sich keine Sorgen um übrig gebliebene Daten am Ende des Arrays machen. </strong>Es ist zwar performanter, der verarbeitenden Methode das teilweise gefüllte Array und den Endindex zu übergeben, die gezeigt Variante ist aber weniger fehleranfällig, weil man in <em>verarbeitePuffer</em> nicht darauf achten muss, wann man mit lesen aufhört.</p>
<p><strong>Es ist sehr wichtig, dass man eine Datei nach dem Zugriff darauf wieder schliesst.</strong> Im Beispiel geschieht das implizit durch das Statement try-with-resources, das an seinen Ressourcen automatisch close aufruft. Sollte man aus irgendeinem Grund dieses Statement nicht verwenden können oder wollen, dann muss man selbst sicherstellen, dass der Reader (oder Writer, InputStream, OutputStream oder jedes Objekt, das auf eine Datei zugreift) ordnungsgemäss geschlossen wird.</p>
<p><code>public void liesAusDatei(File quelle) throws IOException{</code><br><code>    Reader reader = null;</code><br><code>    try {</code><br><code>        reader =  new BufferedReader(new FileReader(quelle));</code><br><code>        //Daten lesen und verarbeiten</code><br><code>    } finally {</code><br><code>        if (reader != null){</code><br><code>            reader.close();</code><br><code>        }</code><br><code>    }</code><br><code>}</code></p>
<p>Dieser Code ist etwas unhandlicher und hat zwei Unschönheiten. Die Reader-Variable muss ausserhalb des try-Blocks deklariert werden, da try und Finally keinen gemeinsamen Scope haben. Ausserdem muss im finally-Block geprüft werden, ob der Reader nicht null ist. Das kann passieren, wenn schon beim Erzeugen des Readers eine Exception auftritt, weil Beispielsweise die Datei nicht existiert. In diesem Fall gibt es keinen Reader, der geschlossen werden kann, und ohne die entsprechende Prüfung käme es zu einer weiteren NullPointerException.</p>
<p>Ein weiteres Problem ist, dass auch reader.close eine IOException werfen kann. Im Beispiel werden innerhalb der Methode liesAusDatei keine Fehler behandelt, alle Fehler werden an den Aufrufer weitergereicht. Im schlimmsten Fall kann es so passieren, dass sowohl im try- als auch im finally-Block Fehler geworfen werden. Der Aufrufer erhält dann nur die Exception aus dem finally-Block, obwohl sie wahrscheinlich nur eine Konsequenz der Exception aus dem try-Block ist. <strong>Das untere Code-Beispiel ist also länger, komplexer und fehleranfälliger. Es gibt somit keinen Grund, diese Variante zu bevorzugen, wenn die Java-Version try-with-resources unterstützt.</strong></p>
<h3 id="mcetoc_1g4tdq62j5mr">Puffern und zeilenweise lesen</h3>
<p>Das Puffern der Daten in einem char[] kann man sich theoretisch sparen, wenn man einen BufferedReader einsetzt. Dessen Hauptaufgabe ist es, zu verhindern, dass Daten Byte für Byte von der Festplatte gelesen werden. Dazu liest er immer einen Puffer voll Daten ein, genau wie im oberen Beispiel. Nachfolgende read-Aufrufe werden dann aus dem Puffer bedient, solange dieser noch genügend Daten enthält, erst danach wird wieder auf die Festplatte zugegriffen.</p>
<p>Als Nebeneffekt seines Puffers hat der BufferedReader aber eine weitere nützliche Fähigkeit: Er kann Textdateien zeilenweise lesen. BufferedReader bietet sowohl die Methode readLine, die die nächste Zeile der Datei liefert, als auf die Methode lines, die alle Zeilen der Datei in einem Stream liefert. Wenn der Inhalt der Datei zeilenorientiert ist, dann ist das viel praktischer, als Daten Zeichen für Zeichen oder Puffer für Puffer einzulesen und selbst nach den Umbrüchen zu suchen.</p>
<p>Eine BufferedReader lässt sich aus jedem anderen Reader erzeugen, indem man diesen als parameter an den Konstruktor von BufferedReader übergibt:</p>
<p><code>try (BufferedReader reader = new BufferedReader(new FileReader(quelle))) {</code><br><code>    String zeile;</code><br><code>    while ((zeile = reader.readLine()) != null){</code><br><code>        verarbeiteZeile(zeile);</code><br><code>    }</code><br><code>}</code></p>
<p>Der zugrunde liegende FileReader wird in einem BufferReader verpackt, um die Fähigkeit zu puffern und zeilenweise zu lesen hinzuzufügen. Das ist eine Anwendung des Decorator-Entwurfsmusters, das für Ein- und Ausgabe in Java extensiv zum Einsatz kommt. Man muss in diesem Fall nur den BufferedReader schliessen, dessen close-Methode ruft automatisch die close-Methode des dekorierten Readers auf.</p>
<h3 id="mcetoc_1g4tdq62j5ms">Schreiben mit Writer</h3>
<p>Das Schreiben in eine Date funktioniert fast genau so wie das Lesen aus einer Datei. Man erzeugt ein FileWriter-Objekt, dekoriert es noch mit einem BufferedWriter, schreibt Daten hinein und schliesst den Writer wieder:</p>
<p><code>try (BufferedWriter writer = new BufferedWriter(new FileWriter(ziel))) {</code><br><code>    for (String zeile : zeilen){</code><br><code>        writer.write(zeile);</code><br><code>        writer.newLine();</code><br><code>    }</code><br><code>}</code></p>
<p>So schreibt man eine Datei Zeile für Zeile. Writer sind in vielerlei Hinsicht das Spiegelbild von Readern. Sie besitzen eine Methode, die einzelne char-Werte schreibt und eine Methode, die ein ganzes char[] schreibt - man kann einen Schreibpuffer erzeugen, indem man seinen Writer mit einem BufferedWriter dekoriert und auch den Writer in diesem Fall schliesst, wenn man damit fertig ist. Writer selbst kennen das Konzept der Zeile ebenfalls nicht. Wenn man zeilenweise schreiben möchte, dann ist der beste Weg, einen BufferedWriter und seine Methode newLine zu verwenden, um an Ende jeder Zeile einen Umbruch zu erzeugen.</p>
<p> </p>
<p> </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Dateien und Verzeichnisse unter Java</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/dateien-und-verzeichnisse-unter-java.html"/>
        <id>https://www.finecloud.ch/dateien-und-verzeichnisse-unter-java.html</id>
            <category term="verzeichnisse"/>
            <category term="softwareentwicklung"/>
            <category term="java.nio.files"/>
            <category term="java.io.file"/>
            <category term="java.io"/>
            <category term="java"/>
            <category term="dev"/>
            <category term="dateien"/>

        <updated>2022-06-06T23:13:08+02:00</updated>
            <summary>
                <![CDATA[
                    Dateioperationen mit java.io werden in Java immer, direkt oder indirekt, durch ein Objekt des Typs java.io.File abgebildet. Dabei kann File aber nicht selbst aus Dateien lesen, oder in sie schreiben, dazu benötigt man einen Reader oder Writer (für Textdateien) resp. einen InputStream oder OutputStream (für&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="post__toc">
<h3>Table of Contents</h3>
<ul>
<li><a href="#mcetoc_1g4tdqg1s5n6">Dateien und Pfade</a></li>
<li><a href="#mcetoc_1g4tdqg1s5n7">Dateioperationen aus "Files"</a></li>
<li><a href="#mcetoc_1g4tdqg1s5n8">Verzeichnisse</a></li>
</ul>
</div>
<p>Dateioperationen mit java.io werden in Java immer, direkt oder indirekt, durch ein Objekt des Typs java.io.File abgebildet. Dabei kann File aber nicht selbst aus Dateien lesen, oder in sie schreiben, dazu benötigt man einen Reader oder Writer (für Textdateien) resp. einen InputStream oder OutputStream (für Binärdateien).</p>
<h3 id="mcetoc_1g4tdqg1s5n6">Dateien und Pfade</h3>
<p>Ein File wird immer aus einer Pfadangabe, entweder <em>absolut</em> oder <em>relativ</em> erzeugt. Absolut geht von einem Wurzelverzeichnis aus, zum Beispiel C:\ unter Windows, oder / unter Linux. Ein relativer Pfad bezieht sich dagegen auf das aktuelle Verzeichnis des Benutzers, normalerweise von dort aus woher das Programm aufgerufen wurde. Wenn die Datei unter dem angegebenen Pfad nicht existiert, wird auch keine entsprechende Datei unter dem definierten Pfad angelegt:</p>
<p><code>File windowsDatei = new File("C:\\home\\user\\text.txt");</code><br><code>File linuxDatei = new File("/home/user/text.txt");</code></p>
<p>Pfade werden also je nach OS unterschiedlich angegeben. Für Windows Pfade als Konstante sind effektiv zwei Doppel Backslashes zu verwenden! Solange die Pfadeingabe vom Benutzer selbst kommt, macht das keine Probleme. Wenn aber aus dem Programm heraus Dateipfade erzeugt werden müssen, dann müssen Sie auf diese Details acht geben. Das richtige Zeichen zum trennen von Verzeichnissen in einer Pfadangabe findet sich in der Konstanten File.separator. Damit lässt sich einen Pfad OS unabhängig erstellen: </p>
<p><code>File datei = new File(File.separator + "home" </code><br><code>    + File.separator + "user"</code><br><code>    + File.separator + "text.txt");</code></p>
<p>Unter Unix-basierten Systemen funktioniert dieser Code. Unter Windows bleibt das Problem mit dem Laufwerksbuchstaben. Dazu kann unabhängig vom OS, alle Wurzelverzeichnisse aufgelistet werden. Dazu kennt File die statische Methode listRoots. So lässt sich ein OS unabhängiger Code schreiben:</p>
<p><code>public File waehleWurzel(){</code><br><code>    File[] wurzeln = File.listRoots();</code><br><code>    if (wurzeln.length == 1){</code><br><code>        return wurzeln[0];</code><br><code>    } else {</code><br><code>        System. out.println("Bitte wählen Sie eine Wurzel");</code><br><code>        for (int i = 0; i &lt; wurzeln.length; i++){</code><br><code>            System.out.println(i + ": " + wurzeln[i]);</code><br><code>        }</code><br><code>        int index = liesZahl();</code><br><code>        return wurzeln[index];</code><br><code>    }</code><br><code>}</code></p>
<p>Doch das reicht immer noch nicht ganz, denn unter Windows kann es hier mehrere Einträge geben, je nachdem wieviele Laufwerke vorhanden sind (C:\, D:\ ...). In diesem Fall wird der Benutzer geben, ein Laufwerk auszuwählen. Anschliessend kann ein neues File-Objekt relativ zur ausgewählten Wurzel erzeugt werden, indem dies dem Konstruktor angegeben wird:</p>
<p><code>File wurzel = waehleWurzel();</code><br><code>File datei = new File(wurzel, "home"</code><br><code> + File.separator + "user"</code><br><code> + File.separator + "text.txt");</code></p>
<p>Ob eine Datei überhaupt existiert kann mit der Methode exists überprüft werden. Da ein File lediglich die objektorientierte Repräsentation eines Pfades ist, kann man Files erzeugen, ohne das diese Dateien bereits existieren. Falls keine Datei existiert kann eine neue Datei mit createNewFile oder mit mkdir ein Verzeichnis an der vom Pfad angegebenen Stelle angelegt werden. File liefert weitere Informationen über Dateien:</p>
<table style="border-collapse: collapse; width: 100%; height: 525.297px;" border="1">
<tbody>
<tr style="height: 50.3594px;">
<td style="width: 49.9288%; height: 50.3594px;"><strong>Methode</strong></td>
<td style="width: 49.9288%; height: 50.3594px;"><strong>Funktion</strong></td>
</tr>
<tr style="height: 107.953px;">
<td style="width: 49.9288%; height: 107.953px;">isFile()</td>
<td style="width: 49.9288%; height: 107.953px;">Prüft, ob es sich bei der angegebenen File-Objekt um eine Datei handelt, (oder einen Ordner)</td>
</tr>
<tr style="height: 107.953px;">
<td style="width: 49.9288%; height: 107.953px;">isDirectory()</td>
<td style="width: 49.9288%; height: 107.953px;">Prüft, ob es sich bei der angegebenen File-Objekt um einen Ordner handelt, (oder eine Datei)</td>
</tr>
<tr style="height: 50.3594px;">
<td style="width: 49.9288%; height: 50.3594px;">canRead()</td>
<td style="width: 49.9288%; height: 50.3594px;">Prüft, ob der Benutzer Leserechte hat</td>
</tr>
<tr style="height: 79.1562px;">
<td style="width: 49.9288%; height: 79.1562px;">canWrite()</td>
<td style="width: 49.9288%; height: 79.1562px;">Prüft, ob der Benutzer Schreibrechte hat</td>
</tr>
<tr>
<td style="width: 49.9288%;">canExectue()</td>
<td style="width: 49.9288%;">Prüft, ob der Benutzer Ausführungsrechte hat</td>
</tr>
<tr style="height: 79.1562px;">
<td style="width: 49.9288%; height: 79.1562px;">getName()</td>
<td style="width: 49.9288%; height: 79.1562px;">Liefert den Namen der Datei, ohne vorangehende Pfadangabe</td>
</tr>
<tr style="height: 50.3594px;">
<td style="width: 49.9288%; height: 50.3594px;">getParent()<br>getParentFile()</td>
<td style="width: 49.9288%; height: 50.3594px;">Liefert das übergeordnete Verzeichnis, entweder als String mit getParent oder als Objekt mit getParentFile</td>
</tr>
<tr>
<td style="width: 49.9288%;">lastModified()</td>
<td style="width: 49.9288%;">Liefert das letzte Änderungsdatum der Datei als long</td>
</tr>
<tr>
<td style="width: 49.9288%;">length()</td>
<td style="width: 49.9288%;">Liefert die Grösse der Datei in Byte als long</td>
</tr>
<tr>
<td style="width: 49.9288%;">delete</td>
<td style="width: 49.9288%;">eine Datei löschen</td>
</tr>
<tr>
<td style="width: 49.9288%;">renameTo</td>
<td style="width: 49.9288%;">eine Datei umbenennen</td>
</tr>
</tbody>
</table>
<p>java.io.File stellt jedoch keine Methoden zur Verfügung für das Kopieren oder verschieben von Dateien. Dazu gibt es aber seit Java 7 eine Hilfsklasse aus Files.</p>
<h3 id="mcetoc_1g4tdqg1s5n7">Dateioperationen aus "Files"</h3>
<p>Die Klasse Files ist eine Sammlung von Hilfsmethoden für alles, was mit Dateien zu tun hat. Diese Klasse ist aber nicht im java.io-Package enthalten, sondern nur im java.nio.files. Damit ist es die einzige Klasse aus der Non-Blocking-I/O-API, die man auch beim alltäglichen Umgang mit Dateien regelmässig benutzt.</p>
<p>Da die Hilfsklasse zu der API java.nio.file.Path gehört und nicht zur java.io.File müssen bei jeder Operation die Parameter von File nach Path und die Rückgabewerte, falls Dateien zurückgegeben werden, wieder von Path nach File konvertiert werden. Dabei lassen sich nicht alle Path-Objekte nach File konvertieren, nur solche welche aus einer Operation auf einem File resultieren. Damit sind auch Kopier- und Verschiebeoperationen möglich. Die Verwendung dieser Methode macht mehr Sinn, als eine Eigenentwicklung in Java, da dies nicht nur praktischer ist, sondern auch effizienter die JDL Systemaufrufe verwenden kann.</p>
<p><code>//File nach Path konvertieren</code><br><code>Path quellPath = quelle.toPath();</code><br><code>Path zielPath = ziel.toPath();</code><br><code>//ENTWEDER Datei kopieren</code><br><code>Path ergebnisPath = Files.copy(quellPath, zielPath);</code><br><code>//ODER Datei verschieben</code><br><code>Path ergebnisPath = Files.move(quellPath, zielPath);</code><br><code>//Ergebnis - eigentlich wieder das Ziel - nach File konvertieren</code><br><code>File ergebnis = ergebnisPath.toFile();</code></p>
<h3 id="mcetoc_1g4tdqg1s5n8">Verzeichnisse</h3>
<p>Um den Inhalt von Verzeichnissen zu ermitteln, gibt es die überladene Methode listFiles die zur Files Klasse gehört. Ohne Parameter gibt sie alle im Verzeichnis enthaltenen Dateien zurück. Wenn man nur an bestimmten Dateien interessiert ist, dann sollte man entweder einen FileFilter oder einen FilenameFilter an listFiles übergeben. Die beiden Filterklassen unterscheiden sich nur darin, dass FileFilter das File-Objekt der gefundenen Datei zur Prüfung erhält, FilenameFilter den Dateinamen als String und das aktuelle Verzeichnis. Beide Filter sind funktionale Interfaces und können deshalb auch als Lambdas angegeben werden.</p>
<p><code>//Alle Dateien auflisten</code><br><code>File[] alleDateien = verzeichnis.listFiles();</code><br><code>//Alle Dateien mit der Endung .txt auflisten </code><br><code>File[] textDateien = verzeichnis.listFiles((parent, name) -&gt; </code><br><code> name.endsWith(".txt"));</code><br><code>//Alle Unterverzeichnisse auflisten</code><br><code>File[] unterverzeichnisse = verzeichnis.listFiles(file -&gt; </code><br><code> file.isDirectory());</code></p>
<p>Auch zum Auflisten des Verzeichnisinhalts hat die Klasse Files Hilfsmethoden. list gibt dabei den Inhalt eines Verzeichnisses als einen Stream von Path-Objekten zurück. walk, listet nicht nur den Inhalt des übergebenen Verzeichnisses auf, sondern auch aller Unterverzeichnisse, ist also rekursiv.</p>
<p><code>Files.walk(quelle.toPath()).forEach(System.out::println);</code></p>
<p>Optional kann die Tiefe der rekursiven Auflistung limitiert werden bis zu einer bestimmten Tiefe. walk(quelle, 1) enthält nur den Inhalt des Verzeichnisses selbst, tut also dasselbe wie list. walk(quelle, 2) enthält den Inhalt der Verzeichnisses und seiner direkten Unterverzeichnisse usw.</p>
<p>Weiter kann mit Files.find in einem Verzeichnis und dessen Unterverzeichnisse nach Dateien gesucht werden, die bestimmten Vorgaben entsprechen. Leider ist auch hier dass java.io und java.nio nicht aus einem Guss. So muss man also die Suchkriterien nicht als FileFilter angeben, sondern als BiPredicate, das als Parameter des Path-Objekt der Datei und ein Objekt vom Typ BasicFileAttributes erhält, in dem sich Informationen wie Dateigrösse und letzte Zugriffszeit finden. Das Beispiel zeigt, wie man Dateien, die grösser als 500MB sind, auflisten kann. Der grosse Nachteil von walk und find ist, dass wenn der Zugriff auf ein Verzeichnis nicht möglich ist, brechen sie mit einer Fehlermeldung ab. Es gibt keine Funktion, diesen Methoden beizubringen, bei unlesbaren Verzeichnissen einfach den Fehler zu ignorieren und weiter zu suchen. Deswegen wird häufig dennoch auf File.listFiles zurückgegriffen.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Stream.collect - Daten aus einem Stream sammeln</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/streamcollect-daten-aus-einem-stream-sammeln.html"/>
        <id>https://www.finecloud.ch/streamcollect-daten-aus-einem-stream-sammeln.html</id>
            <category term="stream-api"/>
            <category term="softwareentwicklung"/>
            <category term="lambda"/>
            <category term="java"/>
            <category term="dev"/>
            <category term="collector"/>
            <category term="collect"/>

        <updated>2022-06-04T12:14:10+02:00</updated>
            <summary>
                <![CDATA[
                    Die mächtige collect-Methode ist mit zwei Signaturen überladen, collect(Supplier, BiConsumer, BiConsumer) und collect(Collector). Beide sind aber prinzipiell identisch; ein Collection ist lediglich ein Objekt, das die drei Funktionen zusammenfasst und wiederverwendbar macht. collect sieht etwas bedrohlich aus, weil man gleich drei Funktionen übergeben muss, die&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Die mächtige collect-Methode ist mit zwei Signaturen überladen, collect(Supplier, BiConsumer, BiConsumer) und collect(Collector). Beide sind aber prinzipiell identisch; ein Collection ist lediglich ein Objekt, das die drei Funktionen zusammenfasst und wiederverwendbar macht.</p>
<p>collect sieht etwas bedrohlich aus, weil man gleich drei Funktionen übergeben muss, die zusammen irgendwie Ihre Ausgabe erzeugen sollen. Jede Funktion hat eine klar definierte Aufgabe:</p>
<ul>
<li>Der <strong>Supplier</strong> erzeugt ein Objekt, in dem gesammelt werden soll. Wenn man mittels collection eine Liste aus einem Stream erzeugen will, dann muss der Supplier diese Liste erzeugen. Warum übergibt man dann nicht gleich das Objekt, in dem gesammelt werden soll? Weil der Supplier in einem parallelen Stream mehrmals gerufen wird: Es werden mehrere Listen erzeugt, die später zusammengefasst werden.</li>
<li>Die <strong>erste BiConsumer</strong>, genannt der <em>Akkumulator</em>, kombiniert ein Element des Streams mit einem der vom Supplier erzeugten Sammelobjekte. Um beim Beispiel der Liste zu bleiben, fügt diese Funktion der Liste ein Element hinzu.</li>
<li>Der <strong>zweite BiConsumer</strong>, der <em>Kombinator</em>, fügt zwei Sammelobjekte zu einem zusammen. Diese Funktion sorgt also dafür, dass am Ende nur eine Liste zurückgegeben wird, auch wenn mehrere vom Supplier erzeugt wurden. Damit das funktioniert, muss das Sammelobjekt eine Funktion haben, dir diesem Objekt den Inhalt eines anderen Objekts hinzufügt, wie zum Beispiel die Methode addAll an einer Liste.</li>
</ul>
<p>Das Beispiel zeigt, wie alle Stream-Elemente in einer Liste gesammelt werden können:</p>
<p><code>List&lt;Person&gt; personen = personenStream.collect(</code><br><code>        ArrayList::new, </code><br><code>        ArrayList::add, </code><br><code>        ArrayList::addAll);</code></p>
<p>collect funktioniert nicht nur mit Listen, auch wenn der Methodenname nach Collections klingt. Jedes Objekt, das geeignete Methoden bereitstellt, kann zum Sammeln verwendet werden. So sammeln Sie alle Titel aus Ihrer Musiksammlung in einem String:</p>
<p><code>String songliste = songs.collect(StringBuilder::new, </code><br><code> (acc, el) -&gt; acc.append(el.getTitel()).append("\n"), </code><br><code> StringBuilder::append).toString();</code></p>
<p>Die drei richtigen Funktionen für einen Collector anzugeben, kann schwierig sein. Als Hilfe können die statische Methoden der Companion-Klasse verwendet werden, die nützliche Kollektoren bereitstellt. Zum Beispiel die, welche aus einem Stream wieder eine Collection machen:</p>
<p><code>List&lt;Song&gt; songList = songs.collect(Collectors.toList());</code><br><code>Set&lt;Song&gt; songSet = songs.collect(Collectors.toSet());</code></p>
<p>Kollektoren können mehr als das, die nachfolgenden Möglichkeiten aus Collectors machen deutlich, wie mächtig die collect-Methode ist:</p>
<table style="border-collapse: collapse; width: 100%;" border="1">
<tbody>
<tr>
<td style="width: 49.9288%;"><strong>collectors-Methode</strong></td>
<td style="width: 49.9288%;"><strong>Funktion</strong></td>
</tr>
<tr>
<td style="width: 49.9288%;">mapToDouble().average()</td>
<td style="width: 49.9288%;">Durchschnitt berechnen</td>
</tr>
<tr>
<td style="width: 49.9288%;">.count()</td>
<td style="width: 49.9288%;">Elemente zählen</td>
</tr>
<tr>
<td style="width: 49.9288%;">.summarizingDouble</td>
<td style="width: 49.9288%;">Statistische Daten, Summe (Double)</td>
</tr>
<tr>
<td style="width: 49.9288%;">.summarizingInt</td>
<td style="width: 49.9288%;">Statistische Daten, Summe (Int)</td>
</tr>
<tr>
<td style="width: 49.9288%;">.summarizingLong</td>
<td style="width: 49.9288%;">Statistische Daten, Summe (Long)</td>
</tr>
</tbody>
</table>
<p><code>DoubleSummaryStatistics statistik = zeilen</code><br><code>    .flatMap(line -&gt; Arrays.stream(line.split("\\s+"))</code><br><code>        .skip(1))</code><br><code>    .collect(Collectors.summarizingDouble(Double::parseDouble));</code><br><code>    System.out.println("Kältester Monat: " + statistik.getMin() + " Grad.");</code><br><code>    System.out.println("Wärmster Monat: " + statistik.getMax() + " Grad.");</code><br><code>    System.out.println("Durchschnitt: " + statistik.getAverage() + " Grad.");</code></p>
<p>Für fortgeschrittene statistische Auswertungen reicht das zwar noch nicht, es fehlt zum Beispiel eine Varianz, aber wenn Sie diese Funktionalität benötigen, können Sie nach demselben Muster einen eigenen Kollektor schreiben.</p>
<p>Die wohl vielseitigsten collect-Operationen, die Collectors anbietet, sind Partitionierung und Gruppierung. Beide trennen die Elemente im Stream nach einem festgelegten Kriterium in mehrere Gruppen. Der Unterschied zwischen den beiden besteht nur darin, dass <em>partitioningBy</em> Elemente nach einem Prädikat in zwei Gruppen zerlegt, die true-Gruppe und die false-Gruppe, während <em>groupingBy</em> anhand einer Funktion beliebig viele Gruppen erzeugen kann, eine für jeden Wert, den die Funktion zurückgegeben hat. Beide geben eine Map zurück, in der die Schlüssel TRUE/FALSE oder die Rückgabewerte der Funktion enthalten sind, mit den Werten dazu als jeweils eine Liste aller Objekte, die in diese Gruppe sortiert wurden. Mit diesem Beispiel können Songs nach Interpret sortiert werden:</p>
<p><code>songs.collect(Collectors.groupingBy(Song::getInterpret));</code></p>
<p>Dieses Beispiel gibt eine Map zurück, deren Schlüssel die Namen der Interpreten sind, die dazugehörigen Werte sind Listen aller Songs dieses Interpreten. Wenn Sie noch einen Schritt weiter gehen wollen, können Sie <em>groupingBy</em> und <em>partitioningBy</em> einen weiteren Collector übergeben, der auf die Werte jeder Gruppe angewendet wird:</p>
<p><code>songs.collect(Collectors.groupingBy(</code><br><code> Song::getInterpret,</code><br><code> Collectors.maxBy(Comparator.comparing(Song::getSterne))));</code></p>
<p>So einfach bekommen Sie den besten Song jedes Interpreten. Erst werden Songs nach Interpret gruppiert, in jeder Gruppe wird anschliessend der Song mit der maximalen Anzahl Sterne gefunden.</p>
<p>Fast immer ist es egal, welche Art von Map Sie beim Gruppieren oder Partitionieren zurückbekommen, aber in seltenen Fällen möchten Sie eine bestimmte Art von Map nutzen, zum Beispiel eine SortedMap. Für diesen Fall können Sie auch noch einen Supplier übergeben, der die richtige Map-Implementierung erzeugt.</p>
<p> </p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Endlose Streams</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/endlose-streams.html"/>
        <id>https://www.finecloud.ch/endlose-streams.html</id>
            <category term="threads"/>
            <category term="stream-api"/>
            <category term="softwareentwicklung"/>
            <category term="lambda"/>
            <category term="java"/>
            <category term="dev"/>

        <updated>2022-06-02T11:03:18+02:00</updated>
            <summary>
                <![CDATA[
                    Nicht jeder Stream ist endlich. Manche Streams erzeugen immer weiter Daten. Solche Streams nennt man auch Generatoren, weil sie ihre Daten selbst herstellen. Dazu gibt es in Stream und den primitiven Streams jeweils zwei statische Methoden, die einen solchen Stream erzeugen. Die generate-Methode arbeiten mit&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Nicht jeder Stream ist endlich. Manche Streams erzeugen immer weiter Daten. Solche Streams nennt man auch Generatoren, weil sie ihre Daten selbst herstellen. Dazu gibt es in Stream und den primitiven Streams jeweils zwei statische Methoden, die einen solchen Stream erzeugen.</p>
<p>Die <em>generate</em>-Methode arbeiten mit einem <em>Supplier</em>. Der so erzeugte Stream enthält nach und nach alle Werte, die dieser Supplier liefert. Ein solcher Stream ist sehr monoton, wenn der übergebene Supplier () -&gt; 1 lautet, aber er ist trotzdem endlos, denn der Supplier wird immer wieder aufgerufen. Zum Glück existieren auch interessantere Supplier.</p>
<p>Die zweite Möglichkeit, einen endlosen Stream zu erzeugen, heisst <em>iterate</em>. Diese Methode erzeugt einen Stream, indem sie eine übergebene Funktion immer wieder auf einen Standwert anwendet. Für einen Startwert n und eine Funktion f heisst das, der erzeugt Stream enthält die Werte [n, f(n), f(f(n)), f(f(f(n))), …]</p>
<p><code>Stream.iterate(BigInteger.ONE, i -&gt; i.multiply(two))</code><br><code>        .limit(1000)</code><br><code>        .forEach(System.out::println);</code></p>
<p>Das Beispiel erzeugt einen Stream alle Zweierpotenzen und gibt die ersten 1000 davon aus. Es versteht sich von selbst, dass manche Operationen auf einem endlosen Stream keine gute Idee sind. Ihn zu sortieren, führt eher zu Problemen, und auch bei einer forEach ohne limit sollte man sicher sein, was man tut. Für den zweiten Fall gibt es aber durchaus Anwendungen. So könnte man in einem Thread einen endlosen Stream von Ergebnissen erzeugen und jedes gefundene Ergebnis in einem anderen Thread verarbeiten.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Parallele Streams</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/parallele-streams.html"/>
        <id>https://www.finecloud.ch/parallele-streams.html</id>
            <category term="threads"/>
            <category term="stream-api"/>
            <category term="softwareentwicklung"/>
            <category term="parallel"/>
            <category term="lambda"/>
            <category term="java"/>
            <category term="dev"/>

        <updated>2022-05-31T12:06:01+02:00</updated>
            <summary>
                <![CDATA[
                    Streams können die Arbeit an Listen von Daten erheblich vereinfachen. Sie haben die Fähigkeit, die vor allem bei grossen Datenmengen extrem nützlich sein kann: Sie können in mehren Threads arbeiten. Das kann die Datenverarbeitung erheblich beschleunigen. Sie müssen dazu nicht selbst neue Threads starten, Streams&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <p>Streams können die Arbeit an Listen von Daten erheblich vereinfachen. Sie haben die Fähigkeit, die vor allem bei grossen Datenmengen extrem nützlich sein kann: Sie können in mehren Threads arbeiten. Das kann die Datenverarbeitung erheblich beschleunigen.</p>
<p>Sie müssen dazu nicht selbst neue Threads starten, Streams erledigen das für Sie. Manchmal können Sie einen Stream gleich als einen parallelen Stream erzeugen, zum Beispiel, indem Sie an einer Collection parallelStream anstelle von stream aufrufen. Es ist aber auch möglich einen Stream nachträglich in einen parallelen Stream umzuwandeln, indem die Methode parallel gerufen wird, oder wieder in einen sequenziellen Stream, also einen Stream, der in nur einem Thread verarbeitet wird, mit der Methode sequential. Beide Methoden sind intermediär, dadurch können Sie sogar in einer Pipeline einige Schritte parallel und andere sequenziell ausführen:</p>
<p><code>studentenDatei</code><br><code>        .lines()</code><br><code>        .parallel()</code><br><code>        .map(line -&gt; parseStudent(line))</code><br><code>        .filter(student -&gt; student.getNotendurchschnitt() &gt;= 5.0)</code><br><code>        .sequential()</code><br><code>        .forEach(student -&gt; schreibeInDatei(student)); </code></p>
<p>Im Beispiel wird eine Datei mit Studentendaten eingelesen, darin werden alle Studenten mit einem Notendurchschnitt von 5.0 oder höher in eine neue Datei geschrieben. Dazu werden zunächst die aus der Datei gelesenen Strings in Student-Objekte gemappt und nach Notendurchschnitt gefiltert. Diese Operationen können parallel ausgeführt werden, ohne dass es zu Fehlern kommt. In die Ausgabedatei muss aber ein Datensatz nach dem anderen geschrieben werden, es können nicht mehrere Threads gleichzeitig in dieselbe Datei schreiben. Dazu wird von dem terminalen <em>forEach</em> der Stream wieder sequenziell gemacht. So sind die Aufgaben, die in mehreren Threads verarbeitet werden können, parallel, aber die, bei denen es nicht geht, sequenziell.</p>
            ]]>
        </content>
    </entry>
    <entry>
        <title>Die Stream-API</title>
        <author>
            <name>Finecloud</name>
        </author>
        <link href="https://www.finecloud.ch/die-stream-api.html"/>
        <id>https://www.finecloud.ch/die-stream-api.html</id>
            <category term="stream-api"/>
            <category term="softwareentwicklung"/>
            <category term="lambda"/>
            <category term="java"/>
            <category term="dev"/>

        <updated>2022-06-06T23:14:49+02:00</updated>
            <summary>
                <![CDATA[
                    Das konsequente Fluent Interface der Stream-API macht es möglich, mit einem Blick zu erkennen was durch einen Lambda-Ausdruck in jeder einzelnen Zeile geschieht. Mit diesem Beispiel werden alle Vielfachen von 3 zwischen 0 und 100 ausgegeben: IntStream.range(0, 100) .filter(i -&gt; i % 3 == 0)&hellip;
                ]]>
            </summary>
        <content type="html">
            <![CDATA[
                <div class="post__toc">
<h3>Table of Contents</h3>
<ul>
<li><a href="#mcetoc_1g4tdrc035oj">Intermediäre und terminale Methoden</a></li>
<li><a href="#mcetoc_1g4tdrc035ok">Intermediäre Operatoren</a>
<ul>
<li><a href="#mcetoc_1g4tdrc035ol">Sortieren (sort)</a></li>
<li><a href="#mcetoc_1g4tdrc035om">Limitieren (limit)</a></li>
<li><a href="#mcetoc_1g4tdrc035on">Überspringen (skip)</a></li>
<li><a href="#mcetoc_1g4tdrc035oo">Filtern (filter)</a></li>
<li><a href="#mcetoc_1g4tdrc035op">Einmaligkeit (distinct)</a></li>
<li><a href="#mcetoc_1g4tdrc035oq">Abbilden</a></li>
<li><a href="#mcetoc_1g4tdrc035or">Spicken (peek)</a></li>
</ul>
</li>
<li><a href="#mcetoc_1g4tdrc035os">Terminale Operatoren</a>
<ul>
<li><a href="#mcetoc_1g4tdrc035ot">Alle Elemente verarbeiten</a></li>
<li><a href="#mcetoc_1g4tdrc035ou">Finden</a></li>
<li><a href="#mcetoc_1g4tdrc035ov">Prüfen</a></li>
<li><a href="#mcetoc_1g4tdrc035p0">Reduzieren</a></li>
</ul>
</li>
</ul>
</div>
<p>Das konsequente Fluent Interface der Stream-API macht es möglich, mit einem Blick zu erkennen was durch einen Lambda-Ausdruck in jeder einzelnen Zeile geschieht. Mit diesem Beispiel werden alle Vielfachen von 3 zwischen 0 und 100 ausgegeben:</p>
<p><code>IntStream.range(0, 100)</code><br><code>        .filter(i -&gt; i % 3 == 0)</code><br><code>        .forEach(System.out::println);</code></p>
<p>Richtig praktisch werden solche Lambda und Streams beim lesen von Dateiinhalten:</p>
<p><code>BufferedReader danksagung = new BufferedReader(new FileReader("ebook.txt"))</code><br><code>danksagung.lines()</code><br><code>        .filter(line -&gt; line.toLowerCase().contains("Danksagung"))</code><br><code>        .findFirst()</code><br><code>        .ifPresent(System.out::println);</code></p>
<p>Ab welcher Zeile startet im E-Book die Danksagung? Mit findFrist wird nur die erste Zeile gesucht, in der ein Ergebnis steht, anschliessend wird nicht mehr weiter gesucht, sondern das Ergebnis wird ausgegeben.</p>
<p>Streams sind eine andere Art in Java mit Listen von Daten umzugehen, aber sie sind keinen Ersatz für Collections oder Arrays, eher eine Ergänzung. Streams fehlt nämlich eine Eigenschaft, welche den anderen Datenstrukturen haben: Permanenz. In einer Collection speichern Sie Daten, um bei Bedarf wieder darauf zuzugreifen und zwar so oft sie wollen. Ein Stream dient lediglich der Verarbeitung von Daten. Sie können den Inhalt einen Streams genau einmal auslesen, danach ist er weg und nicht mehr zurückzubekommen. Insofern gleicht ein Stream eher einem Iterator als einer Collection. Wenn Sie auf die Ausgabe der Pipeline nach Belieben wieder zugreifen möchten, dann müssen Sie sie wieder in einer Collection sammeln.</p>
<h3 id="mcetoc_1g4tdrc035oj">Intermediäre und terminale Methoden</h3>
<p>Der Unterschied ist, das Intermediäre Methoden wieder ein Stream zurückgeben mit dem man weiterarbeiten kann, terminale Methoden geben einen anderen Ergebnistyp zurück. So entsteht eine Pipeline, die durch die terminale Methode gesteuert wird. Sie "zieht" Daten aus dem Stream und erst durch die terminale Methode werden überhaupt Daten aus dem Stream gelesen. Solange Sie nur intermediäre Methoden aufrufen, passiert im Stream noch nichts.</p>
<p><em>findFrist</em> gibt keinen Stream mehr zurück, sondern ein Optional und if-Present ist eine Methode davon. <em>findFirst</em> ist eine terminale Methode, also eine die am Ende der Stream-Verarbeitung steht. <em>filter</em> dagegen ist eine intermediäre Methode und steht in der Mitte der "Pipeline".</p>
<p>Schauen wir uns das mit dem Beispiel von oben an:</p>
<ul>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Die Methode BufferedReader.lines erzeugt einen Stream&lt;String&gt;. Es werden noch keine Daten gelesen.</span></li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Aus diesem Stream wird mit filter ein neuer Stream erzeugt, der die Filteranweisung verarbeitet. Es werden noch immer keine Daten gelesen.</span></li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Die terminale Methode findFirst wird gerufen. Nun beginnt die Verarbeitung.</span></li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">findFirst liest das erste Element aus dem gefilterten Stream.</span></li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Der gefilterte Stream liest das erste Element des ungefilterten Streams und wertet sein Prädikat line.toLowerCase().contains("Danksagung") aus.</span></li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Die erste Zeile "Einleitung" wird vom Filter zurückgewiesen. Der gefilterte Stream liest die zweite Zeile des ungefilterten Streams und wendet erneut sein Prädikat an. Auch diese Zeile wird zurückgewiesen.</span></li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Erst Zeile Nummer X wird vom Filter akzeptiert. Jetzt gibt der gefilterte Stream seine erste Rückgabe: "Danksagung".</span></li>
<li>findFirst empfängt die Rückgabe vom gefilterten Stream. Es benötigt keine weiteren Ergebnisse. Es wird nur der erste Treffer gesucht, deshalb wird kein weiteres Element aus dem gefilterten Stream gelesen.</li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">findFirst schliesst den gefilterten Stream und gibt das gefundene Ergebnis (richtiger: ein Optional mit dem gefundenen Ergebnis) zurück.</span></li>
<li><span style="color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);">Was ist wirklich passiert? Es wurden 13 Zeilen aus dem ungefilterten Stream gelesen, davon wurde eine Zeile in den gefilterten Stream weitergeschrieben. Mehr nicht.</span></li>
</ul>
<p>Damit wurde keine Zeile mehr gelesen, als notwendig. Streams sind nicht nur gut darin, Ihre Absichten in Code auszudrücken, sie sind dabei auch noch äusserst effizient.</p>
<h3 id="mcetoc_1g4tdrc035ok">Intermediäre Operatoren</h3>
<h4 id="mcetoc_1g4tdrc035ol"><strong>Sortieren (sort)</strong></h4>
<p>Einen Stream kann nach seiner natürlichen Ordnung sortiert werden, wenn seine Elemente Comparable implementieren, oder mit einem übergebenen Comparator. In allen Fällen bleibt der Inhalt der Datenquelle unverändert. Nachfolgend ein Beispiel, darin wird der heisseste Tag im Jahr gesucht, zuerst wird absteigend nach Temperatur sortiert und dann das erste Element selektiert:</p>
<p><code>tagestemperaturen</code><br><code>        .sorted(Comparator</code><br><code>                .comparing(Tagestemperatur::getTemperatur)</code><br><code>                .reversed())</code><br><code>        .findFirst();</code></p>
<h4 id="mcetoc_1g4tdrc035om">Limitieren (limit)</h4>
<p>Meistens will man nur auf einem teil des Streams arbeiten, z.B. nur auf dem Anfang. Mit limit kann ein Stream auf eine beliebige Anzahl von Elementen beschränkt werden. Auch wenn der darunterliegende Stream mehr Elemente hätte, endet der limitierte Stream, wenn seine Anzahl erreicht ist. Im Beispiel werden die zehn besten Songs aus einer Sammlung sortiert, limitiert und ausgegeben:</p>
<p><code>songs</code><br><code>        .sorted(Comparator.comparing(Song::getSterne).reversed())</code><br><code>        .limit(10)</code><br><code>        .forEach(song -&gt; System.out.println(song.getTitel()));</code></p>
<h4 id="mcetoc_1g4tdrc035on">Überspringen (skip)</h4>
<p>Will man nicht nach einem bestimmen Inhalt suchen, sondern diesen bestimmten Inhalt bewusst überspringen. Folgende Datei soll eingelesen werden:</p>
<p><em>Höchsttemperaturen Basel</em><br><em>Datum;Temperatur</em><br><em>01.3.2021;1</em><br><em>02.3.2021;3</em><br><em>13.3.2021;8</em><br><em>…</em></p>
<p>dabei interessieren uns aber nur die Temperaturen, die ersten zwei Zeilen interessieren uns nicht:</p>
<p><code>daten.lines()</code><br><code>        .skip(2)</code><br><code>        .map(TemperaturMessung::parse)</code><br><code>        ...</code></p>
<h4 id="mcetoc_1g4tdrc035oo">Filtern (filter)</h4>
<p>Man übergibt ihr ein Predicate und nur die Elemente, für die das Predicate true liefert, werden im Stream weitergereicht:</p>
<p><code>kandidaten</code><br><code>        .filter(k -&gt; k.getHaarfarbe().equals("rot") </code><br><code>                &amp;&amp; k.getAugenfarbe().equals("grün"))</code><br><code>        .forEach(k -&gt; sprichAn(k));</code></p>
<h4 id="mcetoc_1g4tdrc035op">Einmaligkeit (distinct)</h4>
<p>Wenn in einem Stream Duplikate entfernt werden sollen, kann das mit distinct sichergestellt werden. Damit merkt sich der Strom alle Elemente, die bereits einmal vorkamen und gibt sie kein zweites Mal zurück. Bei Streams von Objekten wird Gleichheit mit equals bestimmt. Achtung: distinct ist eine Operation mit Zustand und kann für lange Streams sehr viel Speicher belegen.</p>
<p><code>kontakte</code><br><code>        .distinct()</code><br><code>        .count();</code></p>
<h4 id="mcetoc_1g4tdrc035oq">Abbilden</h4>
<p>Das sind alle Operationen, die aus den Eingabewerten etwas berechnen und als Ausgabestrom wieder ausgeben:</p>
<p><code>personen</code><br><code>        .map(Person::getName)</code><br><code>        .forEach(System.out::println);</code></p>
<p>Mit der map-Methode ist der Ausgabe-Stream wieder ein Stream von Objekten; wenn das Ergebnis der Function ein primitiver Typ ist, wird er dazu in den passenden Wrapper konvertiert. Wenn man deinen Stream von primitiven Typen als Ausgaben benötigt, stehen dafür die Methoden <em>mapToInt</em>, <em>mapToLong</em> und <em>mapToDouble</em> zur Verfügung.</p>
<p>Etwas komplizierter ist die Methode flatMap und ihre primitiven Gegenstücke. Sie erwarten als Parameter eine Funktion, die aus jedem Eingabeelement einen Stream erzeugt. Die Ausgabe von flatMap ist ein Stream, in dem die Elemente aller Streams jeweils nacheinander zu einem Ausgabe Stream zusammengefasst sind. Als Beispiel: Das Stadtfest in Ihrer Stadt. Es war eine Anmeldung erforderlich und von jeder Anmeldung wird erwartet, dass die gesamte Familie mitkommt. Anmeldungen sind in einem Objekt vom typ Person gespeichert, das den Namen der Person enthält, seinen oder ihren Partner als weiteres Person-Objekt und die Kinder als Liste von Personen. Angemeldet sind:</p>
<ul>
<li>Hans Fischer mit Partner Frieda Fischer und den Kindern Fritz, Max und Lisa</li>
<li>Ida mit Partner Martin</li>
<li>Max Müller mit seinen Kindern Moritz und Peter</li>
</ul>
<p>Von der ersten Anmeldung ausgehend soll nun eine Liste aller erwarteten Gäste ausgegeben werden:</p>
<p><code>anmeldungen</code><br><code>        .flatMap(p -&gt; Stream.concat(</code><br><code>                Stream.of(p, p.getPartner()), </code><br><code>                p.getKinder().stream()))</code><br><code>        .filter(p -&gt; p != null)</code><br><code>        .map(Person::getName)</code><br><code>        .forEach(System.out::println);</code></p>
<p>Mit flatMap ist die Liste schnell erstellt, aber was genau passiert, ist auch mit Lambda-Ausdrücken nicht sofort ersichtlich:</p>
<ul>
<li>Mit Stream.of wird ein Stream erzeugt, der die person selbst und ihren Partner enthält. Dank Varargs können Stream.of einfach alle Elemente übergeben werden, die der so erzeugt Stream enthalten soll.</li>
<li>Aus der Liste von Kindern wird ein weiterer Stream erzeugt. Da die Kinder in einer Collection gespeichert sind, kann da smit der stream-Methode erreicht werden.</li>
<li>Diese beiden Stream werden mit Stream.concat zusammengesetzt. Die Methode gibt einen Stream zurück, der das Erste aller Elemente des ersten übergebenen Streams und danach allen Elemente des zweiten übergebenen Streams enthält.</li>
<li>flatMap wird für jede Person aus <em>anmeldungen</em> gerufen, intern werden dadurch drei Stream erzeugt: [Hans Fischer, Frieda Fischer, Fritz, Max, Lisa][Ida, Martin][Max Müller, null, Moritz und Peter]. Da Max Müller keinen Partner (mehr) hat, resultiert aus p.getPartner() ein null-Wert; dieser wird von der späteren filter-Anweisung wieder entfernt werden.</li>
<li>flatMap gibt aber nicht einen Stream pro Eingabe zurück (das käme bei map heraus), sondern nur einen langen Stream. Daher auch der Name flatMap: Anstatt einen Stream von Streams auszugeben, ist die Ausgabe flach. Der so erzeugte Stream enthält also: [Hans Fischer, Frieda Fischer, Fritz, Max, Lisa, Ida, Martin, Max Müller, null, Moritz und Peter]</li>
</ul>
<h4 id="mcetoc_1g4tdrc035or">Spicken (peek)</h4>
<p>peek gibt genau denselben Stream aus, der auch eingegeben wurde, führt aber für jedes Element einen Consumer aus. Der Inhalt des Streams wird nicht verändert. Mit peek können Sie einem Stream bei der Arbeit zuschauen, was insbesondere bei Fehlersuche hilfreich ist:</p>
<p><code>danksagung.lines()</code><br><code>        .peek(line -&gt; System.out.println("Ungefiltert " + line))</code><br><code>        .filter(line -&gt; line.toLowerCase().contains("Danksagung"))</code><br><code>        .peek(line -&gt; System.out.println("Gefiltert " + line))</code><br><code>        .findFirst()</code><br><code>        .ifPresent(System.out::println);</code></p>
<p>peek kann auch verwendet werden, um beispielsweise bei Anmeldungen Bestätigungen zu versenden:</p>
<p><code>anmeldungen</code><br><code>        .peek(p -&gt; bestaetigeAnmeldung(p))</code><br><code>        .flatMap(p -&gt; Stream.concat(Stream.of(</code><br><code>                p, p.getPartner()), </code><br><code>                p.getKinder().stream()))</code><br><code>        .filter(p -&gt; p!= null)</code><br><code>        .map(Person::getName)</code><br><code>        .forEach(System.out::println);</code></p>
<h3 id="mcetoc_1g4tdrc035os">Terminale Operatoren</h3>
<h4 id="mcetoc_1g4tdrc035ot">Alle Elemente verarbeiten</h4>
<p>Diese Methode führt für alle Elemente, die am Ende in einem Stream enthalten sind, diesele Operation aus. forEach ist als Beispiel zu nennen. Sie führt den übergebenen Consumer für jedes Element des Streams aus. </p>
<h4 id="mcetoc_1g4tdrc035ou">Finden</h4>
<p>Wenn aus einem Stream nicht alle Elemente verarbeitet werden solle, sondern nur ein einzelnen benötigt wird, gibt es dafür findFirst oder findAny:</p>
<p><code>Optional&lt;Student&gt; gut = studenten</code><br><code>        .filter(student -&gt; student.getNotendurchschnitt() == 5.0)</code><br><code>        .findAny();</code></p>
<p>Der unterschied zwischen den beiden Methoden ist, dass findFirst garantiert das erste Element zurückgibt, findAny nur irgendein Element. Dieser Unterschied kommt bei paralleler Verarbeitung zum Tragen, wo das erste gefunden Element nicht notwendig das erste aus dem Stream ist. findFirst stellt in dieser Situation sicher, dass wirklich das erste Element des Stream ausgegeben wird.</p>
<p>Beide Methoden geben ein Optional-Objekt zurück. Grob gesagt handelt es sich um einen Umschlag, der ein Objekt ungleich null enthalten oder auch leer sein kann. So wird auch, wenn kein Ergebnis gefunden wurde, ein Objekt zurückgegeben, nicht direkt ein null-Wert. Dadurch können Sie an dem zurückgegeben en Objekt immer weitere Methoden aufrufen und müssen nicht auf null prüfen, was. in der Aufrufkette der Fluent API nicht möglich wäre. Stattdessen können Sie diese Prüfung in die Aufrufkette integrieren:</p>
<p><code>studenten</code><br><code>        .filter(student -&gt; student.getNotendurchschnitt() == 5.0)</code><br><code>        .findAny()</code><br><code>        .ifPresent(s -&gt; verarbeiteGutenStudenten(s));</code></p>
<p>Das an ifPresent übergebene Lambda wird nur ausgeführt, wenn das von findAny zurückgegebene Optional ein Ergebnis enthält.</p>
<h4 id="mcetoc_1g4tdrc035ov">Prüfen</h4>
<p>Nur um zu prüfen, ob der Stream Elemente enthält, die einem bestimmten Kriterium entsprechen, ohne diese Elemente zurückzugeben, gibt es drei boolesche Methoden. anyMatch, prüft, ob irgendein Element des Streams zum übergebenen Predicate passt, allMatch prüft, ob alle Elemente passen, und noneMatch schliesslich, ob keines der Elemente passt.</p>
<p><code>if (studenten.anyMatch(student -&gt; </code><br><code>        student.getNotendurchschnitt() == 6.0)){</code><br><code>    …            </code><br><code>}</code></p>
<h4 id="mcetoc_1g4tdrc035p0">Reduzieren</h4>
<p>Mit Streams können Sie auch einen einzelnen Wert berechnen lassen, der den Stream zusammenfasst. Der Inhalt wird auf diesen einen Wert reduziert, daher auch der Name der Methode für diese Operatoren: reduce.</p>
<p><code>int gesamtlaenge = songs</code><br><code>        .mapToInt(Song::getLaengeInSekunden)</code><br><code>        .reduce(0, (x, y) -&gt; x+y);</code></p>
<p>Die reduce-Methode funktioniert, indem nacheinander (oder sogar parallel) alle Elemente des Streams durch die übergebene Funktion mit einem Akkumulator verknüpft werden. Der Akkumulator wird mit dem übergebenen Neutralwert der Verknüpfung vorbelegt. Im Beispiel werden also, von einem Wert 0 ausgehend, die Länge aller Songs im Stream addiert, um die Gesamtlänge zu berechnen.</p>
<p>Sie müssen keinen Neutralwert übergeben, dann erhält der Akkumulator anfangs das erste Element (sofern vorhanden)m due erste Verknüpfung geschieht mit dem zweiten Element, und das Ergebnis der reduce-Operation ist Optional. Im Beispiel soll der längste Songs gefunden werden:</p>
<p><code>Optional&lt;Song&gt; laengsterSong = songs.reduce((x, y) -&gt;</code><br><code> x.getLaengeInSekunden() &gt; y.getLaengeInSekunden() ? x : y);</code></p>
<p>Der ternäre Fragezeichen-Operator gibt immer den längeren der beiden Songs zurück, am Ende bleibt im Akkumulator der längste stehen.</p>
<p>Einige häufigt reduce-Operatoren sind schon als eigene Methoden implementiert:</p>
<table style="border-collapse: collapse; width: 100%;" border="1">
<tbody>
<tr>
<td style="width: 49.9288%;"><strong>Methode</strong></td>
<td style="width: 49.9288%;"><strong>Funktion</strong></td>
</tr>
<tr>
<td style="width: 49.9288%;">count</td>
<td style="width: 49.9288%;">zählt die Elemente im Stream</td>
</tr>
<tr>
<td style="width: 49.9288%;">(nur primitive Streams) sum</td>
<td style="width: 49.9288%;">summiert alle Zahlen im Stream</td>
</tr>
<tr>
<td style="width: 49.9288%;">(nur primitive Streams) min / max</td>
<td style="width: 49.9288%;">das kleinste, bzw. grösste Element</td>
</tr>
<tr>
<td style="width: 49.9288%;">(nur primitive Streams) average</td>
<td style="width: 49.9288%;">Durchschnitt aller Elemente</td>
</tr>
</tbody>
</table>
<p>Komplexere Methoden, die aus einem Stream wieder andere Typen gewinnen, um z.B. einen Stream wieder in eine Liste umzuwandeln, werden mit Collections umgesetzt.</p>
<p> </p>
<p> </p>
            ]]>
        </content>
    </entry>
</feed>
